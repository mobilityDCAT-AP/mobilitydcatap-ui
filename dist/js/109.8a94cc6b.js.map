{"version":3,"file":"js/109.8a94cc6b.js","mappings":"oHAAA,MAAMA,EAAO,EAAQ,OACfC,EAAe,EAAQ,OAE7B,MAAMC,UAAeF,EACnB,WAAAG,CAAaC,GACXC,MAAMJ,EAAcG,EACtB,EAGFE,EAAOC,QAAUL,C,wBCTjB,MAAMM,EAAM,EAAQ,QACd,aAAEC,GAAiB,EAAQ,QAC3B,UAAEC,GAAc,EAAQ,OAExBC,EAAsB,QAE5B,SAASC,EAAaC,GACpB,OAAOC,GACiB,cAAlBA,EAAKC,SACA,KAGJD,EAAKE,MAAMC,WAAWN,GAKpBE,EAAQK,UAAUJ,EAAKE,MAAMG,MAAMR,EAAoBS,SAJrD,IAMb,CAEA,SAASC,EAAaR,GACpB,MAAMS,EAAUV,EAAYC,GAE5B,OAAOU,IACL,MAAMC,EAAUF,EAAQC,EAAKC,SACvBC,EAAYH,EAAQC,EAAKE,WACzBC,EAASJ,EAAQC,EAAKG,QACtBC,EAAQL,EAAQC,EAAKI,OAE3B,OAAIH,GAAWC,GAAaC,GAAUC,EAC7Bd,EAAQU,KACbC,GAAWD,EAAKC,QAChBC,GAAaF,EAAKE,UAClBC,GAAUH,EAAKG,OACfC,GAASJ,EAAKI,OAIXJ,EAEX,CAEA,MAAMtB,EACJ,WAAAE,CAAayB,GAAO,QAAEC,EAAUlB,EAAmB,QAAEmB,EAAU,KAAI,QAAEjB,EAAUL,GAAQ,CAAC,GACtF,MAAMuB,EAAS,IAAItB,EAAa,CAC9BoB,UACAC,UACAE,YAAanB,EACboB,kBAAkB,IAGpBL,EAAMM,KAAKH,GAEX,MAAMT,EAAUD,EAAYR,GAEtBsB,EAAY,IAAIzB,EAAU,CAC9B0B,YAAY,EACZD,UAAW,CAACZ,EAAMc,EAAUC,KAC1BA,EAAS,KAAMhB,EAAQC,GAAK,IAYhC,OARAQ,EAAOQ,GAAG,WAAWT,IACnBU,OAAOC,QAAQX,GAASY,SAAQ,EAAEC,EAAQC,MACxCT,EAAUU,KAAK,SAAUF,EAAQ9B,EAAQK,UAAU0B,GAAI,GACxD,IAEHb,EAAOQ,GAAG,SAASO,GAAOX,EAAUY,QAAQD,KAC5Cf,EAAOG,KAAKC,GAELA,CACT,EAGF7B,EAAOC,QAAUN,C,wBC3EjB,MAAM+C,EAAc,EAAQ,OAE5B1C,EAAOC,QAAUyC,C,oBCFjB,MAAMC,EACJ,WAAA9C,CAAa+C,GACXC,KAAKnC,MAAQkC,GAAO,OAASD,EAAUG,MACzC,CAEA,MAAAC,CAAQC,GACN,QAASA,GAASA,EAAMvC,WAAaoC,KAAKpC,UAAYuC,EAAMtC,QAAUmC,KAAKnC,KAC7E,EAGFiC,EAAUM,UAAUxC,SAAW,YAE/BkC,EAAUG,OAAS,EAEnB9C,EAAOC,QAAU0C,C,wBCdjB,MAAMA,EAAY,EAAQ,OACpBO,EAAe,EAAQ,OACvBC,EAAc,EAAQ,MACtBC,EAAU,EAAQ,OAClBC,EAAY,EAAQ,OACpBC,EAAO,EAAQ,OACfC,EAAW,EAAQ,OAEzB,SAAS3C,EAAWF,GAClB,OAAO,IAAI2C,EAAU3C,EACvB,CAEA,SAAS8C,EAAW9C,GAClB,OAAO,IAAIiC,EAAUjC,EACvB,CAEA,SAAS+C,EAAS/C,EAAOgD,GACvB,MAAkC,kBAAvBA,GACgC,IAArCA,EAAmBC,QAAQ,KACtB,IAAIP,EAAQ1C,EAAOgD,GAGrB,IAAIN,EAAQ1C,EAAO,KAAMgC,EAAY9B,UAAU8C,IAGjD,IAAIN,EAAQ1C,EAAO,KAAMgD,EAClC,CAEA,SAASE,EAAUlD,GACjB,OAAO,IAAI6C,EAAS7C,EACtB,CAEA,SAASmD,IACP,OAAOnB,EAAYoB,oBACrB,CAEA,SAASC,EAAQ7C,EAASC,EAAWC,GACnC,OAAOsB,EAAYzB,KAAKC,EAASC,EAAWC,EAC9C,CAEA,SAASH,EAAMC,EAASC,EAAWC,EAAQC,GACzC,OAAO,IAAIiC,EAAKpC,EAASC,EAAWC,EAAQC,GAASqB,EAAYoB,qBACnE,CAEA,SAASE,EAAUC,GACjB,OAAOd,EAAYe,KAAKxB,EAAauB,EACvC,CAEA,SAASE,EAAUF,GACjB,OAAOd,EAAYe,KAAKxB,EAAauB,EACvC,CAEA,MAAMvB,EAAc,CAClB9B,YACA4C,YACAC,UACAG,WACAC,eACAE,SACA9C,OACA+C,WACAG,WACAL,qBAAsB,IAAIZ,GAG5BlD,EAAOC,QAAUyC,C,oBCjEjB,MAAMQ,EACJ,MAAAH,CAAQC,GACN,QAASA,GAASA,EAAMvC,WAAaoC,KAAKpC,QAC5C,EAGFyC,EAAaD,UAAUxC,SAAW,eAClCyC,EAAaD,UAAUvC,MAAQ,GAE/BV,EAAOC,QAAUiD,C,wBCTjB,MAAMG,EAAY,EAAQ,OAE1B,MAAMD,EACJ,WAAAvD,CAAaa,EAAO0D,EAAUC,GAC5BxB,KAAKnC,MAAQA,EACbmC,KAAKwB,SAAWjB,EAAQkB,eACxBzB,KAAKuB,SAAW,GAEZA,GACFvB,KAAKuB,SAAWA,EAChBvB,KAAKwB,SAAWjB,EAAQmB,oBACfF,IACTxB,KAAKwB,SAAWA,EAEpB,CAEA,MAAAtB,CAAQC,GACN,QAASA,GAASA,EAAMvC,WAAaoC,KAAKpC,UAAYuC,EAAMtC,QAAUmC,KAAKnC,OACzEsC,EAAMoB,WAAavB,KAAKuB,UAAYpB,EAAMqB,SAAStB,OAAOF,KAAKwB,SACnE,EAGFjB,EAAQH,UAAUxC,SAAW,UAE7B2C,EAAQmB,mBAAqB,IAAIlB,EAAU,yDAC3CD,EAAQkB,eAAiB,IAAIjB,EAAU,2CAEvCrD,EAAOC,QAAUmD,C,oBC3BjB,MAAMC,EACJ,WAAAxD,CAAayC,GACXO,KAAKnC,MAAQ4B,CACf,CAEA,MAAAS,CAAQC,GACN,QAASA,GAASA,EAAMvC,WAAaoC,KAAKpC,UAAYuC,EAAMtC,QAAUmC,KAAKnC,KAC7E,EAGF2C,EAAUJ,UAAUxC,SAAW,YAE/BT,EAAOC,QAAUoD,C,wBCZjB,MAAMH,EAAe,EAAQ,OAE7B,MAAMI,EACJ,WAAAzD,CAAaqB,EAASC,EAAWC,EAAQC,GACvCwB,KAAK3B,QAAUA,EACf2B,KAAK1B,UAAYA,EACjB0B,KAAKzB,OAASA,EAGZyB,KAAKxB,MADHA,GAGW,IAAI6B,CAErB,CAEA,MAAAH,CAAQC,GAEN,QAASA,IAA6B,SAAnBA,EAAMvC,WAAwBuC,EAAMvC,WACrDuC,EAAM9B,QAAQ6B,OAAOF,KAAK3B,UAAY8B,EAAM7B,UAAU4B,OAAOF,KAAK1B,YAClE6B,EAAM5B,OAAO2B,OAAOF,KAAKzB,SAAW4B,EAAM3B,MAAM0B,OAAOF,KAAKxB,MAChE,EAGFiC,EAAKL,UAAUxC,SAAW,OAC1B6C,EAAKL,UAAUvC,MAAQ,GAEvBV,EAAOC,QAAUqD,C,oBC1BjB,MAAMC,EACJ,WAAA1D,CAAa2E,GACX3B,KAAKnC,MAAQ8D,CACf,CAEA,MAAAzB,CAAQC,GACN,QAASA,GAASA,EAAMvC,WAAaoC,KAAKpC,UAAYuC,EAAMtC,QAAUmC,KAAKnC,KAC7E,EAGF6C,EAASN,UAAUxC,SAAW,WAE9BT,EAAOC,QAAUsD,C,mBCZjB,SAASS,EAAUC,GACjB,IAAKA,EACH,OAAO,KAGT,GAA0B,cAAtBA,EAASxD,SACX,OAAOoC,KAAKW,UAAUS,EAASvD,OAGjC,GAA0B,iBAAtBuD,EAASxD,SACX,OAAOoC,KAAKgB,eAGd,GAA0B,YAAtBI,EAASxD,SACX,OAAOoC,KAAKY,QAAQQ,EAASvD,MAAOuD,EAASG,UAAYvB,KAAKjC,UAAUqD,EAASI,SAAS3D,QAG5F,GAA0B,cAAtBuD,EAASxD,SACX,OAAOoC,KAAKjC,UAAUqD,EAASvD,OAGjC,GAA0B,SAAtBuD,EAASxD,SAAqB,CAChC,MAAMS,EAAU2B,KAAKmB,SAASC,EAAS/C,SACjCC,EAAY0B,KAAKmB,SAASC,EAAS9C,WACnCC,EAASyB,KAAKmB,SAASC,EAAS7C,QAChCC,EAAQwB,KAAKmB,SAASC,EAAS5C,OAErC,OAAOwB,KAAK5B,KAAKC,EAASC,EAAWC,EAAQC,EAC/C,CAEA,GAA0B,aAAtB4C,EAASxD,SACX,OAAOoC,KAAKe,SAASK,EAASvD,OAGhC,MAAM,IAAI+D,MAAM,oBAAoBR,EAASxD,WAC/C,CAEAT,EAAOC,QAAU+D,C,oBCrCjB,MAAMtE,EACJ,WAAAG,CAAa6E,EAAM5E,GACjB+C,KAAK6B,KAAOA,EACZ7B,KAAK/C,QAAUA,CACjB,CAEA,MAAA6E,CAAQrD,EAAOxB,GACb,MAAM8E,EAAS,IAAI/B,KAAK6B,KAAKpD,EAAOY,OAAO2C,OAAO,CAAC,EAAGhC,KAAK/C,QAASA,IAYpE,OAVAwB,EAAMW,GAAG,OAAO,KACT2C,EAAOE,UACVF,EAAOrC,KAAK,MACd,IAGFjB,EAAMW,GAAG,SAAUO,IACjBoC,EAAOrC,KAAK,QAASC,EAAG,IAGnBoC,CACT,EAGF5E,EAAOC,QAAUP,C,oBCvBjB,SAAUqF,IAEO,SAAW9E,GAE1B,IAAI+E,EAAU,CACZC,aAAc,oBAAqBF,EACnCG,SAAU,WAAYH,GAAQ,aAAcI,OAC5CC,KACE,eAAgBL,GAChB,SAAUA,GACV,WACE,IAEE,OADA,IAAIM,MACG,CACT,CAAE,MAAOC,GACP,OAAO,CACT,CACD,CAPD,GAQFC,SAAU,aAAcR,EACxBS,YAAa,gBAAiBT,GAGhC,SAASU,EAAWC,GAClB,OAAOA,GAAOC,SAAS1C,UAAU2C,cAAcF,EACjD,CAEA,GAAIV,EAAQQ,YACV,IAAIK,EAAc,CAChB,qBACA,sBACA,6BACA,sBACA,uBACA,sBACA,uBACA,wBACA,yBAGEC,EACFC,YAAYC,QACZ,SAASN,GACP,OAAOA,GAAOG,EAAYlC,QAAQzB,OAAOe,UAAUgD,SAAS/B,KAAKwB,KAAS,CAC5E,EAGJ,SAASQ,EAAc1B,GAIrB,GAHoB,kBAATA,IACTA,EAAO2B,OAAO3B,IAEZ,4BAA4B4B,KAAK5B,GACnC,MAAM,IAAI6B,UAAU,0CAEtB,OAAO7B,EAAK8B,aACd,CAEA,SAASC,EAAe7F,GAItB,MAHqB,kBAAVA,IACTA,EAAQyF,OAAOzF,IAEVA,CACT,CAGA,SAAS8F,EAAYC,GACnB,IAAIC,EAAW,CACbC,KAAM,WACJ,IAAIjG,EAAQ+F,EAAMG,QAClB,MAAO,CAACC,UAAgBC,IAAVpG,EAAqBA,MAAOA,EAC5C,GASF,OANIsE,EAAQE,WACVwB,EAASvB,OAAOuB,UAAY,WAC1B,OAAOA,CACT,GAGKA,CACT,CAEA,SAASK,EAAQC,GACfnE,KAAKoE,IAAM,CAAC,EAERD,aAAmBD,EACrBC,EAAQ5E,SAAQ,SAAS1B,EAAO8D,GAC9B3B,KAAKqE,OAAO1C,EAAM9D,EACpB,GAAGmC,MACMsE,MAAMC,QAAQJ,GACvBA,EAAQ5E,SAAQ,SAASiF,GACvBxE,KAAKqE,OAAOG,EAAO,GAAIA,EAAO,GAChC,GAAGxE,MACMmE,GACT9E,OAAOoF,oBAAoBN,GAAS5E,SAAQ,SAASoC,GACnD3B,KAAKqE,OAAO1C,EAAMwC,EAAQxC,GAC5B,GAAG3B,KAEP,CA8DA,SAAS0E,EAASC,GAChB,GAAIA,EAAKC,SACP,OAAOC,QAAQC,OAAO,IAAItB,UAAU,iBAEtCmB,EAAKC,UAAW,CAClB,CAEA,SAASG,EAAgBC,GACvB,OAAO,IAAIH,SAAQ,SAASI,EAASH,GACnCE,EAAOE,OAAS,WACdD,EAAQD,EAAOG,OACjB,EACAH,EAAOI,QAAU,WACfN,EAAOE,EAAOK,MAChB,CACF,GACF,CAEA,SAASC,EAAsB/C,GAC7B,IAAIyC,EAAS,IAAIO,WACbC,EAAUT,EAAgBC,GAE9B,OADAA,EAAOS,kBAAkBlD,GAClBiD,CACT,CAEA,SAASE,EAAenD,GACtB,IAAIyC,EAAS,IAAIO,WACbC,EAAUT,EAAgBC,GAE9B,OADAA,EAAOW,WAAWpD,GACXiD,CACT,CAEA,SAASI,EAAsBC,GAI7B,IAHA,IAAIC,EAAO,IAAIC,WAAWF,GACtBG,EAAQ,IAAI1B,MAAMwB,EAAK7H,QAElBgI,EAAI,EAAGA,EAAIH,EAAK7H,OAAQgI,IAC/BD,EAAMC,GAAK3C,OAAO4C,aAAaJ,EAAKG,IAEtC,OAAOD,EAAMG,KAAK,GACpB,CAEA,SAASC,EAAYP,GACnB,GAAIA,EAAI7H,MACN,OAAO6H,EAAI7H,MAAM,GAEjB,IAAI8H,EAAO,IAAIC,WAAWF,EAAIQ,YAE9B,OADAP,EAAKQ,IAAI,IAAIP,WAAWF,IACjBC,EAAKS,MAEhB,CAEA,SAASC,IA0FP,OAzFAxG,KAAK4E,UAAW,EAEhB5E,KAAKyG,UAAY,SAAS9B,GACxB3E,KAAK0G,UAAY/B,EACZA,EAEsB,kBAATA,EAChB3E,KAAK2G,UAAYhC,EACRxC,EAAQI,MAAQC,KAAKpC,UAAU2C,cAAc4B,GACtD3E,KAAK4G,UAAYjC,EACRxC,EAAQO,UAAYmE,SAASzG,UAAU2C,cAAc4B,GAC9D3E,KAAK8G,cAAgBnC,EACZxC,EAAQC,cAAgB2E,gBAAgB3G,UAAU2C,cAAc4B,GACzE3E,KAAK2G,UAAYhC,EAAKvB,WACbjB,EAAQQ,aAAeR,EAAQI,MAAQK,EAAW+B,IAC3D3E,KAAKgH,iBAAmBZ,EAAYzB,EAAK4B,QAEzCvG,KAAK0G,UAAY,IAAIlE,KAAK,CAACxC,KAAKgH,oBACvB7E,EAAQQ,cAAgBO,YAAY9C,UAAU2C,cAAc4B,IAAS1B,EAAkB0B,IAChG3E,KAAKgH,iBAAmBZ,EAAYzB,GAEpC3E,KAAK2G,UAAYhC,EAAOtF,OAAOe,UAAUgD,SAAS/B,KAAKsD,GAhBvD3E,KAAK2G,UAAY,GAmBd3G,KAAKmE,QAAQ8C,IAAI,kBACA,kBAATtC,EACT3E,KAAKmE,QAAQmC,IAAI,eAAgB,4BACxBtG,KAAK4G,WAAa5G,KAAK4G,UAAUM,KAC1ClH,KAAKmE,QAAQmC,IAAI,eAAgBtG,KAAK4G,UAAUM,MACvC/E,EAAQC,cAAgB2E,gBAAgB3G,UAAU2C,cAAc4B,IACzE3E,KAAKmE,QAAQmC,IAAI,eAAgB,mDAGvC,EAEInE,EAAQI,OACVvC,KAAKuC,KAAO,WACV,IAAI4E,EAAWzC,EAAS1E,MACxB,GAAImH,EACF,OAAOA,EAGT,GAAInH,KAAK4G,UACP,OAAO/B,QAAQI,QAAQjF,KAAK4G,WACvB,GAAI5G,KAAKgH,iBACd,OAAOnC,QAAQI,QAAQ,IAAIzC,KAAK,CAACxC,KAAKgH,oBACjC,GAAIhH,KAAK8G,cACd,MAAM,IAAIlF,MAAM,wCAEhB,OAAOiD,QAAQI,QAAQ,IAAIzC,KAAK,CAACxC,KAAK2G,YAE1C,EAEA3G,KAAK2C,YAAc,WACjB,OAAI3C,KAAKgH,iBACAtC,EAAS1E,OAAS6E,QAAQI,QAAQjF,KAAKgH,kBAEvChH,KAAKuC,OAAO6E,KAAK9B,EAE5B,GAGFtF,KAAKqH,KAAO,WACV,IAAIF,EAAWzC,EAAS1E,MACxB,GAAImH,EACF,OAAOA,EAGT,GAAInH,KAAK4G,UACP,OAAOlB,EAAe1F,KAAK4G,WACtB,GAAI5G,KAAKgH,iBACd,OAAOnC,QAAQI,QAAQW,EAAsB5F,KAAKgH,mBAC7C,GAAIhH,KAAK8G,cACd,MAAM,IAAIlF,MAAM,wCAEhB,OAAOiD,QAAQI,QAAQjF,KAAK2G,UAEhC,EAEIxE,EAAQO,WACV1C,KAAK0C,SAAW,WACd,OAAO1C,KAAKqH,OAAOD,KAAKE,EAC1B,GAGFtH,KAAKuH,KAAO,WACV,OAAOvH,KAAKqH,OAAOD,KAAKI,KAAKC,MAC/B,EAEOzH,IACT,CA3MAkE,EAAQ9D,UAAUiE,OAAS,SAAS1C,EAAM9D,GACxC8D,EAAO0B,EAAc1B,GACrB9D,EAAQ6F,EAAe7F,GACvB,IAAI6J,EAAW1H,KAAKoE,IAAIzC,GACxB3B,KAAKoE,IAAIzC,GAAQ+F,EAAWA,EAAW,KAAO7J,EAAQA,CACxD,EAEAqG,EAAQ9D,UAAU,UAAY,SAASuB,UAC9B3B,KAAKoE,IAAIf,EAAc1B,GAChC,EAEAuC,EAAQ9D,UAAU6G,IAAM,SAAStF,GAE/B,OADAA,EAAO0B,EAAc1B,GACd3B,KAAK2H,IAAIhG,GAAQ3B,KAAKoE,IAAIzC,GAAQ,IAC3C,EAEAuC,EAAQ9D,UAAUuH,IAAM,SAAShG,GAC/B,OAAO3B,KAAKoE,IAAIwD,eAAevE,EAAc1B,GAC/C,EAEAuC,EAAQ9D,UAAUkG,IAAM,SAAS3E,EAAM9D,GACrCmC,KAAKoE,IAAIf,EAAc1B,IAAS+B,EAAe7F,EACjD,EAEAqG,EAAQ9D,UAAUb,QAAU,SAASJ,EAAU0I,GAC7C,IAAK,IAAIlG,KAAQ3B,KAAKoE,IAChBpE,KAAKoE,IAAIwD,eAAejG,IAC1BxC,EAASkC,KAAKwG,EAAS7H,KAAKoE,IAAIzC,GAAOA,EAAM3B,KAGnD,EAEAkE,EAAQ9D,UAAU0H,KAAO,WACvB,IAAIlE,EAAQ,GAIZ,OAHA5D,KAAKT,SAAQ,SAAS1B,EAAO8D,GAC3BiC,EAAMmE,KAAKpG,EACb,IACOgC,EAAYC,EACrB,EAEAM,EAAQ9D,UAAU4H,OAAS,WACzB,IAAIpE,EAAQ,GAIZ,OAHA5D,KAAKT,SAAQ,SAAS1B,GACpB+F,EAAMmE,KAAKlK,EACb,IACO8F,EAAYC,EACrB,EAEAM,EAAQ9D,UAAUd,QAAU,WAC1B,IAAIsE,EAAQ,GAIZ,OAHA5D,KAAKT,SAAQ,SAAS1B,EAAO8D,GAC3BiC,EAAMmE,KAAK,CAACpG,EAAM9D,GACpB,IACO8F,EAAYC,EACrB,EAEIzB,EAAQE,WACV6B,EAAQ9D,UAAUkC,OAAOuB,UAAYK,EAAQ9D,UAAUd,SAqJzD,IAAI2I,EAAU,CAAC,SAAU,MAAO,OAAQ,UAAW,OAAQ,OAE3D,SAASC,EAAgBC,GACvB,IAAIC,EAAUD,EAAOE,cACrB,OAAOJ,EAAQnH,QAAQsH,IAAY,EAAIA,EAAUD,CACnD,CAEA,SAASG,EAAQ7J,EAAOxB,GACtBA,EAAUA,GAAW,CAAC,EACtB,IAAI0H,EAAO1H,EAAQ0H,KAEnB,GAAIlG,aAAiB6J,EAAS,CAC5B,GAAI7J,EAAMmG,SACR,MAAM,IAAIpB,UAAU,gBAEtBxD,KAAKuI,IAAM9J,EAAM8J,IACjBvI,KAAKwI,YAAc/J,EAAM+J,YACpBvL,EAAQkH,UACXnE,KAAKmE,QAAU,IAAID,EAAQzF,EAAM0F,UAEnCnE,KAAKmI,OAAS1J,EAAM0J,OACpBnI,KAAKyI,KAAOhK,EAAMgK,KAClBzI,KAAK0I,OAASjK,EAAMiK,OACf/D,GAA2B,MAAnBlG,EAAMiI,YACjB/B,EAAOlG,EAAMiI,UACbjI,EAAMmG,UAAW,EAErB,MACE5E,KAAKuI,IAAMjF,OAAO7E,GAYpB,GATAuB,KAAKwI,YAAcvL,EAAQuL,aAAexI,KAAKwI,aAAe,eAC1DvL,EAAQkH,SAAYnE,KAAKmE,UAC3BnE,KAAKmE,QAAU,IAAID,EAAQjH,EAAQkH,UAErCnE,KAAKmI,OAASD,EAAgBjL,EAAQkL,QAAUnI,KAAKmI,QAAU,OAC/DnI,KAAKyI,KAAOxL,EAAQwL,MAAQzI,KAAKyI,MAAQ,KACzCzI,KAAK0I,OAASzL,EAAQyL,QAAU1I,KAAK0I,OACrC1I,KAAK2I,SAAW,MAEK,QAAhB3I,KAAKmI,QAAoC,SAAhBnI,KAAKmI,SAAsBxD,EACvD,MAAM,IAAInB,UAAU,6CAEtBxD,KAAKyG,UAAU9B,EACjB,CAMA,SAAS2C,EAAO3C,GACd,IAAIiE,EAAO,IAAI/B,SAYf,OAXAlC,EACGkE,OACAC,MAAM,KACNvJ,SAAQ,SAASwJ,GAChB,GAAIA,EAAO,CACT,IAAID,EAAQC,EAAMD,MAAM,KACpBnH,EAAOmH,EAAM/E,QAAQiF,QAAQ,MAAO,KACpCnL,EAAQiL,EAAM3C,KAAK,KAAK6C,QAAQ,MAAO,KAC3CJ,EAAKvE,OAAO4E,mBAAmBtH,GAAOsH,mBAAmBpL,GAC3D,CACF,IACK+K,CACT,CAEA,SAASM,EAAaC,GACpB,IAAIhF,EAAU,IAAID,EAGdkF,EAAsBD,EAAWH,QAAQ,eAAgB,KAS7D,OARAI,EAAoBN,MAAM,SAASvJ,SAAQ,SAAS8J,GAClD,IAAIC,EAAQD,EAAKP,MAAM,KACnBS,EAAMD,EAAMvF,QAAQ8E,OACxB,GAAIU,EAAK,CACP,IAAI1L,EAAQyL,EAAMnD,KAAK,KAAK0C,OAC5B1E,EAAQE,OAAOkF,EAAK1L,EACtB,CACF,IACOsG,CACT,CAIA,SAASqF,EAASC,EAAUxM,GACrBA,IACHA,EAAU,CAAC,GAGb+C,KAAKkH,KAAO,UACZlH,KAAK0J,YAA4BzF,IAAnBhH,EAAQyM,OAAuB,IAAMzM,EAAQyM,OAC3D1J,KAAK2J,GAAK3J,KAAK0J,QAAU,KAAO1J,KAAK0J,OAAS,IAC9C1J,KAAK4J,WAAa,eAAgB3M,EAAUA,EAAQ2M,WAAa,KACjE5J,KAAKmE,QAAU,IAAID,EAAQjH,EAAQkH,SACnCnE,KAAKuI,IAAMtL,EAAQsL,KAAO,GAC1BvI,KAAKyG,UAAUgD,EACjB,CAlDAnB,EAAQlI,UAAUyJ,MAAQ,WACxB,OAAO,IAAIvB,EAAQtI,KAAM,CAAC2E,KAAM3E,KAAK0G,WACvC,EAkCAF,EAAKnF,KAAKiH,EAAQlI,WAgBlBoG,EAAKnF,KAAKmI,EAASpJ,WAEnBoJ,EAASpJ,UAAUyJ,MAAQ,WACzB,OAAO,IAAIL,EAASxJ,KAAK0G,UAAW,CAClCgD,OAAQ1J,KAAK0J,OACbE,WAAY5J,KAAK4J,WACjBzF,QAAS,IAAID,EAAQlE,KAAKmE,SAC1BoE,IAAKvI,KAAKuI,KAEd,EAEAiB,EAASnE,MAAQ,WACf,IAAIyE,EAAW,IAAIN,EAAS,KAAM,CAACE,OAAQ,EAAGE,WAAY,KAE1D,OADAE,EAAS5C,KAAO,QACT4C,CACT,EAEA,IAAIC,EAAmB,CAAC,IAAK,IAAK,IAAK,IAAK,KAE5CP,EAASQ,SAAW,SAASzB,EAAKmB,GAChC,IAA0C,IAAtCK,EAAiBjJ,QAAQ4I,GAC3B,MAAM,IAAIO,WAAW,uBAGvB,OAAO,IAAIT,EAAS,KAAM,CAACE,OAAQA,EAAQvF,QAAS,CAAC+F,SAAU3B,IACjE,EAEAnL,EAAQ+M,aAAejI,EAAKiI,aAC5B,IACE,IAAI/M,EAAQ+M,YACd,CAAE,MAAOxK,GACPvC,EAAQ+M,aAAe,SAASC,EAASzI,GACvC3B,KAAKoK,QAAUA,EACfpK,KAAK2B,KAAOA,EACZ,IAAI0D,EAAQzD,MAAMwI,GAClBpK,KAAKqK,MAAQhF,EAAMgF,KACrB,EACAjN,EAAQ+M,aAAa/J,UAAYf,OAAOiL,OAAO1I,MAAMxB,WACrDhD,EAAQ+M,aAAa/J,UAAUpD,YAAcI,EAAQ+M,YACvD,CAEA,SAASI,EAAM9L,EAAO+L,GACpB,OAAO,IAAI3F,SAAQ,SAASI,EAASH,GACnC,IAAI2F,EAAU,IAAInC,EAAQ7J,EAAO+L,GAEjC,GAAIC,EAAQ/B,QAAU+B,EAAQ/B,OAAOgC,QACnC,OAAO5F,EAAO,IAAI1H,EAAQ+M,aAAa,UAAW,eAGpD,IAAIQ,EAAM,IAAIC,eAEd,SAASC,IACPF,EAAIG,OACN,CAEAH,EAAIzF,OAAS,WACX,IAAIjI,EAAU,CACZyM,OAAQiB,EAAIjB,OACZE,WAAYe,EAAIf,WAChBzF,QAAS+E,EAAayB,EAAII,yBAA2B,KAEvD9N,EAAQsL,IAAM,gBAAiBoC,EAAMA,EAAIK,YAAc/N,EAAQkH,QAAQ8C,IAAI,iBAC3E,IAAItC,EAAO,aAAcgG,EAAMA,EAAIb,SAAWa,EAAIM,aAClDhG,EAAQ,IAAIuE,EAAS7E,EAAM1H,GAC7B,EAEA0N,EAAIvF,QAAU,WACZN,EAAO,IAAItB,UAAU,0BACvB,EAEAmH,EAAIO,UAAY,WACdpG,EAAO,IAAItB,UAAU,0BACvB,EAEAmH,EAAIQ,QAAU,WACZrG,EAAO,IAAI1H,EAAQ+M,aAAa,UAAW,cAC7C,EAEAQ,EAAIS,KAAKX,EAAQtC,OAAQsC,EAAQlC,KAAK,GAEV,YAAxBkC,EAAQjC,YACVmC,EAAIU,iBAAkB,EACW,SAAxBZ,EAAQjC,cACjBmC,EAAIU,iBAAkB,GAGpB,iBAAkBV,GAAOxI,EAAQI,OACnCoI,EAAIW,aAAe,QAGrBb,EAAQtG,QAAQ5E,SAAQ,SAAS1B,EAAO8D,GACtCgJ,EAAIY,iBAAiB5J,EAAM9D,EAC7B,IAEI4M,EAAQ/B,SACV+B,EAAQ/B,OAAO8C,iBAAiB,QAASX,GAEzCF,EAAIc,mBAAqB,WAEA,IAAnBd,EAAIe,YACNjB,EAAQ/B,OAAOiD,oBAAoB,QAASd,EAEhD,GAGFF,EAAIiB,KAAkC,qBAAtBnB,EAAQ/D,UAA4B,KAAO+D,EAAQ/D,UACrE,GACF,CAEA6D,EAAMsB,UAAW,EAEZ3J,EAAKqI,QACRrI,EAAKqI,MAAQA,EACbrI,EAAKgC,QAAUA,EACfhC,EAAKoG,QAAUA,EACfpG,EAAKsH,SAAWA,GAGlBpM,EAAQ8G,QAAUA,EAClB9G,EAAQkL,QAAUA,EAClBlL,EAAQoM,SAAWA,EACnBpM,EAAQmN,MAAQA,EAEhBlL,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,GAIvD,EAhhBgB,CAghBd,CAAC,EACH,EAnhBD,CAmhBmB,qBAATqE,KAAuBA,KAAOlC,K,qCClhBxC,IAAI+L,EAAmB/L,MAAQA,KAAK+L,kBAAqB1M,OAAOiL,OAAS,SAAU0B,EAAGC,EAAGC,EAAGC,QAC7ElI,IAAPkI,IAAkBA,EAAKD,GAC3B,IAAIE,EAAO/M,OAAOgN,yBAAyBJ,EAAGC,GACzCE,KAAS,QAASA,GAAQH,EAAEK,WAAaF,EAAKG,UAAYH,EAAKI,gBAClEJ,EAAO,CAAEK,YAAY,EAAMxF,IAAK,WAAa,OAAOgF,EAAEC,EAAI,IAE5D7M,OAAOyM,eAAeE,EAAGG,EAAIC,EAChC,EAAI,SAAUJ,EAAGC,EAAGC,EAAGC,QACTlI,IAAPkI,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,EACb,GACGQ,EAAgB1M,MAAQA,KAAK0M,cAAiB,SAAST,EAAG7O,GAC1D,IAAK,IAAIuP,KAAKV,EAAa,YAANU,GAAoBtN,OAAOe,UAAUwH,eAAevG,KAAKjE,EAASuP,IAAIZ,EAAgB3O,EAAS6O,EAAGU,EAC3H,EACAtN,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtD6O,EAAa,EAAQ,OAAwBtP,GAC7CsP,EAAa,EAAQ,OAAqBtP,GAC1CsP,EAAa,EAAQ,OAA8BtP,GACnDsP,EAAa,EAAQ,OAA0BtP,GAC/CsP,EAAa,EAAQ,OAAwBtP,GAC7CsP,EAAa,EAAQ,OAAkCtP,GACvDsP,EAAa,EAAQ,OAAetP,E,qCCrBpCiC,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQwP,mBAAgB,EACxB,EAAQ,OACR,MAAMC,EAA6B,EAAQ,OACrCC,EAAe,EAAQ,OACvBC,EAAwB,EAAQ,OAChCC,EAA4B,EAAQ,OACpCC,EAAS,EAAQ,OAIvB,MAAML,EACF,WAAA5P,CAAYC,GACRA,EAAUA,GAAW,CAAC,EACtB+C,KAAKkN,eAAiBjQ,EAAQiQ,gBAAkB,IAAIH,EAAsBI,oBAC1EnN,KAAKoN,cAAgB,CAAC,EACtBpN,KAAKqN,iBAAmBpQ,EAAQqQ,eAChCtN,KAAKuN,0BAA4BtQ,EAAQsQ,wBACzCvN,KAAKwN,yBAA2BvQ,EAAQuQ,0BAA4B,GACpExN,KAAKyN,yBAAyB,2BAA4BxQ,MAAYA,EAAQwQ,sBAClF,CAUA,uBAAOC,CAAiB7P,EAAO8P,EAAaC,GACxC,GAAqB,kBAAV/P,EACP,MAAM,IAAIiP,EAAae,WAAW,sDAAsDrG,KAAKsG,UAAUjQ,MAAW+P,GAEtH,IAAKX,EAAOc,KAAKC,mBAAmBzK,KAAK1F,GAAQ,CAC7C,GAAI8P,EACA,MAAM,IAAIb,EAAae,WAAW,kEAAkErG,KAAKsG,UAAUjQ,MAAW+P,GAG9H,OAAO,CAEf,CACA,OAAO,CACX,CASA,wBAAOK,CAAkBpQ,EAAOqQ,GAC5B,GAAqB,kBAAVrQ,EACP,MAAM,IAAIiP,EAAae,WAAW,uDAAuDrG,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYC,wBAEhJ,IAAKnB,EAAOc,KAAKM,oBAAoB9K,KAAK1F,GAAQ,CAC9C,GAAIqQ,EACA,MAAM,IAAIpB,EAAae,WAAW,6DAA6DrG,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYC,wBAGlJ,OAAO,CAEf,CACA,OAAO,CACX,CAMA,iBAAAE,CAAkB3P,GACd,IAAK,MAAM4K,KAAOlK,OAAOyI,KAAKnJ,GAAU,CACpC,IAAId,EAAQc,EAAQ4K,GACpB,GAAI1L,GAA0B,kBAAVA,GACZA,EAAM,cAAgBA,EAAM,OAAQ,CACpC,GAAiC,kBAAtBA,EAAM,aAA4BoP,EAAOc,KAAKQ,eAAe1Q,EAAM,aAC1E,MAAM,IAAIiP,EAAae,WAAW,gEAAgEhQ,EAAM,eAAgBiP,EAAaqB,YAAYK,qBAErJ3Q,EAAQc,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGnE,GAAQ,CAAE,MAAOA,EAAM,cAC9EA,EAAM,OAASA,EAAM,YACjBoP,EAAOc,KAAKU,mBAAmB5Q,EAAM,oBAC9BA,EAAM,YAGbA,EAAM,aAAc,CAE5B,CAER,CACA,OAAOc,CACX,CASA,mBAAA+P,CAAoB/P,EAAS4O,EAAyBzF,GAClD,MAAM6G,EAAahQ,EAAQiQ,gBAC3B,IAAK,MAAMrF,KAAQzB,GAAQzI,OAAOyI,KAAK6G,GAEnC,GAAI1B,EAAOc,KAAKc,sBAAsB/N,QAAQyI,GAAO,IAAM0D,EAAOc,KAAKe,0BAA0BvF,GAAM,CAEnG,MAAMwF,EAAWJ,EAAWpF,GAC5B,GAAI0D,EAAOc,KAAKU,mBAAmBlF,IAAQ0D,EAAOc,KAAKiB,uBAAuBlO,QAAQyI,IAAQ,IAC9E,UAARA,GAA8C,kBAApBoF,EAAWpF,KAChCoF,EAAWpF,GAAK,eAAmD,SAAlCoF,EAAWpF,GAAK,eACtD,MAAM,IAAIuD,EAAae,WAAW,iEAC1CtE,QAAU/B,KAAKsG,UAAUiB,KAAajC,EAAaqB,YAAYc,sBAI/D,GAAIhC,EAAOc,KAAKmB,sBAAsBpO,QAAQmM,EAAOc,KAAKoB,kBAAkBJ,KAAc,EACtF,MAAM,IAAIjC,EAAae,WAAW,+DACtCtE,QAAU/B,KAAKsG,UAAUiB,KAAajC,EAAaqB,YAAYiB,uBAG/D,GAAIL,GAAY9B,EAAOc,KAAKU,mBAAmBxB,EAAOc,KAAKoB,kBAAkBJ,MAC9C,IAAxBA,EAAS,WACZ,MAAM,IAAIjC,EAAae,WAAW,4CAA4CtE,QAAU/B,KAAKsG,UAAUiB,MAAcjC,EAAaqB,YAAYkB,yBAGlJ,MAAOpC,EAAOc,KAAKuB,cAAcX,EAAWpF,IAAO,CAC/C,MAAM1L,EAAQ8Q,EAAWpF,GACzB,IAAIgG,GAAU,EACd,GAAqB,kBAAV1R,EACP8Q,EAAWpF,GAAO5K,EAAQ6Q,WAAW3R,GAAO,GAC5C0R,EAAUA,GAAW1R,IAAU8Q,EAAWpF,OAEzC,CACD,MAAMxJ,EAAKlC,EAAM,OACXqJ,EAAOrJ,EAAM,SAEb4R,IAAkB,YAAa5R,IAAUoP,EAAOc,KAAK2B,WAAWnG,GACtE,GAAI,QAAS1L,OAEEoG,IAAPlE,GAA2B,OAAPA,GAA6B,kBAAPA,IAC1C4O,EAAWpF,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG2M,EAAWpF,IAAO,CAAE,MAAO5K,EAAQ6Q,WAAWzP,GAAI,KACpGwP,EAAUA,GAAWxP,IAAO4O,EAAWpF,GAAK,aAG/C,IAAK0D,EAAOc,KAAKU,mBAAmBlF,IAAQkG,EAAe,CAE5D,MAAME,EAAQhR,EAAQ6Q,WAAWjG,GAAK,GAClCoG,IAAUpG,IAEVoF,EAAWpF,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG2M,EAAWpF,IAAO,CAAE,MAAOoG,IAC7EJ,GAAU,EAElB,CACA,GAAIrI,GAAwB,kBAATA,GAA8B,WAATA,KAC/BrJ,EAAM,gBAAkBA,EAAM,cAAc,WAC9C4R,EAAe,CAElB,IAAIG,EAAejR,EAAQ6Q,WAAWtI,GAAM,GACxCqG,GAA2BrG,IAAS0I,IACpCA,EAAejR,EAAQ6Q,WAAWtI,GAAM,IAExC0I,IAAiB1I,IACjBqI,GAAU,EACVZ,EAAWpF,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG2M,EAAWpF,IAAO,CAAE,QAASqG,IAEvF,CACJ,CACA,IAAKL,EACD,KAER,CACJ,CAER,CAMA,SAAAM,CAAUlR,GAAS,eAAEmR,EAAc,sBAAEC,IAEjC,GAAIA,GAA4C,IAAnBD,EACzB,IAAK,MAAMvG,KAAOlK,OAAOyI,KAAKnJ,GAC1B,GAAY,cAAR4K,GAA+C,kBAAjB5K,EAAQ4K,GACtC5K,EAAQ4K,GAAO5K,EAAQ4K,GAAK9F,kBAE3B,CACD,MAAM5F,EAAQc,EAAQ4K,GACtB,GAAI1L,GAA0B,kBAAVA,GACkB,kBAAvBA,EAAM,aAA2B,CACxC,MAAMmS,EAAYnS,EAAM,aAAa4F,cACjCuM,IAAcnS,EAAM,eACpBc,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGnE,GAAQ,CAAE,YAAamS,IAE9E,CAER,CAGZ,CAKA,gBAAAC,CAAiBtR,GACb,IAAK,MAAM4K,KAAOlK,OAAOyI,KAAKnJ,GAAU,CACpC,MAAMd,EAAQc,EAAQ4K,GACtB,GAAI1L,GAA0B,kBAAVA,EAChB,GAAmC,kBAAxBA,EAAM,cACbc,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGnE,GAAQ,CAAE,aAAc,CAAE,CAACA,EAAM,gBAAgB,UAE/F,GAAIyG,MAAMC,QAAQ1G,EAAM,eAAgB,CACzC,MAAMqS,EAAW,CAAC,EAClB,IAAK,MAAMC,KAAkBtS,EAAM,cAC/BqS,EAASC,IAAkB,EAE/BxR,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGnE,GAAQ,CAAE,aAAcqS,GAC3E,CAER,CACJ,CAMA,oBAAAE,CAAqBzR,GAAS,eAAEmR,GAAkBO,GAC9C,GAAIP,GAAkBA,GAAkB,KAChCnR,EAAQ,cAAe,CACvB,IAAK,MAAM4K,KAAOlK,OAAOyI,KAAKnJ,GAC1B,IAAIsO,EAAOc,KAAKe,0BAA0BvF,KAGrC0D,EAAOc,KAAKU,mBAAmBlF,KAAS0D,EAAOc,KAAKuC,gBAAgB3R,EAAS4K,GAAM,CACpF,MAAM1L,EAAQc,EAAQ4K,GAClB1L,GAA0B,kBAAVA,EACV,eAAgBc,EAAQ4K,KAE1B5K,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGrD,EAAQ4K,IAAO,CAAE,cAAc,MAKlF5K,EAAQ4K,GAAO,CACX,MAAO1L,EACP,cAAc,GAEdoP,EAAOc,KAAKwC,6BAA6B1S,EAAOwS,KAChD1R,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGrD,EAAQ4K,IAAO,CAAE,WAAW,KAGvF,QAEG5K,EAAQ,aACnB,CAER,CASA,4BAAA6R,CAA6BC,EAAeC,EAAcL,EAAevI,GACrE,IAAK,MAAMyB,KAAiB,OAATzB,QAA0B,IAATA,EAAkBA,EAAOzI,OAAOyI,KAAK4I,GACrE,GAAIzD,EAAOc,KAAKuC,gBAAgBG,EAAelH,KAIV,kBAAtBmH,EAAanH,GACpBmH,EAAanH,GAAO,CAAE,MAAOmH,EAAanH,GAAM,cAAc,GAM9DmH,EAAanH,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG0O,EAAanH,IAAO,CAAE,cAAc,KAGvF0D,EAAOc,KAAK4C,UAAUF,EAAclH,GAAMmH,EAAanH,KACxD,MAAM,IAAIuD,EAAae,WAAW,+CAA+CtE,UAAY/B,KAAKsG,UAAUb,EAAOc,KAAKoB,kBAAkBsB,EAAclH,WAAa/B,KAAKsG,UAAUb,EAAOc,KAAKoB,kBAAkBuB,EAAanH,OAAUuD,EAAaqB,YAAYyC,4BAIlR,CAMA,QAAAC,CAASlS,GAAS,eAAEmR,IAChB,IAAK,MAAMvG,KAAOlK,OAAOyI,KAAKnJ,GAAU,CAEpC,GAAIsO,EAAOc,KAAKe,0BAA0BvF,GACtC,SAGJ,GAAY,KAARA,EACA,MAAM,IAAIuD,EAAae,WAAW,wCAAwCtE,QAAU/B,KAAKsG,UAAUnP,EAAQ4K,OAAUuD,EAAaqB,YAAYkB,yBAElJ,MAAMxR,EAAQc,EAAQ4K,GAChBuH,SAAmBjT,EAEzB,GAAIoP,EAAOc,KAAKU,mBAAmBlF,GAAnC,CACI,OAAQA,EAAIwH,OAAO,IACf,IAAK,QACD,GAAc,OAAVlT,GAAgC,WAAdiT,EAClB,MAAM,IAAIhE,EAAae,WAAW,gCAAgChQ,IAASiP,EAAaqB,YAAY6C,uBAExG,MACJ,IAAK,OACD,GAAc,OAAVnT,GAAgC,WAAdiT,EAClB,MAAM,IAAIhE,EAAae,WAAW,+BAA+BlP,EAAQ4K,KAAQuD,EAAaqB,YAAY8C,kBAE9G,MACJ,IAAK,WACa,OAAVpT,GACA+O,EAAcc,iBAAiB7P,GAAO,EAAMiP,EAAaqB,YAAY+C,0BAEzE,MACJ,IAAK,UACD,GAAc,OAAVrT,GAAgC,WAAdiT,EAClB,MAAM,IAAIhE,EAAae,WAAW,qCAAqChQ,IAASiP,EAAaqB,YAAYgD,uBAE7G,MACJ,IAAK,YACa,OAAVtT,GACA+O,EAAcqB,kBAAkBpQ,GAAO,GAE3C,MACJ,IAAK,YACD,GAAuB,IAAnBiS,EACA,MAAM,IAAIhD,EAAae,WAAW,wCAAwChQ,IAASiP,EAAaqB,YAAYiD,uBAEhH,GAAc,OAAVvT,GAAgC,YAAdiT,EAClB,MAAM,IAAIhE,EAAae,WAAW,sCAAsChQ,IAASiP,EAAaqB,YAAYkD,yBAE9G,MAGR,GAAIpE,EAAOc,KAAKQ,eAAehF,IAAQ0D,EAAOc,KAAKQ,eAAetB,EAAOc,KAAKoB,kBAAkBtR,IAC5F,MAAM,IAAIiP,EAAae,WAAW,gDAAgDtE,QAAU0D,EAAOc,KAC9FoB,kBAAkBtR,MAAWiP,EAAaqB,YAAYc,qBAGnE,MAEA,GAAc,OAAVpR,EACA,OAAQiT,GACJ,IAAK,SACD,GAAI7D,EAAOc,KAAKuD,UAAUzT,EAAOc,KAAa4K,EAC1C,MAAM,IAAIuD,EAAae,WAAW,oDAAoDtE,QAAU/B,KAC3FsG,UAAUjQ,MAAWiP,EAAaqB,YAAYoD,oBAEvD,GAAItE,EAAOc,KAAKyD,eAAejI,GAAM,CACjC,GAAc,UAAV1L,EACA,MAAM,IAAIiP,EAAae,WAAW,4CAA4CtE,QAAU1L,KAAUiP,EAAaqB,YAAYK,qBAE1H,GAAIvB,EAAOc,KAAK2B,WAAW7R,IAAUA,IAAU,IAAImP,EAA0ByE,wBAAwB9S,GAAS6Q,WAAWjG,GAC1H,MAAM,IAAIuD,EAAae,WAAW,iDAAiDtE,QAAU1L,KAAUiP,EAAaqB,YAAYK,oBAExI,CACA,MACJ,IAAK,SACD,IAAKvB,EAAOc,KAAK2D,aAAanI,MAAU,QAAS1L,KACtB,QAAnBA,EAAM,UAAsBc,EAAQ,UAAYA,EAAQ,WAC5D,MAAM,IAAImO,EAAae,WAAW,kCAAkCtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYK,qBAErI,IAAK,MAAMmD,KAAatS,OAAOyI,KAAKjK,GAAQ,CACxC,MAAM+T,EAAc/T,EAAM8T,GAC1B,GAAKC,EAGL,OAAQD,GACJ,IAAK,MACD,GAAI1E,EAAOc,KAAKQ,eAAeqD,IACR,UAAhBA,GAA2C,QAAhBA,GAAyC,WAAhBA,GAA4C,UAAhBA,EACnF,MAAM,IAAI9E,EAAae,WAAW,gDAAgDtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYK,qBAEnJ,GAAIvB,EAAOc,KAAKyD,eAAejI,GAAM,CACjC,GAAoB,UAAhBqI,EACA,MAAM,IAAI9E,EAAae,WAAW,4CAA4CtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYK,qBAE1I,GAAIvB,EAAOc,KAAK2B,WAAWkC,IACzBA,IAAgB,IAAI5E,EAA0ByE,wBAAwB9S,GAAS6Q,WAAWjG,GAC7F,MAAM,IAAIuD,EAAae,WAAW,iDAAiDtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYK,oBAExJ,CACA,GAA2B,kBAAhBoD,EACP,MAAM,IAAI9E,EAAae,WAAW,8CAA8CtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYK,qBAEjJ,GAAIvB,EAAOc,KAAKuD,UAAUM,EAAajT,KAAa4K,EAChD,MAAM,IAAIuD,EAAae,WAAW,oDAAoDtE,QAAU/B,KAC3FsG,UAAUjQ,MAAWiP,EAAaqB,YAAYoD,oBAEvD,MACJ,IAAK,QACD,GAA4B,UAAxB1T,EAAM,eAA6C,QAAhB+T,GAAyC,WAAhBA,EAC5D,MAAM,IAAI9E,EAAae,WAAW,iEAAiEtE,QAAUqI,KAAgB9E,EAAaqB,YAAY0D,sBAE1J,GAA2B,kBAAhBD,EACP,MAAM,IAAI9E,EAAae,WAAW,kDAAkDrG,KAAKsG,UAAUgD,MAAehE,EAAaqB,YAAY0D,sBAE/I,GAAoB,QAAhBD,GAAyC,WAAhBA,IACF,IAAnB9B,GAA0C,UAAhB8B,KACP,IAAnB9B,GAA0C,UAAhB8B,KACP,MAAnBA,EAAY,KAAe3E,EAAOc,KAAK2B,WAAWkC,IACtD,MAAM,IAAI9E,EAAae,WAAW,oDAAoDtE,QAAUqI,KAAgB9E,EAAaqB,YAAY0D,sBAE7I,MACJ,IAAK,WACD,GAA2B,kBAAhBD,GAA4B/T,EAAM,QAAUA,EAAM,SAAW+T,EACpE,MAAM,IAAI9E,EAAae,WAAW,uDAAuDtE,OAC9HqI,WAAqB/T,EAAM,UAAWiP,EAAaqB,YAAY2D,0BAE9B,GAAI,UAAWjU,EACX,MAAM,IAAIiP,EAAae,WAAW,iDAAiDtE,KAAQuD,EAAaqB,YAAY2D,0BAExH,MACJ,IAAK,aACD,GAAuB,IAAnBhC,IACIzQ,OAAOyI,KAAK8J,GAAa3T,OAAS,GAC/BgP,EAAOc,KAAKgE,eAAejR,QAAQzB,OAAOyI,KAAK8J,GAAa,IAAM,GACrE,MAAM,IAAI9E,EAAae,WAAW,gCAAgCtE,QAAUlK,OAAOyI,KAAK8J,oCAC9G3E,EAAOc,KAAKgE,eAAe5L,KAAK,QAAS2G,EAAaqB,YAAY6D,2BAGpD,IAAK,MAAM7B,KAAkB9Q,OAAOyI,KAAK8J,GAAc,CACnD,GAAuB,UAAnBzB,GAA8BtS,EAAM,YACpC,MAAM,IAAIiP,EAAae,WAAW,6EAA6EtE,KAAQuD,EAAaqB,YAAY2D,0BAEpJ,GAAI7E,EAAOc,KAAKkE,WAAWnR,QAAQqP,GAAkB,EACjD,MAAM,IAAIrD,EAAae,WAAW,gCAAgCtE,QAAU4G,uBACvGlD,EAAOc,KAAKkE,WAAW9L,KAAK,QAAS2G,EAAaqB,YAAY6D,0BAE3C,CACA,MACJ,IAAK,YACDpF,EAAcc,iBAAiBkE,GAAa,EAAM9E,EAAaqB,YAAY+D,0BAC3E,MACJ,IAAK,aACDtF,EAAcqB,kBAAkB2D,GAAa,GAC7C,MACJ,IAAK,UACD,GAAoB,OAAhBA,GAA+C,mBAAhBA,EAC/B,MAAM,IAAI9E,EAAae,WAAW,8CAA8CtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYgE,sBAEjJ,KAAM,QAAStU,KAAWoP,EAAOc,KAAK2B,WAAWnG,GAC7C,MAAM,IAAIuD,EAAae,WAAW,mCAAmCtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYkB,yBAEtI,MACJ,IAAK,SACD,GAAuB,IAAnBS,IAA2BjS,EAAM,gBAAkBA,EAAM,cAAc,UACvE,MAAM,IAAIiP,EAAae,WAAW,gDAAgDtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYkB,yBAEnJ,MACJ,IAAK,QACD,GAAIpC,EAAOc,KAAKU,mBAAmBmD,IAAgC,UAAhBA,EAC/C,MAAM,IAAI9E,EAAae,WAAW,0CAA0CtE,QAAU/B,KAAKsG,UAAUjQ,MAAWiP,EAAaqB,YAAYiE,oBAGzJ,CACA,MACJ,QACI,MAAM,IAAItF,EAAae,WAAW,iCAAiCtE,QAAU1L,KAAUiP,EAAaqB,YAAYkB,yBAGhI,CACJ,CAQA,cAAAgD,CAAe1T,EAAS1B,EAASqV,GAE7B,MAAuB,kBAAZ3T,IAIP2T,KAAuB,UAAW3T,IAAY1B,EAAQsV,eAClB,kBAA1BtV,EAAQsV,eAA8B,UAAWtV,EAAQsV,gBACnE5T,EAAQ,SAAW1B,EAAQsV,cAAc,SACrCtV,EAAQsV,cAAc,qBACtB5T,EAAQ,oBAAqB,IAIjC1B,EAAQyB,UAAYzB,EAAQuV,WACtB,UAAW7T,EAKa,OAArBA,EAAQ,UAAiD,kBAArBA,EAAQ,UAC7CsO,EAAOc,KAAK2B,WAAW/Q,EAAQ,YAEnCA,EAAQ,UAAW,EAAIkO,EAA2B5H,SAAStG,EAAQ,SAAU1B,EAAQsV,eAAiBtV,EAAQsV,cAAc,UAAYtV,EAAQyB,WANhJC,EAAQ,SAAW1B,EAAQyB,QAC3BC,EAAQ,oBAAqB,KAf1BA,CAwBf,CAOA,mBAAA8T,CAAoBC,EAAYhU,GAC5B,IAAKuO,EAAOc,KAAK2B,WAAWgD,GACxB,IACIA,GAAa,EAAI7F,EAA2B5H,SAASyN,EAAYhU,EACrE,CACA,MAAOiU,GACH,MAAM,IAAI/Q,MAAM,wBAAwB8Q,IAC5C,CAMJ,OAHI1S,KAAKyN,wBAA0BiF,EAAW5U,WAAW,uBACrD4U,EAAa,uBAEVA,CACX,CASA,wBAAME,CAAmBjU,EAAS1B,EAAS6K,GACvC,IAAK,MAAMyB,KAAiB,OAATzB,QAA0B,IAATA,EAAkBA,EAAOzI,OAAOyI,KAAKnJ,GAAW,CAChF,MAAMd,EAAQc,EAAQ4K,GACtB,GAAI1L,GAA0B,kBAAVA,GACZ,aAAcA,GAA+B,OAAtBA,EAAM,cAAyBZ,EAAQ4V,qBAAsB,CAMpF,GAAI7S,KAAKqN,gBACL,IACI,MAAMkF,EAAgBlT,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGrD,GAAU,CAAE,CAAC4K,GAAMlK,OAAO2C,OAAO,CAAC,EAAGrD,EAAQ4K,aAC5FgJ,EAAchJ,GAAK,kBACpBvJ,KAAKyH,MAAM5J,EAAM,YAAawB,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG/E,GAAU,CAAEuV,UAAU,EAAOD,gBAAeO,kBAAkB,EAAMC,4BAA4B,EAAMF,sBAAsB,IACpM,CACA,MAAOpQ,GACH,MAAM,IAAIqK,EAAae,WAAWpL,EAAE2H,QAAS0C,EAAaqB,YAAY6E,uBAC1E,CAEJrU,EAAQ4K,GAAOlK,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGnE,GAAQ,CAAE,kBAAmBmC,KAAKyH,MAAM5J,EAAM,YAAawB,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG/E,GAAU,CAAEuV,UAAU,EAAOS,mBAAmB,EAAMF,4BAA4B,EAAMR,cAAe5T,MACxOiQ,iBACb,CAER,CACA,OAAOjQ,CACX,CACA,WAAM8I,CAAM9I,EAAS1B,EAAU,CAAC,EAGhCiW,EAAkB,CAAC,GACf,MAAM,QAAExU,EAAO,cAAE6T,EAAa,SAAEC,EAAQ,eAAE1C,EAAiBlD,EAAcuG,wBAAuB,sBAAEpD,EAAqB,iBAAE+C,EAAgB,kBAAEG,GAAuBhW,EAC5JmW,EAAiBnW,EAAQmW,gBAAkB,CAAC,EAElD,GAAI/T,OAAOyI,KAAKsL,GAAgBnV,QAAU+B,KAAKwN,yBAC3C,MAAM,IAAIV,EAAae,WAAW,sDAAwDxO,OAAOyI,KAAKsL,GAAiBtG,EAAaqB,YAAYkF,kBAEpJ,GAAgB,OAAZ1U,QAAgCsF,IAAZtF,EAAuB,CAE3C,IAAKmU,GAAoBP,GAAiBtF,EAAOc,KAAKuF,kBAAkBf,GACpE,MAAM,IAAIzF,EAAae,WAAW,yDAA0Df,EAAaqB,YAAYoF,+BAGzH,OAAO,IAAIvG,EAA0ByE,wBAAwBzR,KAAKqS,eAAe,CAAC,EAAGpV,GAAS,GAClG,CACK,GAAuB,kBAAZ0B,EAAsB,CAClC,MAAM+T,EAAa1S,KAAKyS,oBAAoB9T,EAASD,GAC/C8U,EAAiBxT,KAAKyT,kBAAkBf,EAAYzV,GAC1D,GAAIuW,EACA,OAAO,IAAIxG,EAA0ByE,wBAAwB+B,GAEjE,MAAME,QAA4B1T,KAAKyH,YAAYzH,KAAK2T,KAAKjB,GAAarT,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG/E,GAAU,CAAEyB,QAASgU,EAAYF,UAAU,EAAMY,eAAgB/T,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGoR,GAAiB,CAAE,CAACV,IAAa,OAE5O,OADA1S,KAAKqS,eAAeqB,EAAoB9E,gBAAiB3R,GAAS,GAC3DyW,CACX,CACK,GAAIpP,MAAMC,QAAQ5F,GAAU,CAE7B,MAAMiV,EAAc,GACdC,QAAiBhP,QAAQiP,IAAInV,EAAQyF,KAAI,CAAC2P,EAAY9N,KACxD,GAA0B,kBAAf8N,EAAyB,CAChC,MAAMrB,EAAa1S,KAAKyS,oBAAoBsB,EAAYrV,GACxDkV,EAAY3N,GAAKyM,EACjB,MAAMc,EAAiBxT,KAAKyT,kBAAkBf,EAAYzV,GAC1D,OAAIuW,GAGGxT,KAAK2T,KAAKjB,EACrB,CAEI,OAAOqB,CACX,KAGJ,GAAId,EACA,OAAO,IAAIjG,EAA0ByE,wBAAwBoC,GAEjE,MAAMG,QAAwBH,EAASI,QAAO,CAACC,EAAmBC,EAAclO,IAAMiO,EACjF9M,MAAMgN,GAAepU,KAAKyH,MAAM0M,EAAc9U,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAG/E,GAAU,CAAEyB,QAASkV,EAAY3N,IAAMhJ,EAAQyB,QAAS8T,WAAYoB,EAAY3N,IAAMhJ,EAAQuV,SAAUD,cAAe6B,EAAWxF,gBAAiBwE,eAAgBQ,EAAY3N,GAAK5G,OAAO2C,OAAO3C,OAAO2C,OAAO,CAAC,EAAGoR,GAAiB,CAAE,CAACQ,EAAY3N,KAAK,IAAUmN,IAEtV,CACI9F,eAAgBrH,EAAI4N,EAAS5V,OAAS,OACrC4G,QAAQI,QAAQ,IAAI+H,EAA0ByE,wBAAwBc,GAAiB,CAAC,KAG7F,OADAvS,KAAKqS,eAAe2B,EAAgBpF,gBAAiB3R,GAAS,GACvD+W,CACX,CACK,GAAuB,kBAAZrV,EAAsB,CAClC,GAAI,aAAcA,EACd,aAAaqB,KAAKyH,MAAM9I,EAAQ,YAAa1B,GAcjD,GAXA0B,EAAUU,OAAO2C,OAAO,CAAC,EAAGrD,GAExB6T,UACO7T,EAAQ,SAGnBqB,KAAKqS,eAAe1T,EAAS1B,GAAS,GAGtC+C,KAAKiQ,iBAAiBtR,GAElBsU,EACA,OAAO,IAAIjG,EAA0ByE,wBAAwB9S,GAGjE,IAAI0V,EAAgB,CAAC,EACrB,GAAI,YAAa1V,EAAS,CACtB,KAAImR,GAAkB,KAUlB,MAAM,IAAIhD,EAAae,WAAW,oDAAqDf,EAAaqB,YAAYiD,uBARhH,GAAkC,kBAAvBzS,EAAQ,WACf,MAAM,IAAImO,EAAae,WAAW,qDAAuDlP,EAAQ,WAAYmO,EAAaqB,YAAYmG,sBAG1ID,QAAsBrU,KAAKuU,kBAAkBvU,KAAKyS,oBAAoB9T,EAAQ,WAAYD,WACnFC,EAAQ,UAKvB,CACAqB,KAAKoQ,qBAAqBiE,EAAe,CAAEvE,kBAAkB9C,EAA0BwH,sBACvF,MAAMC,EAAapV,OAAO2C,OAAOqS,EAAe1V,GAEhDqB,KAAKsO,kBAAkBmG,GACvBzU,KAAK6P,UAAU4E,EAAY,CAAE3E,iBAAgBC,0BAC7C/P,KAAKoQ,qBAAqBqE,EAAY,CAAE3E,kBAAkB9C,EAA0BwH,sBACpF,MAAM1M,EAAOzI,OAAOyI,KAAK2M,GACnBC,EAAkB,GACxB,GAA6B,kBAAlBnC,EAEP,IAAK,MAAMhJ,KAAOgJ,EACVhJ,KAAOkL,EACPC,EAAgB3M,KAAKwB,GAGrBkL,EAAWlL,GAAOgJ,EAAchJ,SAKtCvJ,KAAK4S,mBAAmB6B,EAAYxX,EAAS6K,GACnD,MAAM6M,EAAoB,IAAI3H,EAA0ByE,wBAAwBgD,GAoBhF,OAlBKA,GAAcA,EAAW,aAAe7H,EAAcuG,0BAA4B,MAC9ExU,EAAQ,WAA0C,kBAAtBA,EAAQ,WAAiD,KAAtBA,EAAQ,aACxE4T,GAAiB,WAAYA,GAAiB5T,EAAQ,UAAUmC,QAAQ,KAAO,EAC/E2T,EAAW,UAAYlC,EAAc,UAAY5T,EAAQ,WAEpDsO,EAAOc,KAAK2D,aAAa/S,EAAQ,YAAcA,EAAQ,YAAa8V,KAEzEA,EAAW,UAAYE,EAAkBnF,WAAW7Q,EAAQ,WAAW,KAG/EqB,KAAK0O,oBAAoBiG,EAAmB3U,KAAKuN,wBAAyBzF,IAErEgL,GAAoBP,GAAiBzC,GAAkB,KACxD9P,KAAKwQ,6BAA6B+B,EAAekC,EAAYzH,EAA0BwH,qBAAsBE,GAE7G1U,KAAKqN,kBAAoB6F,EAAgB5F,gBACzCtN,KAAK6Q,SAAS4D,EAAY,CAAE3E,mBAEzB6E,CACX,CAEI,MAAM,IAAI7H,EAAae,WAAW,0EAA0ElP,IAAWmO,EAAaqB,YAAYyG,sBAExJ,CAMA,UAAMjB,CAAKpL,GAEP,MAAMsM,EAAS7U,KAAKoN,cAAc7E,GAClC,GAAIsM,EACA,OAAOA,EAGX,IAAIC,EACJ,IACIA,QAAiB9U,KAAKkN,eAAeyG,KAAKpL,EAC9C,CACA,MAAO9F,GACH,MAAM,IAAIqK,EAAae,WAAW,iCAAiCtF,MAAQ9F,EAAE2H,UAAW0C,EAAaqB,YAAY4G,8BACrH,CAEA,KAAM,aAAcD,GAChB,MAAM,IAAIhI,EAAae,WAAW,yCAAyCtF,IAAOuE,EAAaqB,YAAY6G,wBAE/G,OAAOhV,KAAKoN,cAAc7E,GAAOuM,EAAS,WAC9C,CAUA,iBAAArB,CAAkBlL,EAAKtL,GACnB,GAAIsL,KAAQtL,EAAQmW,gBAAkB,CAAC,GAAI,CACvC,GAAInW,EAAQ8V,2BACR,OAAOxK,EAGP,MAAM,IAAIuE,EAAae,WAAW,0CAA4CtF,EAAKuE,EAAaqB,YAAY8G,4BAEpH,CACA,OAAO,IACX,CAKA,uBAAMV,CAAkBW,GAEpB,IAAIb,QAAsBrU,KAAK2T,KAAKuB,GAEpC,GAA6B,kBAAlBb,GAA8B/P,MAAMC,QAAQ8P,GACnD,MAAM,IAAIvH,EAAae,WAAW,gDAAkDqH,EAAkBpI,EAAaqB,YAAY6G,wBAGnI,GAAI,YAAaX,EACb,MAAM,IAAIvH,EAAae,WAAW,uDAAyDqH,EAAkBpI,EAAaqB,YAAYiD,uBAM1I,OAJAiD,EAAgBhV,OAAO2C,OAAO,CAAC,EAAGqS,GAGlCrU,KAAKiQ,iBAAiBoE,GACfA,CACX,EAEJzH,EAAcuG,wBAA0B,IACxC/V,EAAQwP,cAAgBA,C,mCCnwBxBvN,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ+Q,YAAc/Q,EAAQyQ,gBAAa,EAO3C,MAAMA,UAAmBjM,MAErB,WAAA5E,CAAYoN,EAAS+K,GACjBjY,MAAMkN,GACNpK,KAAKmV,KAAOA,CAChB,EAEJ/X,EAAQyQ,WAAaA,EAOrB,SAAWM,GACPA,EAAY,sBAAwB,qBACpCA,EAAY,uBAAyB,sBACrCA,EAAY,sBAAwB,qBACpCA,EAAY,oBAAsB,oBAClCA,EAAY,uBAAyB,uBACrCA,EAAY,sBAAwB,sBACpCA,EAAY,wBAA0B,wBACtCA,EAAY,2BAA6B,2BACzCA,EAAY,yBAA2B,yBACvCA,EAAY,wBAA0B,wBACtCA,EAAY,yBAA2B,yBACvCA,EAAY,oBAAsB,mBAClCA,EAAY,6BAA+B,4BAC3CA,EAAY,yBAA2B,wBACvCA,EAAY,iCAAmC,gCAC/CA,EAAY,4BAA8B,2BAC1CA,EAAY,0BAA4B,0BACxCA,EAAY,uBAAyB,sBACrCA,EAAY,wBAA0B,uBACtCA,EAAY,yBAA2B,wBACvCA,EAAY,8BAAgC,6BAC5CA,EAAY,4BAA8B,2BAC1CA,EAAY,kCAAoC,iCAChDA,EAAY,iCAAmC,gCAC/CA,EAAY,yBAA2B,wBACvCA,EAAY,0BAA4B,yBACxCA,EAAY,4BAA8B,2BAC1CA,EAAY,gCAAkC,+BAC9CA,EAAY,kCAAoC,iCAChDA,EAAY,0BAA4B,yBACxCA,EAAY,0BAA4B,yBACxCA,EAAY,8BAAgC,6BAC5CA,EAAY,2BAA6B,0BACzCA,EAAY,wBAA0B,uBACtCA,EAAY,sBAAwB,qBACpCA,EAAY,uBAAyB,sBACrCA,EAAY,wBAA0B,uBACtCA,EAAY,8BAAgC,6BAC5CA,EAAY,yBAA2B,wBACvCA,EAAY,4BAA8B,2BAC1CA,EAAY,wBAA0B,uBACtCA,EAAY,2BAA6B,0BACzCA,EAAY,iCAAmC,gCAC/CA,EAAY,iCAAmC,gCAC/CA,EAAY,4BAA8B,2BAC1CA,EAAY,+BAAiC,8BAC7CA,EAAY,oBAAsB,mBAClCA,EAAY,0BAA4B,yBACxCA,EAAY,+BAAiC,8BAC7CA,EAAY,+BAAiC,8BAI7CA,EAAY,yBAA2B,wBACvCA,EAAY,sBAAwB,oBACvC,CAxDD,CAwDiB/Q,EAAQ+Q,cAAgB/Q,EAAQ+Q,YAAc,CAAC,G,qCC9EhE9O,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ+P,yBAAsB,EAC9B,EAAQ,OACR,MAAML,EAAe,EAAQ,OACvBsI,EAAqB,EAAQ,MAC7BvI,EAA6B,EAAQ,OAI3C,MAAMM,EACF,WAAAnQ,CAAYqY,GACRrV,KAAKqV,QAAUA,CACnB,CACA,UAAM1B,CAAKpL,GACP,MAAMuB,QAAkB9J,KAAKqV,SAAW9K,OAAOhC,EAAK,CAAEpE,QAAS,IAAID,QAAQ,CAAEoR,OAAQ,0BACrF,GAAIxL,EAASH,IAAMG,EAAS3F,QAAS,CACjC,IAAIoR,EAAYzL,EAAS3F,QAAQ8C,IAAI,gBACrC,GAAIsO,EAAW,CACX,MAAMC,EAAWD,EAAUzU,QAAQ,KAC/B0U,EAAW,IACXD,EAAYA,EAAUxE,OAAO,EAAGyE,GAExC,CACA,GAAkB,wBAAdD,EAEA,aAAczL,EAASvC,OAIvB,GAAIuC,EAAS3F,QAAQwD,IAAI,QAAS,CAC9B,IAAI8N,EAcJ,GAbA3L,EAAS3F,QAAQ5E,SAAQ,CAAC1B,EAAO0L,KAC7B,GAAY,SAARA,EAAgB,CAChB,MAAMmM,GAAa,EAAIN,EAAmB3N,OAAO5J,GACjD,IAAK,MAAM8X,KAAQD,EAAWzO,IAAI,OAAQ,uBACtC,GAAiB,cAAb0O,EAAKC,IAAqB,CAC1B,GAAIH,EACA,MAAM,IAAI7T,MAAM,kDAAoD2G,GAExEkN,GAAe,EAAI5I,EAA2B5H,SAAS0Q,EAAKE,IAAKtN,EACrE,CAER,KAEAkN,EACA,OAAOzV,KAAK2T,KAAK8B,EAEzB,CACA,MAAM,IAAI3I,EAAae,WAAW,kCAAkC0H,IAAazI,EAAaqB,YAAY2H,wBAElH,CAEI,MAAM,IAAIlU,MAAMkI,EAASF,YAAc,gBAAgBE,EAASJ,SAExE,EAEJtM,EAAQ+P,oBAAsBA,C,mCCxD9B9N,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,G,mCCCtDwB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,G,qCCDtDwB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQoX,qBAAuBpX,EAAQqU,6BAA0B,EACjE,MAAM5E,EAA6B,EAAQ,OACrCC,EAAe,EAAQ,OACvBG,EAAS,EAAQ,OAIvB,MAAMwE,EACF,WAAAzU,CAAY2R,GACR3O,KAAK2O,WAAaA,CACtB,CAIA,aAAAC,GACI,OAAO5O,KAAK2O,UAChB,CAsBA,UAAAa,CAAW7R,EAAMoY,EAAa9Y,EAAUG,EAAQoX,sBAC5C,MAAMwB,EAAehW,KAAK2O,WAAWhR,GAErC,GAAqB,OAAjBqY,GAA0BA,GAAwC,OAAxBA,EAAa,OACvD,OAAO,KAGX,IAAIC,GAAkB,EACtB,GAAID,GAAgBD,EAAa,CAC7B,MAAMlY,EAAQoP,EAAOc,KAAKoB,kBAAkB6G,GAC5C,GAAInY,GAASA,IAAUF,EAAM,CACzB,GAAqB,kBAAVE,IAAwBoP,EAAOc,KAAK2B,WAAW7R,IAAWoP,EAAOc,KAAKQ,eAAe1Q,IAO5F,OAAOA,EALFoP,EAAOc,KAAKU,mBAAmB5Q,KAChCoY,GAAkB,EAM9B,CACJ,CAEA,MAAMzW,EAASyN,EAAOc,KAAKuD,UAAU3T,EAAMqC,KAAK2O,YAC1CuH,EAAQlW,KAAK2O,WAAW,UACxBwH,KAAmBD,GAAmB,KAAVA,IAAiBA,EAAMpV,QAAQ,KAAO,EAClEsV,EAAOpW,KAAK2O,WAAW,SACvB0H,EAAmBpJ,EAAOc,KAAKU,mBAAmB9Q,GACxD,GAAI6B,EAAQ,CACR,MAAM8W,EAAqBtW,KAAK2O,WAAWnP,GACrC3B,EAAQoP,EAAOc,KAAKoB,kBAAkBmH,GAC5C,GAAIzY,EAAO,CACP,GAAkC,kBAAvByY,GAAoCrZ,EAAQsZ,oBAWnD,GAAiB,MAAb1Y,EAAM,KAAewY,IAAqBC,EAAmB,cAAgB3Y,KAAQqC,KAAK2O,YAE1F,OAAOhR,OATX,IAAKsP,EAAOc,KAAKwC,6BAA6B1S,EAAOZ,GAEjD,OAAOU,EAUf,OAAOE,EAAQF,EAAKoT,OAAOvR,EAAOvB,OAAS,EAC/C,CACJ,KACK,IAAI8X,IAAiBG,GAAmB,KAAVA,GAAkBjZ,EAAQuZ,0BAA6BJ,GAAQD,KAC1FE,IAAqBpJ,EAAOc,KAAK2D,aAAa/T,GAAO,CACzD,GAAIwY,EAAe,CACf,GAAIlZ,EAAQuZ,yBACR,OAASN,GAASE,GAAQ,EAAIvJ,EAA2B5H,SAASiR,EAAOE,GAAQ,IAAMzY,EAGvF,MAAM,IAAImP,EAAae,WAAW,sCAAsClQ,kBAAqBuY,qBAA0BpJ,EAAaqB,YAAY6C,sBAExJ,CAEI,OAAOkF,EAAQvY,CAEvB,CACK,IAAKoY,GAAeK,IAASC,IAAqBpJ,EAAOc,KAAK2D,aAAa/T,GAC5E,OAAO,EAAIkP,EAA2B5H,SAAStH,EAAMyY,EACzD,CAEA,GAAIH,EACA,OAAOtY,EAGP,MAAM,IAAImP,EAAae,WAAW,gDAAgDlQ,QAAW6J,KAAKsG,UAAUkI,MAAkBlJ,EAAaqB,YAAYK,oBAE/J,CAWA,UAAAiI,CAAWhX,EAAKyW,GAEZ,GAAIA,GAASlW,KAAK2O,WAAW,WAAalP,EAAI3B,WAAWkC,KAAK2O,WAAW,WACrE,OAAOlP,EAAIsR,OAAO/Q,KAAK2O,WAAW,UAAU1Q,QAGhD,IAAKiY,GAASlW,KAAK2O,WAAW,UAAYlP,EAAI3B,WAAWkC,KAAK2O,WAAW,UACrE,OAAOlP,EAAIsR,OAAO/Q,KAAK2O,WAAW,SAAS1Q,QAK/C,MAAMyY,EAAoB,CAAElX,OAAQ,GAAImX,OAAQlX,GAChD,IAAK,MAAM8J,KAAOvJ,KAAK2O,WAAY,CAC/B,MAAM9Q,EAAQmC,KAAK2O,WAAWpF,GAC9B,GAAI1L,IAAUoP,EAAOc,KAAKU,mBAAmBlF,GAAM,CAC/C,MAAMmJ,EAAazF,EAAOc,KAAKoB,kBAAkBtR,GACjD,GAAI4B,EAAI3B,WAAW4U,GAAa,CAC5B,MAAMiE,EAASlX,EAAIsR,OAAO2B,EAAWzU,QACrC,GAAK0Y,EAMIA,EAAO1Y,OAASyY,EAAkBC,OAAO1Y,SAE9CyY,EAAkBlX,OAAS+J,EAC3BmN,EAAkBC,OAASA,QAR3B,GAAIT,EAEA,OAAO3M,CAQnB,CACJ,CACJ,CAEA,OAAImN,EAAkBlX,OACXkX,EAAkBlX,OAAS,IAAMkX,EAAkBC,OAEvDlX,CACX,EAEJrC,EAAQqU,wBAA0BA,EAClCrU,EAAQoX,qBAAuB,CAC3B+B,oBAAoB,EACpBK,yBAAyB,EACzBJ,0BAA0B,E,mCCzK9BnX,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ2Q,UAAO,EACf,MAAMA,EAOF,mBAAO2D,CAAa/T,GAChB,OAAOA,EAAKmD,QAAQ,KAAO,KAAOnD,GAAoB,MAAZA,EAAK,GACnD,CAQA,gBAAO2T,CAAU3T,EAAMgB,GAEnB,GAAIhB,GAAoB,MAAZA,EAAK,GACb,OAAO,KAEX,MAAMkZ,EAAelZ,EAAKmD,QAAQ,KAClC,GAAI+V,GAAgB,EAAG,CAEnB,GAAIlZ,EAAKM,OAAS4Y,EAAe,GACQ,MAAlClZ,EAAKmZ,OAAOD,EAAe,IACO,MAAlClZ,EAAKmZ,OAAOD,EAAe,GAC9B,OAAO,KAEX,MAAMrX,EAAS7B,EAAKoT,OAAO,EAAG8F,GAE9B,GAAe,MAAXrX,EACA,OAAO,KAGX,GAAIb,EAAQa,GACR,OAAOA,CAEf,CACA,OAAO,IACX,CAMA,wBAAO2P,CAAkB6G,GACrB,GAAqB,OAAjBA,GAAiD,kBAAjBA,EAChC,OAAOA,EAEX,MAAMjW,EAAKiW,EAAa,OACxB,OAAOjW,GAAU,IACrB,CAOA,mCAAOwQ,CAA6B1S,EAAOZ,GACvC,OAAQ8Q,EAAKU,mBAAmB5Q,KACxBZ,EAAQ2Z,yBAA6C,kBAAV/Y,IAAoC,MAAbA,EAAM,IAAckQ,EAAKgJ,8BAA8BlZ,IACrI,CAMA,yBAAO4Q,CAAmBuI,GACtB,MAA0B,kBAAZA,GAAwBjJ,EAAKkJ,cAAc1T,KAAKyT,EAClE,CAMA,oCAAOD,CAA8BG,GACjC,OAAOnJ,EAAKoJ,oBAAoB5T,KAAK2T,EACzC,CAMA,oBAAO5H,CAAczR,GACjB,OAAOA,IAA2B,kBAAVA,GAAuBA,GAA0B,kBAAVA,EACnE,CAMA,iBAAO6R,CAAWjQ,GACd,OAAO2X,QAAQ3X,GAAOsO,EAAKsJ,UAAU9T,KAAK9D,GAC9C,CAMA,qBAAO+R,CAAe/R,GAClB,QAASA,GAAkB,MAAXA,EAAI,IAAcsO,EAAKuJ,eAAe/T,KAAK9D,EAC/D,CAMA,qBAAO8O,CAAeyI,GAClB,OAAOjJ,EAAKwJ,eAAeP,EAC/B,CAOA,sBAAO1G,CAAgB3R,EAAS4K,GAC5B,MAAM1L,EAAQc,EAAQ4K,GACtB,QAA0B,kBAAV1L,IAAuBA,GAASA,EAAM,aAC1D,CAMA,wBAAOyV,CAAkB3U,GACrB,IAAK,MAAM4K,KAAOlK,OAAOyI,KAAKnJ,GAC1B,GAAIoP,EAAKuC,gBAAgB3R,EAAS4K,GAC9B,OAAO,EAGf,OAAO,CACX,CAKA,gCAAOuF,CAA0BvF,GAC7B,OAAOA,EAAIzL,WAAW,MAC1B,CAMA,gBAAO6S,CAAU6G,EAASC,GACtB,MAAMC,EAAWrY,OAAOyI,KAAK0P,GACvBG,EAAWtY,OAAOyI,KAAK2P,GAC7B,OAAIC,EAASzZ,SAAW0Z,EAAS1Z,QAE1ByZ,EAASE,OAAOrO,IACnB,MAAMsO,EAASL,EAAQjO,GACjBuO,EAASL,EAAQlO,GACvB,OAAQsO,IAAWC,GAAuB,OAAXD,GAChB,OAAXC,GACkB,kBAAXD,GACW,kBAAXC,GACP9X,KAAK2Q,UAAUkH,EAAQC,EAAQ,GAE3C,EAIJ/J,EAAKsJ,UAAY,6DAEjBtJ,EAAKuJ,eAAiB,eAEtBvJ,EAAKkJ,cAAgB,aAErBlJ,EAAKoJ,oBAAsB,eAE3BpJ,EAAKC,mBAAqB,8BAE1BD,EAAKM,oBAAsB,gBAG3BN,EAAKwJ,eAAiB,CAClB,eAAe,EACf,SAAS,EACT,cAAc,EACd,YAAY,EACZ,cAAc,EACd,UAAU,EACV,OAAO,EACP,WAAW,EACX,aAAa,EACb,UAAU,EACV,SAAS,EACT,aAAa,EACb,SAAS,EACT,SAAS,EACT,SAAS,EACT,WAAW,EACX,cAAc,EACd,cAAc,EACd,YAAY,EACZ,QAAQ,EACR,SAAS,EACT,UAAU,EACV,YAAY,EACZ,UAAU,GAGdxJ,EAAKc,sBAAwB,CACzB,QACA,SACA,YACA,WACA,cAGJd,EAAKiB,uBAAyB,CAC1B,aACA,SACA,MACA,SACA,QACA,QACA,QACA,UACA,WACA,OACA,QACA,SACA,YAGJjB,EAAKmB,sBAAwB,CACzB,WACA,aAGJnB,EAAKkE,WAAa,CACd,QACA,OACA,SACA,YACA,SACA,MACA,SAGJlE,EAAKgE,eAAiB,CAClB,QACA,OACA,UAEJ3U,EAAQ2Q,KAAOA,C,qCC3Pf,IAAIhC,EAAmB/L,MAAQA,KAAK+L,kBAAqB1M,OAAOiL,OAAS,SAAU0B,EAAGC,EAAGC,EAAGC,QAC7ElI,IAAPkI,IAAkBA,EAAKD,GAC3B7M,OAAOyM,eAAeE,EAAGG,EAAI,CAAEM,YAAY,EAAMxF,IAAK,WAAa,OAAOgF,EAAEC,EAAI,GACnF,EAAI,SAAUF,EAAGC,EAAGC,EAAGC,QACTlI,IAAPkI,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,EACb,GACGQ,EAAgB1M,MAAQA,KAAK0M,cAAiB,SAAST,EAAG7O,GAC1D,IAAK,IAAIuP,KAAKV,EAAa,YAANU,GAAoBtN,OAAOe,UAAUwH,eAAevG,KAAKjE,EAASuP,IAAIZ,EAAgB3O,EAAS6O,EAAGU,EAC3H,EACAtN,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtD6O,EAAa,EAAQ,OAAuBtP,E,kCCX5CiC,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ2a,iBAAc,EAOtB,MAAMA,EACF,WAAA/a,GACIgD,KAAKgY,SAAW,CAAC,CACrB,CACA,UAAAC,CAAWnQ,GACP,GAAIA,EAAK7J,OAAS,EAAG,CACjB,MAAOia,KAASC,GAAQrQ,EAClBsQ,EAAUpY,KAAKgY,SAASE,GAC9B,GAAIE,EAAS,CACT,MAAMrE,EAAaqE,EAAQH,WAAWE,GACtC,GAAIpE,EACA,OAAOA,EAAW3M,MAAK,EAAGzI,UAAS0Z,YAAY,CAAG1Z,UAAS0Z,MAAOA,EAAQ,KAElF,CACJ,CACA,OAAOrY,KAAKrB,QAAUqB,KAAKrB,QAAQyI,MAAMzI,IAAY,CAAGA,UAAS0Z,MAAO,MAAQ,IACpF,CACA,UAAAC,CAAWxQ,EAAMnJ,GACb,GAAoB,IAAhBmJ,EAAK7J,OACL+B,KAAKrB,QAAUA,MAEd,CACD,MAAOuZ,KAASC,GAAQrQ,EACxB,IAAIsQ,EAAUpY,KAAKgY,SAASE,GACvBE,IACDA,EAAUpY,KAAKgY,SAASE,GAAQ,IAAIH,GAExCK,EAAQE,WAAWH,EAAMxZ,EAC7B,CACJ,CACA,aAAA4Z,CAAcC,GACVxY,KAAKsY,WAAWE,EAAM,KAC1B,EAEJpb,EAAQ2a,YAAcA,C,qCC1CtB1Y,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQE,kBAAe,EAEvB,MAAMP,EAAS,EAAQ,OACjB0b,EAA0B,EAAQ,OAClCC,EAAW,EAAQ,OACnBC,EAA2B,EAAQ,OACnCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA0B,EAAQ,OAClCC,EAA+B,EAAQ,OACvCC,EAA6B,EAAQ,OACrCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA4B,EAAQ,OACpCC,EAA4B,EAAQ,OACpCC,EAAuC,EAAQ,OAC/CC,EAA6B,EAAQ,OACrCC,EAAmB,EAAQ,OAC3BtM,EAAS,EAAQ,OACjBmI,EAAqB,EAAQ,MAInC,MAAM9X,UAAqBob,EAASnb,UAChC,WAAAP,CAAYC,GACRC,MAAM,CAAEsc,oBAAoB,IAC5Bvc,EAAUA,GAAW,CAAC,EACtB+C,KAAK/C,QAAUA,EACf+C,KAAKyZ,eAAiB,IAAIF,EAAiBG,eAAera,OAAO2C,OAAO,CAAEpD,OAAQoB,MAAQ/C,IAC1F+C,KAAK2Z,KAAO,IAAI1M,EAAOc,KAAK,CAAElP,YAAa5B,EAAQ4B,YAAa4a,eAAgBzZ,KAAKyZ,iBACrFzZ,KAAK4Z,WAAa,IAAI7c,EACtBiD,KAAK6Z,YAAc,GACnB7Z,KAAK8Z,SAAW,GAChB9Z,KAAK+Z,oBAAsB,GAC3B/Z,KAAKga,UAAY,EACjBha,KAAKia,SAAW,GAChBja,KAAKka,eAAiBrV,QAAQI,UAC9BjF,KAAKma,4BACLna,KAAKZ,GAAG,OAAO,KACyB,qBAAzBY,KAAK4Z,WAAWnR,MACvBzI,KAAKN,KAAK,QAAS,IAAIkC,MAAM,qBACjC,GAER,CAgBA,uBAAOwY,CAAiB1b,EAAS6W,EAAWpR,EAASlH,GACjD,IAAI0B,EA0BAG,EAxBJ,GAAkB,wBAAdyW,EAAqC,CAErC,GAAkB,qBAAdA,IAAqCA,EAAU8E,SAAS,SACxD,MAAM,IAAI5B,EAAwB5K,WAAW,kCAAkC0H,IAAakD,EAAwBtK,YAAY2H,yBAgBpI,GAbI3R,GAAWA,EAAQwD,IAAI,SACvBxD,EAAQ5E,SAAQ,CAAC1B,EAAO0L,KACpB,GAAY,SAARA,EAAgB,CAChB,MAAMmM,EAAaN,EAAmB3N,MAAM5J,GAC5C,IAAK,MAAM8X,KAAQD,EAAWzO,IAAI,MAAO,wCAAyC,CAC9E,GAAItI,EACA,MAAM,IAAI8Z,EAAwB5K,WAAW,uDAAyDnP,EAAS+Z,EAAwBtK,YAAYmM,+BAEvJ3b,EAAUgX,EAAKE,GACnB,CACJ,MAGHlX,KAAyB,OAAZ1B,QAAgC,IAAZA,OAAqB,EAASA,EAAQsd,gCACxE,MAAM,IAAI9B,EAAwB5K,WAAW,8CAA8C0H,QAAgB7W,IAAW+Z,EAAwBtK,YAAY2H,wBAElK,CAGA,GAAI3R,GAAWA,EAAQwD,IAAI,gBAAiB,CACxC,MAAM6S,EAAcrW,EAAQ8C,IAAI,gBAC1BwT,EAAQ,qBAAqBC,KAAKF,GACpCC,GAAsB,2CAAbA,EAAM,KACf3b,GAAmB,EAE3B,CACA,OAAO,IAAIxB,EAAa+B,OAAO2C,OAAO,CAAEtD,UACpCC,UACAG,oBAAoB7B,GAAoB,CAAC,GACjD,CAMA,MAAA6E,CAAO6Y,GACH,MAAM5Y,EAAS,IAAI2W,EAASkC,YAAY,CAAEpB,oBAAoB,IAC9DmB,EAAOvb,GAAG,SAAUiG,GAAUwV,EAAOnb,KAAK,QAAS2F,KACnDsV,EAAOvb,GAAG,QAAS0b,GAAS/Y,EAAOgG,KAAK+S,KACxCH,EAAOvb,GAAG,OAAO,IAAM2C,EAAOgG,KAAK,QACnC,MAAM8S,EAAS9Y,EAAOhD,KAAK,IAAIzB,EAAa0C,KAAK/C,UACjD,OAAO4d,CACX,CACA,UAAAE,CAAWC,EAAO9b,EAAUC,GACxBa,KAAK4Z,WAAWqB,MAAMD,GACtBhb,KAAKka,eACA9S,MAAK,IAAMjI,MAAakG,GAAUlG,EAASkG,IACpD,CAYA,mBAAM6V,CAAcpT,EAAMjK,EAAOwa,EAAO8C,GACpC,IAAIC,GAAc,EAGlB,GAAID,GAAkB9C,EAAQrY,KAAKga,UAAW,CAE1C,MAAMqB,EAAcrb,KAAKyZ,eAAe6B,iBAAiBtb,KAAKga,WAC1DqB,IAEIA,EAAYxd,OACZmC,KAAKN,KAAK,OAAQM,KAAK2Z,KAAK9a,YAAYT,KAAKid,EAAYxd,MAAOmC,KAAK2Z,KAAK4B,QAASvb,KAAK2Z,KAAK6B,OAAQxb,KAAK2Z,KAAK8B,oBAGnHJ,EAAYK,OAAOC,UAAW,EAC9B3b,KAAKyZ,eAAemC,QAAQP,EAAYQ,cAAgB,GAAK,CAACR,EAAYK,QAC1E1b,KAAKyZ,eAAe6B,iBAAiBQ,OAAO9b,KAAKga,UAAW,UAItDpB,EAAwBmD,sBAAsBC,6BAA6Bhc,KAAKyZ,eAAgBzZ,KAAKia,SAAUja,KAAKga,YAC1Hha,KAAKyZ,eAAewC,6BACflU,KAAK,CAAEsQ,MAAOrY,KAAKga,UAAWlS,KAAM9H,KAAKia,SAASjc,MAAM,EAAGgC,KAAKia,SAAShc,UAC9Emd,GAAc,SAGRpb,KAAKkc,YAAYlc,KAAKga,UAAWha,KAAKia,SAEpD,CACA,MAAM1Q,QAAYvJ,KAAK2Z,KAAKwC,eAAerU,EAAKuQ,GAAQvQ,EAAMuQ,GACxD+D,QAAkBpc,KAAK2Z,KAAK0C,qBAAqBvU,EAAMuQ,GAC7DrY,KAAKyZ,eAAe6C,aAAajE,IAAS,EAC1C,IAAIkE,GAAY,EAEZ9D,EAAwB1K,KAAKQ,eAAehF,IAAsB,aAAd6S,GAAoC,aAAR7S,GAChFvJ,KAAKN,KAAK,QAAS,IAAI+Y,EAAwB5K,WAAW,kBAAkBhQ,iCAAsC4a,EAAwBtK,YAAYqO,+BAI1J,IAAIC,GAAa,EACbzc,KAAKyZ,eAAeiD,gBAAgBze,OAAS,IAC7Cwe,EAAazc,KAAKyZ,eAAeiD,gBAAgB1c,KAAKyZ,eAAeiD,gBAAgBze,OAAS,GAAG0e,UAErG,IAAK,IAAI1W,EAAI2W,KAAKC,IAAI,EAAG7c,KAAKyZ,eAAeiD,gBAAgBze,OAAS,GAAIgI,EAAI6B,EAAK7J,OAAS,EAAGgI,IAAK,CAChG,MAAM6W,EAAmB9c,KAAKyZ,eAAeiD,gBAAgBzW,KACrDjG,KAAKyZ,eAAeiD,gBAAgBzW,SAAWjG,KAAK+c,YAAYjV,EAAK9J,MAAM,EAAGiI,EAAI,GAAIA,EAAGwW,IACjG,IAAKK,EAAiBE,MAAO,CACzBhd,KAAKyZ,eAAe6C,aAAajE,IAAS,EAC1CkE,GAAY,EACZ,KACJ,EACUE,GAAcK,EAAiBH,WACrCF,GAAa,EAErB,CAMA,GAJIzc,KAAK2Z,KAAKsD,UAAU5E,KACpBkE,GAAY,GAGZA,EACA,IAAK,MAAMW,KAAgB5f,EAAa6f,eAAgB,CACpD,MAAMC,QAAmBF,EAAa3Z,KAAKvD,KAAKyZ,eAAgBzZ,KAAK2Z,KAAMpQ,EAAKzB,EAAMuQ,GACtF,GAAI+E,EAAY,OAENF,EAAaG,OAAOrd,KAAKyZ,eAAgBzZ,KAAK2Z,KAAMpQ,EAAKzB,EAAMjK,EAAOwa,EAAO+E,GAE/EF,EAAaI,qBACbtd,KAAKyZ,eAAe8D,gBAAgBlF,IAAS,GAEjD,KACJ,CACJ,CAGU,IAAVA,GAAe/T,MAAMC,QAAQ1G,UACvBmC,KAAK2Z,KAAK6D,qBAAqB3f,GAGrCud,GAAe/C,EAAQrY,KAAKga,WAE5Bha,KAAKob,YAAYpb,KAAKga,WAE1Bha,KAAKga,UAAY3B,EACjBrY,KAAKia,SAAWnS,EAEhB9H,KAAKyZ,eAAegE,2BAA2B3B,OAAOzD,EAAQ,EAClE,CAKA,WAAA+C,CAAY/C,GACRrY,KAAKyZ,eAAe8D,gBAAgBzB,OAAOzD,EAAO,GAClDrY,KAAKyZ,eAAeiE,eAAe5B,OAAOzD,EAAO,GACjDrY,KAAKyZ,eAAe6C,aAAaR,OAAOzD,EAAO,GAC/CrY,KAAKyZ,eAAemC,QAAQE,OAAOzD,EAAO,GAC1CrY,KAAKyZ,eAAekE,WAAW7B,OAAOzD,EAAQ,EAAG,GACjDrY,KAAKyZ,eAAemE,wBAAwB9B,OAAOzD,EAAO,GAC1DrY,KAAKyZ,eAAeoE,iBAAiB/B,OAAOzD,EAAO,GACnDrY,KAAKyZ,eAAeiD,gBAAgBZ,OAAOzD,EAAQ,EAAG,GACtDrY,KAAKyZ,eAAeqE,aAAahC,OAAOzD,EAAOrY,KAAKyZ,eAAeqE,aAAa7f,OAASoa,EAE7F,CAUA,iBAAM6D,CAAY7D,EAAOvQ,GACrB,IAAIiW,EAAW/d,KAAKyZ,eAAemC,QAAQvD,GACtC0F,IACDA,EAAW/d,KAAKyZ,eAAemC,QAAQvD,GAAS,CAACrY,KAAK2Z,KAAK9a,YAAY8B,cAG3E,MAAMqd,EAAche,KAAKyZ,eAAewE,yBAAyB5F,GACjE,GAAI2F,EAAa,CACb,IAAK,MAAM3f,KAAW0f,EAAU,CAC5B,MAAMG,QAAyBle,KAAK2Z,KAAKwE,oBAAoB9F,EAAOvQ,GAC9DsW,EAAUpe,KAAKyZ,eAAekE,WAAWtF,IAAU6F,GAAoB,EACvEle,KAAKyZ,eAAemC,QAAQvD,EAAQ6F,EAAmB,GACvD,OAAOle,KAAK2Z,KAAK0E,uBAAuBvW,EAAMuQ,IACpD,GAAI+F,EACA,IAAK,MAAM5f,KAAS4f,EAAQ,CAExBpe,KAAKyZ,eAAe6C,aAAajE,IAAS,EAC1C,IAAK,MAAMiG,KAAiBN,EACpBM,EAAcC,QACdve,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAK2Z,KAAK9a,YAAYT,KAAKkgB,EAAc/f,OAAQ+f,EAAchgB,UAAWD,EAASG,IAGvHwB,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAK2Z,KAAK9a,YAAYT,KAAKC,EAASigB,EAAchgB,UAAWggB,EAAc/f,OAAQC,GAGnI,KAEC,CAED,MAAMigB,EAAiBze,KAAKyZ,eAAeiF,+BAA+BrG,QAAcrY,KAAK2Z,KAAKwE,oBAAoB9F,EAAOvQ,GAAQ,GACrI,IAAK,MAAMwW,KAAiBN,EACpBM,EAAcC,QACdE,EAAe1W,KAAK,CAChBxJ,OAAQF,EACRC,UAAWggB,EAAchgB,UACzBD,QAASigB,EAAc/f,SAI3BkgB,EAAe1W,KAAK,CAChBxJ,OAAQ+f,EAAc/f,OACtBD,UAAWggB,EAAchgB,UACzBD,WAIhB,CACJ,CACA2B,KAAKyZ,eAAewE,yBAAyBnC,OAAOzD,EAAO,GAC3DrY,KAAKyZ,eAAeqE,aAAahC,OAAOzD,EAAO,GAC/CrY,KAAKyZ,eAAeoE,iBAAiB/B,OAAOzD,EAAO,EACvD,CAEA,MAAMsG,EAAc3e,KAAKyZ,eAAemF,yBAAyBvG,GACjE,GAAIsG,EAAa,CACb,IAAK,MAAMtgB,KAAW0f,EAAU,CAI5B,MAAMvf,EAAkB,IAAV6Z,GAAoC,cAArBha,EAAQT,UAC7BoC,KAAKyZ,eAAeoF,mBAAmDxgB,EAA9B2B,KAAK2Z,KAAK8B,kBAC3Dzb,KAAKyZ,eAAe6C,aAAajE,IAAS,EAC1C,IAAK,MAAMiG,KAAiBK,EACxB3e,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAK2Z,KAAK9a,YAAYT,KAAKkgB,EAAcjgB,QAASigB,EAAchgB,UAAWggB,EAAc/f,OAAQC,GAE7I,CACAwB,KAAKyZ,eAAemF,yBAAyB9C,OAAOzD,EAAO,EAC/D,CACJ,CAQA,iBAAM0E,CAAYjV,EAAMuQ,EAAOoE,GAC3B,IAAK,MAAMS,KAAgB5f,EAAa6f,eACpC,SAAUD,EAAarM,SAAS7Q,KAAKyZ,eAAgBzZ,KAAK2Z,KAAM7R,EAAMuQ,EAAOoE,GACzE,MAAO,CAAEO,OAAO,EAAML,SAAUF,GAAcS,EAAa4B,qBAGnE,MAAO,CAAE9B,OAAO,EAAOL,UAAU,EACrC,CAMA,yBAAAxC,GAEIna,KAAK4Z,WAAWmF,QAAWlhB,IACvB,MAAMwa,EAAQrY,KAAK4Z,WAAWvP,MAAMpM,OAC9B6J,EAAQ,IAAIxD,MAAM+T,EAAQ,GAAG2G,KAAK,GAAI5a,KAAI,CAAC6a,EAAGhZ,IACzCA,IAAMoS,EAAQrY,KAAK4Z,WAAWrQ,IAAMvJ,KAAK4Z,WAAWvP,MAAMpE,GAAGsD,MAExE,IAAKvJ,KAAKkf,sBAAsB7G,GAAQ,CACpC,MAAM8G,EAAa,IAAMnf,KAAKkb,cAAcpT,EAAMjK,EAAOwa,GAAO,GAChE,GAAKrY,KAAKyZ,eAAe3a,kBACjBkB,KAAKyZ,eAAe2F,YAAYnH,WAAWnQ,EAAK9J,MAAM,GAAI,IAwB9DgC,KAAKka,eAAiBla,KAAKka,eAAe9S,KAAK+X,QAlB/C,GAAoB,aAAhBrX,EAAKuQ,GAAuB,CAC5B,IAAIgH,EAAOrf,KAAK6Z,YAAYxB,GACvBgH,IACDA,EAAOrf,KAAK6Z,YAAYxB,GAAS,IAErCgH,EAAKtX,KAAKoX,EACd,KACyB,UAAhBrX,EAAKuQ,IACgB,kBAAhBvQ,EAAKuQ,IAA2C,UAApBvQ,EAAKuQ,EAAQ,GAEnDrY,KAAK8Z,SAAS/R,KAAK,CAAEuX,IAAKH,EAAYrX,KAAMA,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,KAGxE+B,KAAK+Z,oBAAoBhS,KAAK,CAAEuX,IAAKH,EAAYrX,SAQpD9H,KAAKyZ,eAAe3a,kBAA8B,IAAVuZ,IACzCrY,KAAKka,eAAiBla,KAAKka,eACtB9S,MAAK,IAAMpH,KAAKuf,wBAE7B,GAEJvf,KAAK4Z,WAAW4F,QAAWna,IACvBrF,KAAKN,KAAK,QAAS2F,EAAM,CAEjC,CAMA,qBAAA6Z,CAAsB7G,GAClB,IAAK,IAAIpS,EAAIoS,EAAOpS,EAAI,EAAGA,IACvB,GAAyC,aAArCjG,KAAK4Z,WAAWvP,MAAMpE,EAAI,GAAGsD,IAC7B,OAAO,EAGf,OAAO,CACX,CAKA,yBAAMgW,GAEF,IAAK,MAAMF,KAAQrf,KAAK6Z,YACpB,GAAIwF,EACA,IAAK,MAAMC,KAAOD,QACRC,IAKlBtf,KAAKyZ,eAAegE,2BAA2B3B,OAAO,GAEtD,IAAK,MAAMwD,KAAOtf,KAAK+Z,oBAAqB,CAGxC,GAAI/Z,KAAK8Z,SAAS7b,OAAS,EAAG,CAE1B,MAAMwhB,EAAqB,GACrBC,EAAuB,GAC7B,IAAK,IAAIzZ,EAAI,EAAGA,EAAIjG,KAAK8Z,SAAS7b,OAAQgI,IAAK,CAC3C,MAAM0Z,EAAU3f,KAAK8Z,SAAS7T,GAC1BgH,EAAOc,KAAK6R,cAAcD,EAAQ7X,KAAMwX,EAAIxX,QAC5C2X,EAAmB1X,KAAK4X,GACxBD,EAAqB3X,KAAK9B,GAElC,CAEA,MAAM4Z,EAAiBJ,EAAmBK,MAAK,CAACC,EAAMC,IAASD,EAAKjY,KAAK7J,OAAS+hB,EAAKlY,KAAK7J,SAE5F,IAAK,MAAM0hB,KAAWE,QACZF,EAAQL,MAIlB,MAAMW,EAA6BP,EAAqBI,OAAOvB,UAC/D,IAAK,MAAM2B,KAASD,EAChBjgB,KAAK8Z,SAASgC,OAAOoE,EAAO,EAEpC,OACMZ,EAAIA,KACd,CACJ,EAEJliB,EAAQE,aAAeA,EACvBA,EAAa6V,wBAA0B,MACvC7V,EAAa6f,eAAiB,CAC1B,IAAIxE,EAAyBwH,uBAC7B,IAAIpH,EAA6BqH,2BACjC,IAAInH,EAAwBoH,sBAC5B,IAAInH,EAA8BoH,4BAClC,IAAItH,EAA2BuH,yBAC/B,IAAIpH,EAA0BqH,wBAC9B,IAAIpH,EAA0BqH,wBAC9B,IAAInH,EAA2BoH,yBAC/B,IAAI9H,EAAwBmD,sBAC5B,IAAI1C,EAAqCsH,mCACzC,IAAI7H,EAAwB8H,sBAC5B,IAAI/H,EAA8BgI,4B,qCClctCxhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQsc,oBAAiB,EACzB,MAAMjB,EAA0B,EAAQ,OAClC3L,EAAe,EAAQ,OACvBgU,EAAgB,EAAQ,MACxBC,EAAiB,EAAQ,OAI/B,MAAMrH,EACF,WAAA1c,CAAYC,GAER+C,KAAKghB,cAAgB,IAAIvI,EAAwB7L,cAAc,CAAEM,eAAgBjQ,EAAQiQ,eAAgBI,eAAgBrQ,EAAQgkB,wBACjIjhB,KAAKlB,mBAAqB7B,EAAQ6B,iBAClCkB,KAAKtB,QAAUzB,EAAQyB,QACvBsB,KAAKkhB,wBAA0BjkB,EAAQikB,sBACvClhB,KAAKmhB,mBAAqBlkB,EAAQkkB,iBAClCnhB,KAAK8P,eAAiB7S,EAAQ6S,gBAAkBiR,EAAezjB,aAAa6V,wBAC5EnT,KAAKkO,eAAiBjR,EAAQiR,aAC9BlO,KAAKwd,uBAAyBvgB,EAAQugB,qBACtCxd,KAAKgB,aAAe/D,EAAQ+D,aAC5BhB,KAAKohB,aAAenkB,EAAQmkB,aAC5BphB,KAAK+P,sBAAwB9S,EAAQ8S,sBACrC/P,KAAKqhB,yCAA2CpkB,EAAQokB,yCACxDrhB,KAAK6e,oBAAqB,EAC1B7e,KAAKshB,qBAAuBC,WAAWvhB,KAAK8P,gBAE5C9P,KAAKud,gBAAkB,GACvBvd,KAAK0d,eAAiB,GACtB1d,KAAKsc,aAAe,GACpBtc,KAAK4b,QAAU,GACf5b,KAAK2d,WAAa,GAClB3d,KAAK4d,wBAA0B,GAC/B5d,KAAKsb,iBAAmB,GACxBtb,KAAKof,YAAc,IAAI0B,EAAc/I,YACrC/X,KAAK8d,aAAe,GACpB9d,KAAK0c,gBAAkB,GACvB1c,KAAKyd,2BAA6B,GAClCzd,KAAK6d,iBAAmB,GACxB7d,KAAKie,yBAA2B,GAChCje,KAAK4e,yBAA2B,GAChC5e,KAAKic,6BAA+B,GACpCjc,KAAKpB,OAAS3B,EAAQ2B,OAClB3B,EAAQ0B,SACRqB,KAAKwhB,YAAcxhB,KAAKyhB,aAAaxkB,EAAQ0B,SAC7CqB,KAAKwhB,YAAYpa,MAAMzI,GAAYqB,KAAKqN,gBAAgB1O,MAGxDqB,KAAKwhB,YAAc3c,QAAQI,QAAQ,IAAIwT,EAAwBhH,wBAAwBzR,KAAKtB,QAAU,CAAE,QAASsB,KAAKtB,QAAS,mBAAmB,GAAS,CAAC,GAEpK,CAQA,kBAAM+iB,CAAa9iB,EAAS4T,EAAeO,GACvC,OAAO9S,KAAKghB,cAAcvZ,MAAM9I,EAAS,CACrCD,QAASsB,KAAKtB,QACdoU,mBACA/C,sBAAuB/P,KAAK+P,sBAC5BwC,gBACAzC,eAAgB9P,KAAKshB,sBAE7B,CAMA,eAAAjU,CAAgB1O,GACZ,MAAM+iB,EAAgB/iB,EAAQiQ,gBAAgB,YAC9C,GAAI8S,EAAe,CACf,GAAI1hB,KAAKshB,sBAAwBI,EAAgB1hB,KAAKshB,qBAClD,MAAM,IAAIxU,EAAae,WAAW,gCAAgC6T,mCAA+C1hB,KAAKshB,wBAAyBxU,EAAaqB,YAAYwT,0BAGxK,GAAI3hB,KAAKshB,sBAAwBI,EAAgB1hB,KAAKshB,qBAClD,MAAM,IAAIxU,EAAae,WAAW,2BAA2B6T,kCAA8C1hB,KAAKshB,wBAAyBxU,EAAaqB,YAAYgD,uBAEtKnR,KAAKshB,qBAAuBI,CAEpC,CACJ,CAOA,gBAAMzJ,CAAWnQ,EAAM8Z,EAAS,GAC5B,MAAMC,EAAe/Z,EAErB,MAAwC,kBAA1BA,EAAKA,EAAK7J,OAAS,GAC7B6J,EAAOA,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAGnC2jB,IACA9Z,EAAOA,EAAK9J,MAAM,GAAI4jB,IAG1B,MAAME,QAAoB9hB,KAAK+hB,2BAA2Bja,GACpDnJ,EAAUmjB,EAAYnjB,QAE5B,IAAIgQ,EAAahQ,EAAQiQ,gBACzB,IAAK,IAAI3I,EAAI6b,EAAYzJ,MAAOpS,EAAI4b,EAAa5jB,OAAS2jB,EAAQ3b,IAAK,CACnE,MAAMsD,EAAMsY,EAAa5b,GACnB+b,EAAkBrT,EAAWpF,GACnC,GAAIyY,GAA8C,kBAApBA,GAAgC,aAAcA,EAAiB,CACzF,MAAMC,SAAuBjiB,KAAKyhB,aAAaO,EAAiBrT,GAAY,IAAOC,gBAC7EsT,IAAc3Y,KAAO0Y,IACpBA,EAAc1Y,GAAK,YAAY,eACpB,IAAd2Y,GAAuBjc,IAAM4b,EAAa5jB,OAAS,EAAI2jB,IACvDjT,EAAasT,SAENtT,EAAW,cAClBA,EAAWpF,GAAOlK,OAAO2C,OAAO,CAAC,EAAG2M,EAAWpF,IAC3C,QAASyY,IACTrT,EAAWpF,GAAK,OAASyY,EAAgB,eAEtCrT,EAAWpF,GAAK,aACL,IAAd2Y,GACAliB,KAAKof,YAAY9G,WAAWuJ,EAAa7jB,MAAM,EAAGiI,EAAI2b,GAAS/c,QAAQI,QAAQ,IAAIwT,EAAwBhH,wBAAwB9C,KAG/I,CACJ,CACA,OAAO,IAAI8J,EAAwBhH,wBAAwB9C,EAC/D,CAaA,gCAAMoT,CAA2Bja,GAC7B,MAAMqa,EAAgBra,EAAK7J,OAC3B,IACImkB,EADAN,EAAc,KAElB,EAAG,CACCM,GAAqC,EACjCN,GAAe,yBAA0BA,EAAYnjB,QAAQiQ,gBAG7DkT,EAAYnjB,QAAU,IAAI8Z,EAAwBhH,wBAAwBqQ,EAAYnjB,QAAQiQ,gBAAgB,0BAG1GkT,IAIAha,EAAOA,EAAK9J,MAAM,EAAG8jB,EAAYzJ,MAAQ,IAE7CyJ,QAAoB9hB,KAAKof,YAAYnH,WAAWnQ,IAAS,CAAEnJ,cAAeqB,KAAKwhB,YAAanJ,MAAO,IAKvG,MAAMgK,EAAUva,EAAKA,EAAK7J,OAAS,GACnC,GAAIokB,KAAWP,EAAYnjB,QAAQiQ,gBAAiB,CAChD,MAAM0T,EAAeR,EAAYnjB,QAAQiQ,gBAAgByT,GACrDC,GAAwC,kBAAjBA,GAA6B,aAAcA,IAClEF,GAAqC,EAE7C,CACJ,OAASN,EAAYzJ,MAAQ,IACgC,IAAtDyJ,EAAYnjB,QAAQiQ,gBAAgB,eACpCkT,EAAYzJ,QAAU8J,IACrBC,GAQR,OAL0B,IAAtBN,EAAYzJ,QAC6C,IAAtDyJ,EAAYnjB,QAAQiQ,gBAAgB,eACpCkT,EAAYzJ,QAAU8J,IACzBL,EAAYnjB,QAAU,IAAI8Z,EAAwBhH,wBAAwB,CAAC,IAExEqQ,CACX,CASA,mBAAM5G,CAAcpT,EAAMjK,EAAOwa,EAAO8C,SAC9Bnb,KAAKpB,OAAOsc,cAAcpT,EAAMjK,EAAOwa,EAAO8C,EACxD,CAKA,wCAAMoH,GACF,GAAIviB,KAAKic,6BAA6Bhe,OAAS,EAAG,CAC9C,IAAK,MAAMukB,KAAsBxiB,KAAKic,mCAC5Bjc,KAAKpB,OAAOsd,YAAYsG,EAAmBnK,MAAOmK,EAAmB1a,MAC3E9H,KAAKpB,OAAOwc,YAAYoH,EAAmBnK,OAG/C,OADArY,KAAKic,6BAA6BH,OAAO,EAAG9b,KAAKic,6BAA6Bhe,SACvE,CACX,CAEI,OAAO,CAEf,CAMA,QAAAugB,CAASnG,EAAOja,GACE,IAAVia,IACArY,KAAK6e,oBAAqB,GAE9B7e,KAAKpB,OAAOmJ,KAAK3J,EACrB,CAKA,SAAAqkB,CAAUpd,GACNrF,KAAKpB,OAAOc,KAAK,QAAS2F,EAC9B,CAKA,WAAAqd,CAAY/jB,GACRqB,KAAKpB,OAAOc,KAAK,UAAWf,EAChC,CAOA,8BAAAgkB,CAA+BtK,GAC3B,IAAI9R,EAASvG,KAAKie,yBAAyB5F,GAK3C,OAJK9R,IACDA,EAAS,GACTvG,KAAKie,yBAAyB5F,GAAS9R,GAEpCA,CACX,CAOA,8BAAAmY,CAA+BrG,GAC3B,IAAI9R,EAASvG,KAAK4e,yBAAyBvG,GAK3C,OAJK9R,IACDA,EAAS,GACTvG,KAAK4e,yBAAyBvG,GAAS9R,GAEpCA,CACX,CAIA,gBAAAqc,GACI,OAAOlJ,EAAemJ,eAAe7iB,KAAKshB,qBAC9C,CAUA,UAAAwB,CAAWzK,EAAO0K,GAEd,MAAMC,EAAgBhjB,KAAK4b,QAAQvD,EAAQ0K,GAO3C,GANIC,IACAhjB,KAAK4b,QAAQvD,GAAS2K,EACtBhjB,KAAKsc,aAAajE,IAAS,SACpBrY,KAAK4b,QAAQvD,EAAQ0K,IAG5B/iB,KAAKic,6BAA6Bhe,OAClC,IAAK,MAAMsI,KAAUvG,KAAKic,6BAClB1V,EAAO8R,OAASA,EAAQ0K,IACxBxc,EAAO8R,OAAS0K,EAChBxc,EAAOuB,KAAKgU,OAAOzD,EAAO0K,IAKlC/iB,KAAKie,yBAAyB5F,EAAQ0K,KACtC/iB,KAAKie,yBAAyB5F,GAASrY,KAAKie,yBAAyB5F,EAAQ0K,UACtE/iB,KAAKie,yBAAyB5F,EAAQ0K,GAGrD,EAEJ3lB,EAAQsc,eAAiBA,EACzBA,EAAemJ,eAAiB,CAC5B,EAAK,CACDtM,oBAAoB,EACpBK,yBAAyB,EACzBJ,0BAA0B,GAE9B,IAAK,CACDD,oBAAoB,EACpBK,yBAAyB,EACzBJ,0BAA0B,G,qCC7TlCnX,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ2Q,UAAO,EACf,MAAM0K,EAA0B,EAAQ,OAClCwK,EAAqB,EAAQ,OAC7BrK,EAA0B,EAAQ,OAElCsK,EAAmB,EAAQ,OAIjC,MAAMnV,EACF,WAAA/Q,CAAYC,GACR+C,KAAKyZ,eAAiBxc,EAAQwc,eAC9BzZ,KAAKnB,YAAc5B,EAAQ4B,aAAe,IAAIokB,EAAmBpjB,YACjEG,KAAKmjB,SAAWnjB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,SACtDpjB,KAAKub,QAAUvb,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,QACrDpjB,KAAKwb,OAASxb,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,OACpDpjB,KAAKqjB,QAAUrjB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,QACrDpjB,KAAKsjB,QAAUtjB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,OACzD,CAYA,sBAAOG,CAAgB5kB,EAAS6kB,EAAYja,EAAKka,GAC7C,MAAMC,EAAQ/kB,EAAQiQ,gBAAgBrF,GACtC,IAAKma,EACD,OAAOD,EAEX,MAAMvc,EAAOwc,EAAMF,GACnB,YAAgBvf,IAATiD,EAAqBuc,EAAWvc,CAC3C,CAYA,+BAAOyc,CAAyBhlB,EAAS4K,GACrC,OAAOwE,EAAKwV,gBAAgB5kB,EAAS,aAAc4K,EAAK,CAAE,QAAQ,GACtE,CAOA,0BAAOqa,CAAoBjlB,EAAS4K,GAChC,MAAMuH,EAAY/C,EAAKwV,gBAAgB5kB,EAAS,QAAS4K,EAAK,MAC9D,MAAkB,UAAduH,EACO,KAEJA,CACX,CAOA,8BAAO+S,CAAwBllB,EAAS4K,GACpC,OAAOwE,EAAKwV,gBAAgB5kB,EAAS,YAAa4K,EAAK5K,EAAQiQ,gBAAgB,cAAgB,KACnG,CAOA,+BAAOkV,CAAyBnlB,EAAS4K,GACrC,OAAOwE,EAAKwV,gBAAgB5kB,EAAS,aAAc4K,EAAK5K,EAAQiQ,gBAAgB,eAAiB,KACrG,CAOA,4BAAOmV,CAAsBplB,EAAS4K,GAClC,QAASwE,EAAKwV,gBAAgB5kB,EAAS,WAAY4K,EAAK,KAC5D,CAOA,2BAAOya,CAAqBrlB,EAAS4K,GACjC,OAAOwE,EAAKwV,gBAAgB5kB,EAAS,SAAU4K,EAAK5K,EAAQiQ,gBAAgB,WAAa,KAC7F,CAQA,wBAAOqV,CAAkBtlB,EAAS4K,EAAK6S,GAEnC,MAAqB,aAAdA,IAA6BrO,EAAKgW,sBAAsBplB,EAAS4K,EAC5E,CAMA,iBAAOmG,CAAWjQ,GACd,OAAe,OAARA,GAAgBgZ,EAAwB1K,KAAK2B,WAAWjQ,EACnE,CAMA,oBAAOmgB,CAAcsE,EAAQC,GACzB,GAAID,EAAOjmB,OAASkmB,EAASlmB,OACzB,OAAO,EAEX,IAAK,IAAIgI,EAAI,EAAGA,EAAIie,EAAOjmB,OAAQgI,IAC/B,GAAIie,EAAOje,KAAOke,EAASle,GACvB,OAAO,EAGf,OAAO,CACX,CAOA,0BAAMuX,CAAqB3f,GACvB,GAAImC,KAAKyZ,eAAe+D,qBAAsB,CAC1C,MAAM4G,EAAc,CAAC,EACrB,IAAK,MAAMV,KAAS7lB,EAChB,GAAI6lB,GAA0B,kBAAVA,EAAoB,CACpC,MAAM3jB,EAAK2jB,EAAM,OACXW,EAAQX,EAAM,UACpB,GAAI3jB,GAAMskB,EAAO,CACb,MAAMC,EAAqBF,EAAYrkB,GACvC,GAAIukB,GAAsBA,IAAuBD,EAC7C,MAAM,IAAI5L,EAAwB5K,WAAW,gCAAgC9N,IAAM0Y,EAAwBtK,YAAYoW,qBAE3HH,EAAYrkB,GAAMskB,CACtB,CACJ,CAER,CACJ,CAUA,iBAAMG,CAAY7lB,EAAS4K,EAAK1L,EAAOwa,EAAOvQ,GAE1C,GAA+C,UAA3CiG,EAAK6V,oBAAoBjlB,EAAS4K,GAClC,MAAO,CAACvJ,KAAKnB,YAAY+B,QAAQZ,KAAKykB,kBAAkB5mB,GAAQmC,KAAKsjB,UAEzE,MAAMpc,SAAcrJ,EACpB,OAAQqJ,GACJ,IAAK,SAED,GAAc,OAAVrJ,QAA4BoG,IAAVpG,EAClB,MAAO,GAGX,GAAIyG,MAAMC,QAAQ1G,GAGd,MAAI,UAAWkQ,EAAK4V,yBAAyBhlB,EAAS4K,GAC7B,IAAjB1L,EAAMI,OACC,CAAC+B,KAAKwb,QAGNxb,KAAKyZ,eAAemC,QAAQvD,EAAQ,IAAM,UAGnDrY,KAAKwd,qBAAqB3f,GACzB,IAUX,GAPAc,QAAgBqB,KAAK0kB,+BAA+B/lB,EAAS4K,GAEzD,aAAc1L,IACdc,QAAgBqB,KAAKyZ,eAAegI,aAAa5jB,EAAM,mBAAoBmC,KAAKyZ,eAAexB,WAAWnQ,EAAM,IAAI8G,kBAGxH/Q,QAAcmC,KAAK2kB,gBAAgB9mB,EAAOiK,EAAMuQ,EAAO1Z,GACnD,WAAYd,EAAO,CACnB,IAAI+mB,EACAC,EACAC,EACAhU,EACAiU,EACJ,IAAKxb,KAAO1L,EAAO,CACf,MAAMmnB,EAAWnnB,EAAM0L,GACvB,OAAQA,GACJ,IAAK,SACDqb,EAAMI,EACN,MACJ,IAAK,YACDH,EAAgBG,EAChB,MACJ,IAAK,aACDF,EAAiBE,EACjB,MACJ,IAAK,QACDlU,EAAYkU,EACZ,MACJ,IAAK,SACDD,EAAaC,EACb,MACJ,QACI,MAAM,IAAIvM,EAAwB5K,WAAW,wBAAwBtE,iBAAmB/B,KAAKsG,UAAUjQ,KAAU4a,EAAwBtK,YAAY8W,sBAEjK,CAEA,GAAyE,gBAA/DjlB,KAAKmc,eAAerL,EAAWhJ,EAAMuQ,GAAO,EAAM1Z,GACxD,MAAO,CAACqB,KAAKnB,YAAY+B,QAAQZ,KAAKykB,kBAAkBG,GAAM5kB,KAAKsjB,UAGvE,GAAY,OAARsB,EACA,MAAO,GAEX,GAAmB,kBAARA,EACP,MAAM,IAAInM,EAAwB5K,WAAW,uDAAuDrG,KAAKsG,UAAU8W,MAASnM,EAAwBtK,YAAY+W,4BAGpK,GAAIllB,KAAKyZ,eAAe+D,sBAAwBuH,GAAoC,kBAAfA,EACjE,MAAM,IAAItM,EAAwB5K,WAAW,mDAAmDrG,KAAKsG,UAAUiX,MAAgBtM,EAAwBtK,YAAYgX,qBAGvK,GAAIN,EAAe,CACf,GAAmB,kBAARD,EACP,MAAM,IAAInM,EAAwB5K,WAAW,4EAA4ErG,KAAKsG,UAAU8W,MAASnM,EAAwBtK,YAAYiX,+BAEzL,IAAK3M,EAAwB7L,cAAcc,iBAAiBmX,EAAe7kB,KAAKyZ,eAAevL,aAAcuK,EAAwBtK,YAAYkX,gCAC7I,MAAO,IAGPrlB,KAAKyZ,eAAe1J,uBAAsE,IAA7C/P,KAAKyZ,eAAe6H,wBACjEuD,EAAgBA,EAAcphB,cAEtC,CACA,GAAIqhB,EAAgB,CAChB,GAAmB,kBAARF,EACP,MAAM,IAAIhjB,MAAM,6EAA6E4F,KAAKsG,UAAU8W,OAEhH,IAAKnM,EAAwB7L,cAAcqB,kBAAkB6W,EAAgB9kB,KAAKyZ,eAAevL,cAC7F,MAAO,EAEf,CAEA,GAAI2W,GAAiBC,GAAkB9kB,KAAKyZ,eAAe2H,aAAc,CACrE,GAAItQ,EACA,MAAM,IAAI2H,EAAwB5K,WAAW,mEAAmErG,KAC3GsG,UAAUjQ,MAAW4a,EAAwBtK,YAAY8W,sBAElE,OAAOjlB,KAAKslB,oBAAoBtlB,KAC3BulB,+BAA+BlN,EAAOuM,EAAKC,EAAeC,GACnE,CACK,GAAID,EAAe,CACpB,GAAI/T,EACA,MAAM,IAAI2H,EAAwB5K,WAAW,0DAA0DrG,KAAKsG,UAAUjQ,MAAW4a,EAAwBtK,YAAY8W,sBAEzK,MAAO,CAACjlB,KAAKnB,YAAY+B,QAAQgkB,EAAKC,GAC1C,CACK,GAAIC,GAAkB9kB,KAAKyZ,eAAe2H,aAAc,CACzD,GAAItQ,EACA,MAAM,IAAI2H,EAAwB5K,WAAW,2DAA2DrG,KAAKsG,UAAUjQ,MAAW4a,EAAwBtK,YAAY8W,sBAE1K,OAAOjlB,KAAKslB,oBAAoBtlB,KAC3BulB,+BAA+BlN,EAAOuM,EAAKC,EAAeC,GACnE,CACK,GAAIhU,EAAW,CAChB,GAAyB,kBAAdA,EACP,MAAM,IAAI2H,EAAwB5K,WAAW,kDAAkDrG,KAAKsG,UAAUgD,MAAe2H,EAAwBtK,YAAYqX,qBAErK,MAAMC,EAAWzlB,KAAK0lB,sBAAsB/mB,EAASmS,GACrD,IAAK2U,EACD,MAAM,IAAIhN,EAAwB5K,WAAW,+BAA+BrG,KAAKsG,UAAUgD,MAAe2H,EAAwBtK,YAAYqX,qBAElJ,GAA0B,cAAtBC,EAAS7nB,SACT,MAAM,IAAI6a,EAAwB5K,WAAW,uBAAuB4X,EAAS7nB,cAAckT,IAAa2H,EAAwBtK,YAAYqX,qBAEhJ,MAAO,CAACxlB,KAAKnB,YAAY+B,QAAQgkB,EAAKa,GAC1C,CAEA,aAAazlB,KAAKwkB,YAAY,IAAI/L,EAAwBhH,wBAAwB,CAAC,GAAIlI,EAAKqb,EAAKvM,EAAOvQ,EAC5G,CACK,GAAI,SAAUjK,EAAO,CAEtB,GAAIwB,OAAOyI,KAAKjK,GAAOI,OAAS,EAC5B,MAAM,IAAIwa,EAAwB5K,WAAW,6DAA6DtE,KAAQkP,EAAwBtK,YAAYwX,4BAG1J,MAAO,EACX,CACK,GAAI,UAAW9nB,EAAO,CAEvB,GAAIwB,OAAOyI,KAAKjK,GAAOI,OAAS,EAC5B,MAAM,IAAIwa,EAAwB5K,WAAW,8DAA8DtE,KAAQkP,EAAwBtK,YAAYwX,4BAE3J,MAAMC,EAAY/nB,EAAM,SAGxB,OAAIyG,MAAMC,QAAQqhB,GACW,IAArBA,EAAU3nB,OACH,CAAC+B,KAAKwb,QAGNxb,KAAKyZ,eAAemC,QAAQvD,EAAQ,IAAM,SAKxCrY,KAAKwkB,kBAAkBxkB,KAAKyZ,eAAexB,WAAWnQ,GAAOyB,EAAKqc,EAAWvN,EAAQ,EAAGvQ,EAAK9J,MAAM,GAAI,GAE5H,CACK,GAAI,aAAcH,GAAsC,mBAAtBA,EAAM,YAGzC,MAAO,GAEN,GAAI,WAAYkQ,EAAK4V,+BAA+B3jB,KAAKyZ,eAAexB,WAAWnQ,GAAOyB,GAAM,CAEjG,MAAMsc,EAAwB7lB,KAAKyZ,eAAemE,wBAAwBvF,EAAQ,GAClF,OAAOwN,EAAwBxmB,OAAO2I,OAAO6d,GAAyB,CAAC7lB,KAAKnB,YAAY8B,YAC5F,CACK,MAAI,QAAS9C,GAEVwB,OAAOyI,KAAKjK,GAAOI,OAAS,IAC5BU,QAAgBqB,KAAKyZ,eAAexB,WAAWnQ,EAAM,IAGrD,aAAcjK,IACdc,QAAgBqB,KAAKyZ,eAAegI,aAAa5jB,EAAM,YAAac,EAAQiQ,kBAEzD,WAAnB/Q,EAAM,SACCmC,KAAKslB,oBAAoBtlB,KAAK0lB,sBAAsB/mB,EAASd,EAAM,SAGnEmC,KAAKslB,oBAAoBtlB,KAAK8lB,eAAennB,EAASd,EAAM,UAKnEmC,KAAKyZ,eAAe6C,aAAajE,EAAQ,IACrCxa,GAA0B,kBAAVA,GAAoD,IAA9BwB,OAAOyI,KAAKjK,GAAOI,OACrD+B,KAAKyZ,eAAemC,QAAQvD,EAAQ,KACpCrY,KAAKyZ,eAAemC,QAAQvD,EAAQ,GAAK,CAACrY,KAAKnB,YAAY8B,cAG5D,GAGnB,IAAK,SACD,OAAOX,KAAKslB,oBAAoBtlB,KAAK+lB,kBAAkB1N,QAAarY,KAAK0kB,+BAA+B/lB,EAAS4K,GAAMA,EAAK1L,EAAO,OACvI,IAAK,UACD,OAAOmC,KAAKslB,oBAAoBtlB,KAAK+lB,kBAAkB1N,QAAarY,KAAK0kB,+BAA+B/lB,EAAS4K,GAAMA,EAAK6N,QAAQvZ,GAAOuF,WAAYpD,KAAKnB,YAAYd,UAAUgQ,EAAKiY,eAC3L,IAAK,SACD,OAAOhmB,KAAKslB,oBAAoBtlB,KAAK+lB,kBAAkB1N,QAAarY,KAAK0kB,+BAA+B/lB,EAAS4K,GAAMA,EAAK1L,EAAOmC,KAAKnB,YAAYd,UAAUF,EAAQ,IAAM,GAAKA,EAAQ,KAAOkQ,EAAKkY,YAAclY,EAAKmY,cAC5N,QAEI,OADAlmB,KAAKyZ,eAAegJ,UAAU,IAAI7gB,MAAM,yCAAyCsF,MAC1E,GAEnB,CAUA,oCAAMwd,CAA+B/lB,EAAS4K,GAC1C,MAAMyY,EAAkBrjB,EAAQiQ,gBAAgBrF,GAIhD,OAHIyY,GAA8C,kBAApBA,GAAgC,aAAcA,IACxErjB,QAAgBqB,KAAKyZ,eAAegI,aAAaO,EAAiBrjB,EAAQiQ,iBAAiB,IAExFjQ,CACX,CAKA,mBAAA2mB,CAAoB3nB,GAChB,OAAOA,EAAO,CAACA,GAAQ,EAC3B,CAQA,eAAAwoB,CAAgBxnB,EAAS4K,GACrB,MAAM6c,EAAWznB,EAAQ6Q,WAAWjG,GAAK,EAAMvJ,KAAKyZ,eAAemJ,oBAEnE,OAAKwD,EAIe,MAAhBA,EAAS,IAA8B,MAAhBA,EAAS,GAC5BpmB,KAAKyZ,eAAeyH,sBACblhB,KAAKnB,YAAY8B,UAAUylB,EAASrV,OAAO,IAG3C,KAIXhD,EAAK2B,WAAW0W,GACTpmB,KAAKnB,YAAYd,UAAUqoB,GAG9BA,GAAYpmB,KAAKyZ,eAAevL,cAChClO,KAAKyZ,eAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,0BAA0BuY,IAAY3N,EAAwBtK,YAAYK,sBAMhJ,MAHQ,KApBJ,IAwBf,CAQA,cAAAsX,CAAennB,EAAS4K,GACpB,GAAIA,EAAIzL,WAAW,MACf,OAAOkC,KAAKnB,YAAY8B,UAAU4I,EAAIwH,OAAO,IAEjD,MAAMtR,EAAMd,EAAQ6Q,WAAWjG,GAAK,EAAOvJ,KAAKyZ,eAAemJ,oBAC/D,IAAK7U,EAAK2B,WAAWjQ,GAAM,CACvB,IAAIA,IAAOO,KAAKyZ,eAAevL,aAI3B,OAAO,KAHPlO,KAAKyZ,eAAegJ,UAAU,IAAI7gB,MAAM,yBAAyBnC,KAKzE,CACA,OAAOO,KAAKnB,YAAYd,UAAU0B,EACtC,CASA,qBAAAimB,CAAsB/mB,EAAS4K,GAC3B,GAAIA,EAAIzL,WAAW,MACf,OAAOkC,KAAKnB,YAAY8B,UAAU4I,EAAIwH,OAAO,IAEjD,MAAMV,EAAgBrQ,KAAKyZ,eAAemJ,mBAC1C,IAAIwD,EAAWznB,EAAQ6Q,WAAWjG,GAAK,EAAM8G,GAI7C,GAHI+V,IAAa7c,IACb6c,EAAWznB,EAAQ6Q,WAAWjG,GAAK,EAAO8G,KAEzCtC,EAAK2B,WAAW0W,GAAW,CAC5B,IAAIA,IAAYpmB,KAAKyZ,eAAevL,cAAiBkY,EAAStoB,WAAW,KAIrE,OAAO,KAHPkC,KAAKyZ,eAAegJ,UAAU,IAAI7gB,MAAM,qBAAqBwkB,KAKrE,CACA,OAAOpmB,KAAKnB,YAAYd,UAAUqoB,EACtC,CAOA,WAAAC,CAAYxoB,EAAO2D,GACf,GAAqB,kBAAV3D,EAAoB,CAC3B,GAAIyoB,OAAOC,SAAS1oB,GAAQ,CACxB,MAAM2oB,EAAY3oB,EAAQ,IAAM,EAChC,OAAI2oB,GAAehlB,GAAYA,EAAS3D,QAAUkQ,EAAKmY,WAI5CroB,EAAM4oB,cAAc,IAAIzd,QAAQ,aAAc,OAH9Csd,OAAOzoB,GAAOuF,UAK7B,CAEI,OAAOvF,EAAQ,EAAI,MAAQ,MAEnC,CAEI,OAAOA,CAEf,CAUA,iBAAAkoB,CAAkB1N,EAAO1Z,EAAS4K,EAAK1L,EAAO6oB,GAE1C,MAAMC,EAAc5Y,EAAK6V,oBAAoBjlB,EAAS4K,GACtD,GAAIod,EACA,GAAoB,QAAhBA,GACA,IAAKD,EACD,OAAO1mB,KAAK8lB,eAAennB,EAASqB,KAAKqmB,YAAYxoB,EAAO6oB,SAG/D,GAAoB,WAAhBC,GACL,IAAKD,EACD,OAAO1mB,KAAK0lB,sBAAsB/mB,EAASqB,KAAKqmB,YAAYxoB,EAAO6oB,SAIvEA,EAAkB1mB,KAAKnB,YAAYd,UAAU4oB,GAIrD,IAAKD,EAAiB,CAClB,MAAME,EAAkB7Y,EAAK8V,wBAAwBllB,EAAS4K,GACxDsd,EAAmB9Y,EAAK+V,yBAAyBnlB,EAAS4K,GAChE,OAAIsd,GAAoB7mB,KAAKyZ,eAAe2H,aACjCphB,KAAKulB,+BAA+BlN,EAAOrY,KAAKqmB,YAAYxoB,EAAO6oB,GAAkBE,EAAiBC,GAGtG7mB,KAAKnB,YAAY+B,QAAQZ,KAAKqmB,YAAYxoB,EAAO6oB,GAAkBE,EAElF,CAEA,OAAO5mB,KAAKnB,YAAY+B,QAAQZ,KAAKqmB,YAAYxoB,EAAO6oB,GAAkBA,EAC9E,CAUA,8BAAAnB,CAA+BlN,EAAOxa,EAAO0D,EAAUulB,GACnD,GAAyC,kBAArC9mB,KAAKyZ,eAAe2H,aAKpB,OAHK7f,IACDA,EAAW,IAERvB,KAAKnB,YAAY+B,QAAQ/C,EAAOmC,KAAKnB,YAAYd,UAAU,8BAA8BwD,KAAYulB,MAE3G,CAED,MAAMC,EAAY/mB,KAAKnB,YAAY8B,YAC7BnC,EAAQwB,KAAKyb,kBAMnB,OALAzb,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAKnB,YAAYT,KAAK2oB,EAAW/mB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,SAAUpjB,KAAKnB,YAAY+B,QAAQ/C,GAAQW,IAClJ+C,GACAvB,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAKnB,YAAYT,KAAK2oB,EAAW/mB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,YAAapjB,KAAKnB,YAAY+B,QAAQW,GAAW/C,IAEhKwB,KAAKyZ,eAAe+E,SAASnG,EAAOrY,KAAKnB,YAAYT,KAAK2oB,EAAW/mB,KAAKnB,YAAYd,UAAUgQ,EAAKqV,IAAM,aAAcpjB,KAAKnB,YAAY+B,QAAQkmB,GAAYtoB,IACvJuoB,CACX,CACJ,CAMA,iBAAAtC,CAAkB5mB,GACd,OAAOqlB,EAAiBrlB,EAC5B,CAYA,oBAAMse,CAAe5S,EAAKzB,EAAMuQ,EAAO2O,EAAcroB,GAEjD,GAAI2nB,OAAOE,UAAUjd,GACjB,OAAOA,EAGX,IAAKyd,EAAc,CACf,MAAMC,EAAyBjnB,KAAKyZ,eAAegE,2BAA2BpF,GAC9E,GAAI4O,EACA,OAAOA,CAEf,CACA,IAAKxO,EAAwB1K,KAAKU,mBAAmBlF,GAAM,CACvD5K,EAAUA,SAAiBqB,KAAKyZ,eAAexB,WAAWnQ,GAC1D,IAAIof,EAAWvoB,EAAQiQ,gBAAgBrF,GACnC2d,GAAgC,kBAAbA,IACnBA,EAAWA,EAAS,QAEpBzO,EAAwB1K,KAAKQ,eAAe2Y,KAC5C3d,EAAM2d,EAEd,CACA,OAAOF,EAAezd,EAAOvJ,KAAKyZ,eAAegE,2BAA2BpF,GAAS9O,CACzF,CAQA,0BAAM8S,CAAqBvU,EAAMuQ,GAC7B,aAAarY,KAAKmc,eAAe9D,EAAQ,GAAKvQ,EAAKuQ,EAAQ,GAAIvQ,EAAMuQ,EAAQ,EACjF,CAUA,qBAAMsM,CAAgBwC,EAAMrf,EAAMuQ,EAAO1Z,GACrC,MAAMyoB,EAAU,CAAC,EACjB,IAAK,MAAM7d,KAAO4d,EACdC,QAAcpnB,KAAKmc,eAAe5S,EAAKzB,EAAMuQ,EAAQ,GAAG,EAAM1Z,IAAYwoB,EAAK5d,GAEnF,OAAO6d,CACX,CASA,SAAAnK,CAAU5E,GACN,IAAK,IAAIpS,EAAIoS,EAAOpS,GAAK,EAAGA,IACxB,GAAIjG,KAAKyZ,eAAeqE,aAAa7X,IAAMjG,KAAKyZ,eAAeoE,iBAAiB5X,GAC5E,OAAO,EAGf,OAAO,CACX,CAQA,yBAAMkY,CAAoB9F,EAAOvQ,GAC7B,IAAK,IAAI7B,EAAIoS,EAAQ,EAAGpS,EAAI,EAAGA,IAC3B,GAAoD,iBAA1CjG,KAAKmc,eAAerU,EAAK7B,GAAI6B,EAAM7B,GAAiB,CAE1D,MAAMohB,SAAoBzO,EAAwBmD,sBAAsBuL,oBAAoBtnB,KAAKyZ,eAAgB3R,EAAM7B,IAAIohB,WAC3H,OAAIzO,EAAwBmD,sBAAsBwL,wBAAwBF,IAC9D,EAELhP,EAAQpS,EAAI,CACvB,CAEJ,OAAQ,CACZ,CAMA,sBAAAuhB,CAAuBnpB,GACnB,GAAyB,YAArBA,EAAQT,SACR,MAAM,IAAI6a,EAAwB5K,WAAW,8CAA8CxP,EAAQR,QAAS4a,EAAwBtK,YAAYsZ,+BAExJ,CAKA,eAAAhM,GACI,OAAOzb,KAAKyZ,eAAezY,cAAgBhB,KAAKnB,YAAYmC,cAChE,CAOA,4BAAMqd,CAAuBvW,EAAMuQ,GAE/B,IAAI7Z,EAAQwB,KAAKyb,kBAEjB,MAAM,WAAE4L,EAAYhP,MAAOqP,SAAyB9O,EAAwBmD,sBACvEuL,oBAAoBtnB,KAAKyZ,eAAgB3R,EAAMuQ,GACpD,GAAI,WAAYgP,EAAY,CAExB,MAAMM,EAAsB/O,EAAwBmD,sBAAsB6L,uBAAuBP,EAAYK,EAAgB5f,GACvH4b,EAAQ1jB,KAAKyZ,eAAemE,wBAAwB8J,GAG1D,GAFAlpB,EAAQklB,EAAQA,EAAMiE,GAAuB,MAExCnpB,EAAO,CACR,IAAIqpB,EAAU,KACd,GAAI,QAASR,EAAY,CACrB,MAAMS,QAAqB9nB,KAAK+nB,gBAAgBjgB,EAAK4f,GAAiB5f,EAAM4f,GACvD,OAAjBI,IACAD,QAAgB7nB,KAAK8lB,qBAAqB9lB,KAAKyZ,eAAexB,WAAWnQ,GAAOggB,GAExF,CACKD,IACDA,EAAU7nB,KAAKnB,YAAY8B,aAE1BX,KAAKyZ,eAAemE,wBAAwB8J,KAC7C1nB,KAAKyZ,eAAemE,wBAAwB8J,GAAkB,CAAC,GAEnElpB,EAAQwB,KAAKyZ,eAAemE,wBAAwB8J,GAAgBC,GAAuBE,CAC/F,CACJ,CACA,OAAOrpB,CACX,CAeA,wBAAMwpB,CAAmBlgB,EAAMuQ,GAC3B,IAAI4P,EAAiB5P,EACrB,IAAK,IAAIpS,EAAIoS,EAAQ,EAAGpS,EAAI,EAAGA,IAC3B,GAAuB,kBAAZ6B,EAAK7B,GAAiB,CAC7B,MAAMmW,QAAkBpc,KAAKmc,eAAerU,EAAK7B,GAAI6B,EAAM7B,GAC3D,GAAkB,aAAdmW,EACA,OAAOnW,EAEN,GAAkB,UAAdmW,EAIL,OAAO6L,EAHPA,EAAiBhiB,CAKzB,CAEJ,OAAOgiB,CACX,CASA,qBAAMF,CAAgBxe,EAAKzB,EAAMuQ,GAC7B,MAAMyP,QAAqB9nB,KAAKmc,eAAe5S,EAAKzB,EAAMuQ,GAC1D,MAAwB,UAAjByP,EAA2B,KAAOA,CAC7C,EAEJ1qB,EAAQ2Q,KAAOA,EACfA,EAAKma,IAAM,oCACXna,EAAKiY,YAAcjY,EAAKma,IAAM,UAC9Bna,EAAKkY,YAAclY,EAAKma,IAAM,UAC9Bna,EAAKmY,WAAanY,EAAKma,IAAM,SAC7Bna,EAAKqV,IAAM,6C,kCC5xBX/jB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ+qB,gCAA6B,EAOrC,MAAMA,EACF,mBAAAC,GACI,OAAO,CACX,CACA,YAAM/K,CAAOgK,EAAY5N,EAAgBE,EAAM7R,EAAMjK,EAAOwa,GACxD,IAAItY,EAEJ,GAAI0Z,EAAe6C,aAAajE,EAAQ,IAAMoB,EAAemC,QAAQvD,EAAQ,GAEzEtY,EAAK0Z,EAAemC,QAAQvD,EAAQ,GAAG,OAEtC,CAED,MAAMyP,QAAqBnO,EAAKoO,gBAAgBjgB,EAAKuQ,GAAQvQ,EAAMuQ,GAC7DgQ,EAA2B,OAAjBP,QACJnO,EAAKmM,qBAAqBrM,EAAexB,WAAWnQ,GAAOA,EAAKuQ,IACtEsB,EAAK9a,YAAY8B,YAEvB,IAAK0nB,EAED,YADA5O,EAAe6C,aAAajE,IAAS,GAGzCtY,EAAKsoB,EAEL5O,EAAemC,QAAQvD,EAAQ,GAAK,CAACtY,EACzC,CAGA,IAAIuoB,EAAM7O,EAAemC,QAAQvD,GAC5BiQ,IACDA,EAAM7O,EAAemC,QAAQvD,GAAS,IAGrCiQ,EAAIC,MAAM5qB,GAASA,EAAKuC,OAAOH,MAChCuoB,EAAIvgB,KAAKhI,SAGF0Z,EAAe8I,uCACtB9I,EAAe6C,aAAajE,IAAS,EAE7C,EAEJjb,EAAQ+qB,2BAA6BA,C,qCClDrC9oB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQorB,2BAAwB,EAChC,MAAM/P,EAA0B,EAAQ,OAClCK,EAA0B,EAAQ,OAClC7L,EAAS,EAAQ,OAMvB,MAAMub,EACF,mBAAAJ,GACI,OAAO,CACX,CACA,YAAM/K,CAAOgK,EAAY5N,EAAgBE,EAAM7R,EAAMjK,EAAOwa,GACxD,IAAK/T,MAAMC,QAAQ1G,GAAQ,CACvB,MAAM4qB,EAAiB,WAAYpB,EAE7B1oB,QAAgB8a,EAAexB,WAAWnQ,GAC1C4gB,EAAW5gB,EAAKuQ,EAAQ,GACxBsQ,EAAmB1b,EAAOc,KAAKiW,qBAAqBrlB,EAAS+pB,GACnE,GAAIC,EAAkB,CAElB,GAAIlQ,EAAwB1K,KAAKU,mBAAmBka,GAChD,MAAM,IAAIlQ,EAAwB5K,WAAW,kDAAkD8a,IAAoBlQ,EAAwBtK,YAAYkB,yBAE3J,GAAgC,kBAArBsZ,EACP,MAAM,IAAIlQ,EAAwB5K,WAAW,uCAAuC8a,IAAoBlQ,EAAwBtK,YAAYkB,yBAGhJ,GAAqB,kBAAVxR,EAAoB,CAE3B,GAA2D,QAAvDoP,EAAOc,KAAK6V,oBAAoBjlB,EAAS+pB,GACzC,MAAM,IAAIjQ,EAAwB5K,WAAW,gGAAgGhQ,IAAS4a,EAAwBtK,YAAY8W,sBAG9L,MAAMllB,EAAK4Z,EAAKmM,eAAennB,EAASd,GACpCkC,IACA0Z,EAAemC,QAAQvD,EAAQ,GAAK,CAACtY,GAE7C,CAEA,MAAM6oB,EAAgBjP,EAAK+L,sBAAsB/mB,EAASgqB,GAC1D,GAAIC,EAAe,CACf,MAAMC,QAAoBlP,EAAK6K,YAAY7lB,EAASgqB,QAAwBhP,EAAKoO,gBAAgBjgB,EAAKuQ,GAAQvQ,EAAMuQ,GAAQA,EAAOvQ,GACnI,GAAI2gB,EAAgB,CAEhB,MAAMZ,QAAgBlO,EAAK0E,uBAAuBvW,EAAMuQ,EAAQ,GAChE,IAAK,MAAMyQ,KAAcD,EACrBpP,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKypB,EAASe,EAAeE,EAAYnP,EAAK8B,mBAEtG,MAGI,IAAK,MAAMqN,KAAcD,QACf/P,EAAwB8H,sBAAsBmI,sBAAsBtP,EAAgBE,EAAM7R,EAAMuQ,EAAQ,EAAGuQ,EAAeE,GAAY,EAGxJ,CACJ,CACA,MAAM/F,EAAc0F,EAAiB,EAAI,QACnChP,EAAeyB,cAAcpT,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS8kB,GAAcllB,EAAOwa,EAAQ0K,GAAa,SAEnGtJ,EAAe8I,oCACzB,CACA9I,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQorB,sBAAwBA,C,qCCpEhCnpB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ4rB,8BAA2B,EACnC,MAAMvQ,EAA0B,EAAQ,OAOxC,MAAMuQ,EACF,mBAAAZ,GACI,OAAO,CACX,CACA,YAAM/K,CAAOgK,EAAY5N,EAAgBE,EAAM7R,EAAMjK,EAAOwa,GACxD,MAAM9W,QAAiBoY,EAAKoO,gBAAgBjgB,EAAKuQ,GAAQvQ,EAAMuQ,GAC/D,GAAI/T,MAAMC,QAAQ1G,GAEdA,EAAQA,EAAMuG,KAAK4gB,IAAa,CAAG,SAAUA,EAAU,YAAazjB,UAEnE,CACD,GAAqB,kBAAV1D,EACP,MAAM,IAAI4a,EAAwB5K,WAAW,wCAAwCrG,KAAKsG,UAAUjQ,2BAAgC4a,EAAwBtK,YAAY8a,4BAE5KprB,EAAQ,CAAE,SAAUA,EAAO,YAAa0D,EAC5C,OACMkY,EAAeyB,cAAcpT,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAAIJ,EAAOwa,EAAQ,GAAG,GACrFoB,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQ4rB,yBAA2BA,C,qCC7BnC3pB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ8rB,0BAAuB,EAC/B,MAAMpQ,EAA0B,EAAQ,OAClC7L,EAAS,EAAQ,OAMvB,MAAMic,EACF,mBAAAd,GACI,OAAO,CACX,CACA,YAAM/K,CAAOgK,EAAY5N,EAAgBE,EAAM7R,EAAMjK,EAAOwa,GACxD,IAAK/T,MAAMC,QAAQ1G,GAAQ,CACvB,GAAqB,kBAAVA,EAAoB,CAE3B,MAAMc,QAAgB8a,EAAexB,WAAWnQ,GAC1CqhB,EAAoBlc,EAAOc,KAAK6V,oBAAoBjlB,EAASmJ,EAAKuQ,EAAQ,IAE1EtY,EAA2B,WAAtBopB,QACCxP,EAAK+L,sBAAsB/mB,EAASd,SACpC8b,EAAKmM,eAAennB,EAASd,GACzC,GAAIkC,EAAI,CAEJ,MAAMilB,EAAW,CAAE,MAAuB,cAAhBjlB,EAAGnC,SAA2BmC,EAAGlC,MAAQA,SAC7D4b,EAAeyB,cAAcpT,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAAI+mB,EAAU3M,EAAQ,GAAG,GAExFoB,EAAemC,QAAQvD,EAAQ,GAAK,CAACtY,EACzC,CACJ,KACK,CAGD,MAAMqpB,IAAuB3P,EAAemC,QAAQvD,EAAQ,GAEvD+Q,UACM3P,EAAemC,QAAQvD,SAE5BoB,EAAeyB,cAAcpT,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAAIJ,EAAOwa,EAAQ,GAAG,GAChF+Q,IACD3P,EAAemC,QAAQvD,EAAQ,GAAKoB,EAAemC,QAAQvD,GAEnE,CAEA,MAAMgR,QAAoB1P,EAAKoO,gBAAgBjgB,EAAKuQ,GAAQvQ,EAAMuQ,GAC5DnR,EAAuB,OAAhBmiB,EACP1P,EAAK+L,4BAA4BjM,EAAexB,WAAWnQ,GAAOuhB,GAClE,KACFniB,SAEM4R,EAAwB8H,sBAAsBmI,sBAAsBtP,EAAgBE,EAAM7R,EAAMuQ,EAAQ,EAAGsB,EAAK0J,QAASnc,GAAM,SAGnIuS,EAAe8I,oCACzB,CACA9I,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQ8rB,qBAAuBA,C,qCC3D/B7pB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ+iB,4BAAyB,EACjC,MAAMlT,EAAS,EAAQ,OAIvB,MAAMkT,EACF,iBAAArB,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,OAAOzc,KAAKuD,KAAKkW,EAAgBE,EAAM,KAAM7R,EAAMuQ,EACvD,CACA,UAAM9U,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,MAA8B,kBAAhBvQ,EAAKuQ,EACvB,CACA,YAAMgF,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GACjD,IAAI+D,QAAkBzC,EAAK0C,qBAAqBvU,EAAMuQ,GAEtD,GAAkB,UAAd+D,EAAuB,CAGvB,IAAIkN,EAAc,KACdzN,EAAgB,EACpB,IAAK,IAAI5V,EAAIoS,EAAQ,EAAGpS,EAAI,EAAGA,IAAK,CAChC,MAAMsjB,EAAYzhB,EAAK7B,GACvB,GAAyB,kBAAdsjB,GAA+C,kBAAdA,EAAwB,CAChE1N,EAAgB5V,EAChBqjB,EAAcC,EACd,KACJ,CACJ,CACA,GAAoB,OAAhBD,EAAsB,CAEtB,MAAMthB,QAAe2R,EAAK6K,kBAAkB/K,EAAexB,WAAWnQ,GAAOwhB,EAAazrB,EAAOwa,EAAOvQ,GACxG,IAAK,MAAMvJ,KAAUyJ,QACXhI,KAAKwpB,kBAAkB/P,EAAgBE,EAAMpb,EAAQV,EAAOwa,EAAOvQ,EAAK9J,MAAM,EAAG6d,GAAgBA,GAGrF,IAAlB7T,EAAO/J,cACD+B,KAAKwpB,kBAAkB/P,EAAgBE,EAAM,KAAM9b,EAAOwa,EAAOvQ,EAAK9J,MAAM,EAAG6d,GAAgBA,EAE7G,CACJ,MACK,GAAkB,SAAdO,QAEC3C,EAAeyB,cAAcpT,EAAK9J,MAAM,GAAI,GAAIH,EAAOwa,EAAQ,GAAG,QAEvE,QAAkBpU,IAAdmY,GAAyC,UAAdA,EAAuB,CAKvD,IAAK,IAAInW,EAAIoS,EAAQ,EAAGpS,EAAI,EAAGA,IAC3B,GAAuB,kBAAZ6B,EAAK7B,GAAiB,CAC7BmW,QAAkBzC,EAAKwC,eAAerU,EAAK7B,GAAI6B,EAAM7B,GACrD,KACJ,CAGJ,MAAMsM,QAAsBkH,EAAexB,WAAWnQ,EAAK9J,MAAM,GAAI,IACrE,GAAI,UAAWiP,EAAOc,KAAK4V,yBAAyBpR,EAAe6J,GAAY,CAG3E3C,EAAe6C,aAAajE,EAAQ,IAAK,EACzC,MAAMrQ,QAAe2R,EAAK6K,kBAAkB/K,EAAexB,WAAWnQ,GAAOsU,EAAWve,EAAOwa,EAAOvQ,GACtG,IAAK,MAAMvJ,KAAUyJ,QACXhI,KAAKwpB,kBAAkB/P,EAAgBE,EAAMpb,EAAQV,EAAOwa,EAAOvQ,EAAK9J,MAAM,GAAI,GAAIqa,EAAQ,GAGlF,IAAlBrQ,EAAO/J,cACD+B,KAAKwpB,kBAAkB/P,EAAgBE,EAAM,KAAM9b,EAAOwa,EAAOvQ,EAAK9J,MAAM,GAAI,GAAIqa,EAAQ,EAE1G,MAGIoB,EAAeqJ,WAAWzK,EAAO,SAE3BoB,EAAeyB,cAAcpT,EAAK9J,MAAM,GAAI,GAAIH,EAAOwa,EAAQ,GAAG,GAExEoB,EAAe2F,YAAY7G,cAAczQ,EAAK9J,MAAM,GAAI,GAEhE,CACJ,CACA,uBAAMwrB,CAAkB/P,EAAgBE,EAAM9b,EAAO4rB,EAAepR,EAAOqR,EAAc7N,GAErF,IAAIR,EAAc5B,EAAe6B,iBAAiBjD,GAClD,GAAsB,OAAlBoR,GAAyG,cAAxE9P,EAAKgL,gBAAgB8E,EAAeC,EAAcrR,IAAQ,UAAoB,CAC/G,GAAKgD,GAAgBA,EAAYxd,MAI5B,CAID,MAAM8rB,EAAchQ,EAAK9a,YAAY8B,YACrC8Y,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKid,EAAYxd,MAAO8b,EAAK4B,QAASoO,EAAahQ,EAAK8B,oBAExGJ,EAAYxd,MAAQ8rB,CACxB,KAZwC,CACpC,MAAMC,EAAWjQ,EAAK9a,YAAY8B,YAClC0a,EAAc,CAAExd,MAAO+rB,EAAU/N,gBAAeH,OAAQkO,EAC5D,CAYI/rB,GACA4b,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKid,EAAYxd,MAAO8b,EAAKwJ,SAAUtlB,EAAO8b,EAAK8B,mBAE3G,MAISJ,IACDA,EAAc,CAAEQ,gBAAeH,OAAQ/B,EAAK6B,SAGpD/B,EAAe6B,iBAAiBjD,GAASgD,CAC7C,EAEJje,EAAQ+iB,uBAAyBA,C,qCCxHjC9gB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ2e,2BAAwB,EAChC,MAAM8N,EAA+B,EAAQ,MACvCC,EAA0B,EAAQ,OAClCC,EAA6B,EAAQ,OACrCC,EAAyB,EAAQ,OACjC/c,EAAS,EAAQ,OAKvB,MAAM8O,EAMF,6BAAOkO,CAAuB5C,GAC1B,MAAO,WAAYA,IACV,SAAUA,GAAiD,IAAnChoB,OAAOyI,KAAKuf,GAAYppB,QAAoD,IAAnCoB,OAAOyI,KAAKuf,GAAYppB,OACtG,CAMA,8BAAOspB,CAAwBF,GAC3B,MAAO,WAAYA,IACV,SAAUA,GAAchoB,OAAOyI,KAAKuf,GAAYppB,OAAS,KACpD,SAAUopB,IAAehoB,OAAOyI,KAAKuf,GAAYppB,OAAS,EAC5E,CAQA,6BAAO2pB,CAAuBP,EAAYhP,EAAOvQ,GAC7C,IAAImiB,EAAyBlO,EAAsBkO,uBAAuB5C,GACtEhD,EAAQ,GACZ,IAAK,IAAIpe,EAAIoS,EAAOpS,EAAI6B,EAAK7J,OAAQgI,IAC5BgkB,GAA6C,kBAAZniB,EAAK7B,KACvCoe,GAAS,IAAMvc,EAAK7B,IAGnBgkB,GAA6C,kBAAZniB,EAAK7B,KACvCgkB,GAAyB,GAGjC,OAAO5F,CACX,CAeA,gCAAaiD,CAAoB7N,EAAgB3R,EAAMuQ,GACnD,MAAMoL,EAAW,CACb4D,WAAY,CAAE,QAAQ,GACtBhP,QACAoL,UAAU,GAGd,IAAIyG,GAAsB,EAE1B,MAAMvrB,QAAgB8a,EAAexB,WAAWnQ,EAAM,GACtD,IAAK,IAAI7B,EAAIoS,EAAQ,EAAGpS,GAAK,EAAGA,IAC5B,GAAuB,kBAAZ6B,EAAK7B,GAAiB,CAE7B,MAAMkkB,EAAiBld,EAAOc,KAAKwV,gBAAgB5kB,EAAS,aAAcmJ,EAAK7B,IAAI,GACnF,GAAIkkB,GAAkBpO,EAAsBkO,uBAAuBE,GAC/D,MAAO,CACH9C,WAAY8C,EACZ9R,MAAOpS,EAAI,EACXwd,UAAU,GAGlB,MAAM2G,EAAmBnd,EAAOc,KAAKwV,gBAAgB5kB,EAAS,aAAcmJ,EAAK7B,EAAI,IAAI,GACzF,GAAKmkB,EAQA,CAED,MAAM3B,EAAiB,WAAY2B,EAEnC,IAAK,MAAMC,KAAuBtO,EAAsBuO,mBACpD,GAAIF,EAAiBC,GACjB,OAAI5B,EAEI1M,EAAsBuO,mBAAmBD,GAAqBjC,sBACvD,CACHf,WAAY+C,EACZ/R,MAAOpS,EACPwd,UAAU,GAIPA,EAKPyG,EACOzG,EAGA,CACH4D,WAAY+C,EACZ/R,MAAOpS,EACPwd,UAAU,GAO9B,OAAOA,CACX,CA3CI,GAAIyG,EAEA,OAAOzG,EAGXyG,GAAsB,CAuC9B,CAEJ,OAAOzG,CACX,CAeA,yCAAazH,CAA6BvC,EAAgB3R,EAAMuQ,GAC5D,MAAMkS,QAAgBxO,EAAsBuL,oBAAoB7N,EAAgB3R,EAAMuQ,GACtF,OAAQkS,EAAQ9G,YAAc,WAAY8G,EAAQlD,WACtD,CACA,iBAAAvI,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,cAAezc,KAAKuD,KAAKkW,EAAgBE,EAAM,KAAM7R,EAAMuQ,EAC/D,CACA,UAAM9U,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,MAAMgP,EAAapa,EAAOc,KAAK4V,+BAA+BlK,EAAexB,WAAWnQ,EAAM,GAAIA,EAAKuQ,EAAQ,IAC/G,IAAK,MAAMmS,KAAiBzO,EAAsBuO,mBAC9C,GAAIjD,EAAWmD,GACX,MAAO,CACHnD,aACAkD,QAASxO,EAAsBuO,mBAAmBE,IAI9D,OAAO,IACX,CACA,YAAMnN,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,EAAO+E,GACxD,OAAOA,EAAWmN,QAAQlN,OAAOD,EAAWiK,WAAY5N,EAAgBE,EAAM7R,EAAMjK,EAAOwa,EAC/F,EAEJjb,EAAQ2e,sBAAwBA,EAChCA,EAAsBuO,mBAAqB,CACvC,MAAO,IAAIT,EAA6B1B,2BACxC,SAAU,IAAI2B,EAAwBtB,sBACtC,YAAa,IAAIuB,EAA2Bf,yBAC5C,QAAS,IAAIgB,EAAuBd,qB,mCCzLxC7pB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQyjB,iCAA8B,EAKtC,MAAMA,EACF,iBAAA/B,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,OAAO,CACX,CACA,UAAMlZ,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,OAAO,CACX,CACA,YAAMgF,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GACjDoB,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQyjB,4BAA8BA,C,qCCvBtCxhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQwjB,2BAAwB,EAChC,MAAMnI,EAA0B,EAAQ,OAClCxL,EAAS,EAAQ,OAKvB,MAAM2T,EAaF,kCAAamI,CAAsBtP,EAAgBE,EAAM7R,EAAMuQ,EAAO/Z,EAAWC,EAAQggB,GACrF,MAAMkM,QAAwB9Q,EAAKqO,mBAAmBlgB,EAAMuQ,GACtD6F,QAAyBvE,EAAKwE,oBAAoB9F,EAAOvQ,GACzD4iB,EAAuBrS,EAAQ6F,EAC/BH,EAAWtE,EAAemC,QAAQ6O,GACxC,GAAI1M,EAEA,IAAK,MAAM1f,KAAW0f,EAAU,CAE5B,MAAM4M,EAAUzM,GAAoB,EACpC,GAAIyM,EAAS,CACT,MAAMvM,EAAS3E,EAAemC,QAAQ8O,EAAuB,GAC7D,GAAItM,EACA,IAAK,MAAM5f,KAAS4f,EAEZG,GACA5E,EAAK6N,uBAAuBjpB,GAC5Bkb,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKG,EAAQD,EAAWD,EAASG,KAGjFib,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKC,EAASC,EAAWC,EAAQC,SAMrF+f,GACA5E,EAAK6N,uBAAuBjpB,GAC5Bkb,EAAeiF,+BAA+BgM,EAAuB,GAAG3iB,KAAK,CAAE1J,QAASE,EAAQD,YAAWC,OAAQF,KAGnHob,EAAeiF,+BAA+BgM,EAAuB,GAChE3iB,KAAK,CAAE1J,UAASC,YAAWC,UAG5C,KACK,CAED,MAAMC,QAAcmb,EAAK0E,uBAAuBvW,EAAM2iB,GAClDlM,GACA5E,EAAK6N,uBAAuBjpB,GAC5Bkb,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKG,EAAQD,EAAWD,EAASG,KAGjFib,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKC,EAASC,EAAWC,EAAQC,GAEzF,CACJ,MAII+f,GACA5E,EAAK6N,uBAAuBjpB,GAEhCkb,EAAekJ,+BAA+B8H,GAAiB1iB,KAAK,CAAEzJ,YAAWC,SAAQggB,WAEjG,CACA,iBAAAO,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,MAAMlT,EAAMzB,EAAKuQ,GACjB,GAAI9O,EAAK,CACL,MAAM5K,QAAgB8a,EAAexB,WAAWnQ,GAChD,IAAK2R,EAAeoE,iBAAiBxF,UAAgBsB,EAAKwM,gBAAgBxnB,EAASmJ,EAAKuQ,IAKpF,MAHsD,UAAlDpL,EAAOc,KAAK6V,oBAAoBjlB,EAAS4K,KACzCkQ,EAAeoE,iBAAiBxF,EAAQ,IAAK,IAE1C,CAEf,CACA,OAAO,CACX,CACA,UAAM9U,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,OAAOvQ,EAAKuQ,EAChB,CACA,YAAMgF,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,EAAO+E,GACxD,MAAMiM,EAAcvhB,EAAKuQ,GACnB1Z,QAAgB8a,EAAexB,WAAWnQ,GAC1CxJ,QAAkBqb,EAAKwM,gBAAgBxnB,EAAS4K,GACtD,GAAIjL,EAAW,CACX,MAAMssB,QAAgBjR,EAAK6K,YAAY7lB,EAAS4K,EAAK1L,EAAOwa,EAAOvQ,GACnE,GAAI8iB,EAAQ3sB,OACR,IAAK,IAAIM,KAAUqsB,EAAS,CACxB,MAAMrM,EAAUtR,EAAOc,KAAKkW,kBAAkBtlB,EAAS0qB,QAAmB1P,EAAK0C,qBAAqBvU,EAAMuQ,IAC1G,GAAIxa,EAAO,CAGP,MAAMgtB,EAAqB,UAAW5d,EAAOc,KAAK4V,yBAAyBhlB,EAAS4K,GACpF,GAAIshB,GAAsBhtB,EAAM,SAAU,CACtC,IAAMgtB,IAAuBvmB,MAAMC,QAAQ1G,KAAWA,EAAM,UACpDA,EAAM,WAAayG,MAAMC,QAAQ1G,EAAM,YACxCU,IAAWob,EAAK6B,OAAQ,CAC3B,MAAMH,EAAc1B,EAAK9a,YAAY8B,YACrC8Y,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKid,EAAa1B,EAAK4B,QAAS5B,EAAK6B,OAAQ7B,EAAK8B,oBAClGhC,EAAe+E,SAASnG,EAAOsB,EAAK9a,YAAYT,KAAKid,EAAa1B,EAAKwJ,SAAU5kB,EAAQob,EAAK8B,oBAC9Fld,EAAS8c,CACb,CAEA,GAAIkD,IAAY9E,EAAe0H,iBAC3B,MAAM,IAAI1I,EAAwB5K,WAAW,mDAAmDtE,IAAOkP,EAAwBtK,YAAYsZ,+BAEnJ,CACJ,OACM7G,EAAsBmI,sBAAsBtP,EAAgBE,EAAM7R,EAAMuQ,EAAO/Z,EAAWC,EAAQggB,EAC5G,CAER,CACJ,EAEJnhB,EAAQwjB,sBAAwBA,C,kCCvIhCvhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQ0tB,yBAAsB,EAI9B,MAAMA,EACF,WAAA9tB,CAAYga,GACRhX,KAAKgX,QAAUA,CACnB,CACA,iBAAA8H,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,OAAO,CACX,CACA,UAAMlZ,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,OAAO9O,IAAQvJ,KAAKgX,OACxB,EAEJ5Z,EAAQ0tB,oBAAsBA,C,qCCtB9BzrB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQgjB,gCAA6B,EACrC,MAAM3H,EAA0B,EAAQ,OAClCsS,EAAwB,EAAQ,MAItC,MAAM3K,UAAmC2K,EAAsBD,oBAC3D,WAAA9tB,GACIE,MAAM,WACV,CACA,gBAAAogB,GACI,OAAO,CACX,CACA,YAAMD,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAE7CoB,EAAe3a,mBACX2a,EAAe8D,gBAAgBlF,IAC5BoB,EAAeiE,eAAerF,SACIpU,IAAlCwV,EAAemC,QAAQvD,KAC9BoB,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,yFAC5B4K,EAAwBtK,YAAY6c,8BAK5E,MAAMzY,EAAgBkH,EAAexB,WAAWnQ,GAE1CnJ,EAAU8a,EAAegI,aAAa5jB,SAAc0U,GAAe3D,iBACzE6K,EAAe2F,YAAY9G,WAAWxQ,EAAK9J,MAAM,GAAI,GAAIW,GACzD8a,EAAeiJ,YAAY7kB,SACrB4b,EAAepM,sBAAsB1O,EAC/C,EAEJvB,EAAQgjB,2BAA6BA,C,qCClCrC/gB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQmjB,8BAA2B,EACnC,MAAMwK,EAAwB,EAAQ,MAItC,MAAMxK,UAAiCwK,EAAsBD,oBACzD,WAAA9tB,GACIE,MAAM,SACV,CACA,YAAMmgB,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAEjDoB,EAAekE,WAAWtF,EAAQ,IAAK,CAC3C,EAEJjb,EAAQmjB,yBAA2BA,C,qCCfnClhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQijB,2BAAwB,EAChC,MAAM5H,EAA0B,EAAQ,OAClCsS,EAAwB,EAAQ,MAItC,MAAM1K,UAA8B0K,EAAsBD,oBACtD,WAAA9tB,GACIE,MAAM,MACV,CACA,gBAAAogB,GACI,OAAO,CACX,CACA,YAAMD,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAC5B,kBAAVxa,GACP4b,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,sBAAsBhQ,KAAU4a,EAAwBtK,YAAY8c,mBAIxI,MAAMR,QAAwB9Q,EAAKqO,mBAAmBlgB,EAAMuQ,QAEZpU,IAA5CwV,EAAemC,QAAQ6O,KACnBhR,EAAemC,QAAQ6O,GAAiB,GAAG9O,SAE3ClC,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,8DAA8D/F,EAAKuQ,EAAQ,MAAOI,EAAwBtK,YAAYwX,6BAItLlM,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,yBAAyB4L,EACpFmC,QAAQ6O,GAAiB,GAAG5sB,eAAeA,KAAU4a,EAAwBtK,YAAY+c,sBAItGzR,EAAemC,QAAQ6O,GAAmB9Q,EAAK2L,0BAA0B3L,EAAKmM,qBAAqBrM,EAAexB,WAAWnQ,GAAOjK,GACxI,EAEJT,EAAQijB,sBAAwBA,C,qCCrChChhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQkjB,iCAA8B,EACtC,MAAM7H,EAA0B,EAAQ,OAClCsS,EAAwB,EAAQ,MAItC,MAAMzK,UAAoCyK,EAAsBD,oBAC5D,WAAA9tB,GACIE,MAAM,YACV,CACA,YAAMmgB,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAC5B,kBAAVxa,GACP4b,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,4BAA4BhQ,KAAU4a,EAAwBtK,YAAYgd,yBAE9I,MAAMC,QAAsBzR,EAAKgL,gBAAgB9mB,EAAOiK,EAAMuQ,QAAaoB,EAAexB,WAAWnQ,IACjG,WAAYsjB,GACZ3R,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,2CAA2CrG,KAAKsG,UAAUjQ,MAAW4a,EAAwBtK,YAAYgd,yBAEzK,UAAWC,GACX3R,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,0CAA0CrG,KAAKsG,UAAUjQ,MAAW4a,EAAwBtK,YAAYgd,yBAE5K1R,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQkjB,4BAA8BA,C,qCCzBtCjhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQojB,6BAA0B,EAClC,MAAM/H,EAA0B,EAAQ,OAClCsS,EAAwB,EAAQ,MAItC,MAAMvK,UAAgCuK,EAAsBD,oBACxD,WAAA9tB,GACIE,MAAM,QACV,CACA,YAAMmgB,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAC5B,kBAAVxa,GACP4b,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,kCAAkCtE,QAAU1L,KAAU4a,EAAwBtK,YAAYiE,qBAE1J,iBAAkBuH,EAAKgL,gBAAgB9mB,EAAOiK,EAAMuQ,QAAaoB,EAAexB,WAAWnQ,KAC3F2R,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,qCAAqCtE,KAAQkP,EAAwBtK,YAAYiE,qBAErJqH,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQojB,wBAA0BA,C,qCCrBlCnhB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQqjB,6BAA0B,EAClC,MAAMhI,EAA0B,EAAQ,OAClCxL,EAAS,EAAQ,OACjB6L,EAA0B,EAAQ,OAClCiS,EAAwB,EAAQ,MAItC,MAAMtK,UAAgCsK,EAAsBD,oBACxD,WAAA9tB,GACIE,MAAM,QACV,CACA,gBAAAogB,GACI,OAAO,CACX,CACA,YAAMD,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GACjD,MAAMgR,EAAcvhB,EAAKuQ,GAInB1Z,QAAgB8a,EAAexB,WAAWnQ,GAC1CxJ,EAAYqb,EAAK0J,QACjB9E,EAAUtR,EAAOc,KAAKkW,kBAAkBtlB,EAAS0qB,QAAmB1P,EAAK0C,qBAAqBvU,EAAMuQ,IAEpGgT,EAAW/mB,MAAMC,QAAQ1G,GAASA,EAAQ,CAACA,GACjD,IAAK,MAAMytB,KAAWD,EAAU,CACL,kBAAZC,GACP7R,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,wBAAwByd,KAAY7S,EAAwBtK,YAAYod,qBAE5I,MAAMrkB,EAAOyS,EAAK+L,sBAAsB/mB,EAAS2sB,GAC7CpkB,SACM4R,EAAwB8H,sBAAsBmI,sBAAsBtP,EAAgBE,EAAM7R,EAAMuQ,EAAO/Z,EAAW4I,EAAMqX,EAEtI,CAEA,IAAI0D,EAAgBpd,QAAQI,QAAQtG,GAChC6sB,GAAwB,EAC5B,IAAK,MAAMF,KAAWD,EAASvL,OAAQ,CACnC,MAAM2L,EAAcxe,EAAOc,KAAKwV,gBAAgB5kB,EAAS,WAAY2sB,EAAS,MAC1EG,IACAD,GAAwB,EACxBvJ,EAAgBA,EAAc7a,MAAMskB,GAAMjS,EAAegI,aAAagK,EAAaC,EAAE9c,mBAE7F,EAEI6K,EAAe3a,mBACX0sB,GAA0B/R,EAAe4H,2CACzC5H,EAAe8D,gBAAgBlF,KAAUoB,EAAemC,QAAQvD,IACpEoB,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,qGAC5B4K,EAAwBtK,YAAY6c,8BAGxEQ,IAEAvJ,EAAgBA,EAAc7a,MAAMskB,IAC1B,eAAgBA,EAAE9c,kBACpB8c,EAAE9c,gBAAgB,eAAgB,IAKE,IAApC8c,EAAE9c,gBAAgB,gBAClB8c,EAAE9c,gBAAgB,wBAA0BjQ,EAAQiQ,iBAEjD8c,KAGXjS,EAAe2F,YAAY9G,WAAWxQ,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAAIgkB,IAG1ExI,EAAeiE,eAAerF,IAAS,CAC3C,EAEJjb,EAAQqjB,wBAA0BA,C,qCC1ElCphB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQujB,wCAAqC,EAC7C,MAAMlI,EAA0B,EAAQ,OAKxC,MAAMkI,EACF,iBAAA7B,GACI,OAAO,CACX,CACA,gBAAAxB,GACI,OAAO,CACX,CACA,cAAMzM,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAC9C,MAAMlT,QAAYoQ,EAAKwC,eAAerU,EAAKuQ,GAAQvQ,EAAMuQ,GACzD,QAAII,EAAwB1K,KAAKU,mBAAmBlF,OAE3CkT,GACW,UAARlT,EAOhB,CACA,UAAMhG,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,OAAOI,EAAwB1K,KAAKU,mBAAmBlF,EAC3D,CACA,YAAM8T,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GACjD,MAAMsT,EAAchL,EAAmCiL,qBAAqBriB,QACxDtF,IAAhB0nB,EACIA,UAAsB9tB,IAAU8tB,EAAYzkB,MAC5CuS,EAAegJ,UAAU,IAAIhK,EAAwB5K,WAAW,2BAA2BtE,kBAAoB1L,KAAU8tB,EAAY/d,YAGpI6L,EAAevL,cACpBuL,EAAegJ,UAAU,IAAI7gB,MAAM,oBAAoB2H,kBAAoB1L,OAE/E4b,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQujB,mCAAqCA,EAC7CA,EAAmCiL,qBAAuB,CACtD,SAAU,CAAE1kB,KAAM,SAAU0G,UAAW6K,EAAwBtK,YAAYgX,qBAC3E,QAAS,KACT,WAAY,CAAEje,KAAM,SAAU0G,UAAW6K,EAAwBtK,YAAY0d,uBAC7E,OAAQ,KACR,SAAU,K,qCCjDdxsB,OAAOyM,eAAe1O,EAAS,aAAc,CAAES,OAAO,IACtDT,EAAQsjB,8BAA2B,EACnC,MAAMqK,EAAwB,EAAQ,MAItC,MAAMrK,UAAiCqK,EAAsBD,oBACzD,WAAA9tB,GACIE,MAAM,SACV,CACA,cAAM2T,CAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,GAE9C,MAAMlT,EAAMzB,EAAKuQ,GAIjB,OAHI9O,IAAQkQ,EAAeqE,aAAazF,UAAgBrY,KAAKuD,KAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,KAC/FoB,EAAeqE,aAAazF,IAAS,GAElCnb,MAAM2T,SAAS4I,EAAgBE,EAAM7R,EAAMuQ,EAAOoE,EAC7D,CACA,UAAMlZ,CAAKkW,EAAgBE,EAAMpQ,EAAKzB,EAAMuQ,GACxC,MAAmG,iBAAtFsB,EAAKwC,eAAerU,EAAKuQ,GAAQvQ,EAAK9J,MAAM,EAAG8J,EAAK7J,OAAS,GAAIoa,EAAQ,GAAG,EAC7F,CACA,YAAMgF,CAAO5D,EAAgBE,EAAMpQ,EAAKzB,EAAMjK,EAAOwa,GAMjDoB,EAAeqE,aAAazF,IAAS,SAE9BoB,EAAewE,yBAAyB5F,UACxCoB,EAAemF,yBAAyBvG,GAE/CoB,EAAe6C,aAAajE,IAAS,CACzC,EAEJjb,EAAQsjB,yBAA2BA,C,iDClC/BoL,EAAI,CAAC,EAELC,EAAgBD,EAAEC,WAAgB,EAClCC,EAAgBF,EAAEE,YAAgB,EAClCC,EAAgBH,EAAEG,aAAgB,EAClCC,EAAgBJ,EAAEI,cAAgB,EAClCC,EAAgBL,EAAEK,MAAgB,EAClCC,EAAgBN,EAAEM,MAAgB,EAClCC,EAAgBP,EAAEO,KAAgB,EAClCC,EAAgBR,EAAEQ,MAAgB,EAClCC,EAAgBT,EAAES,KAAgB,EAClCC,EAAgBV,EAAEU,OAAgB,GAClCC,EAAgBX,EAAEW,OAAgB,GAElCC,EAAUZ,EAAEY,MAAU,GACtBC,EAAUb,EAAEa,KAAU,GACtBC,EAAUd,EAAEc,MAAU,GACtBC,EAAUf,EAAEe,MAAU,GACtBC,EAAUhB,EAAEgB,MAAU,GACtBC,EAAUjB,EAAEiB,OAAU,GACtBC,EAAUlB,EAAEkB,OAAU,GACtBC,EAAUnB,EAAEmB,OAAU,GACtBC,EAAUpB,EAAEoB,OAAU,GACtBC,EAAUrB,EAAEqB,MAAU,GACtBC,EAAUtB,EAAEsB,MAAU,GACtBC,EAAUvB,EAAEuB,MAAU,GACtBC,EAAUxB,EAAEwB,QAAU,GACtBC,EAAUzB,EAAEyB,QAAU,GACtBC,EAAU1B,EAAE0B,QAAU,GACtBC,EAAU3B,EAAE2B,QAAU,GACtBC,EAAU5B,EAAE4B,QAAU,GACtBC,EAAU7B,EAAE6B,QAAU,IACtBC,EAAU9B,EAAE8B,QAAU,IACtBC,EAAU/B,EAAE+B,QAAU,IAEtBC,EAAUhC,EAAEgC,MAAU,IACtBC,EAAUjC,EAAEiC,IAAU,IAEtBC,EAAUlC,EAAEkC,OAAU,IACtBC,EAAUnC,EAAEmC,MAAU,IAEtBC,EAAkB,KAAKC,WAAW,GAClCC,EAAkB,IAAKD,WAAW,GAClCE,EAAkB,KAAKF,WAAW,GAClCG,EAAkB,KAAKH,WAAW,GAClCI,EAAkB,KAAKJ,WAAW,GAClCK,EAAkB,KAAKL,WAAW,GAClCM,EAAkB,KAAKN,WAAW,GAElCO,EAAqB,MAEzB,SAAS3xB,IACPiD,KAAK2uB,OAASjC,EACd1sB,KAAKnC,WAAQoG,EAEbjE,KAAK4uB,YAAS3qB,EACdjE,KAAK6uB,aAAeC,EAAOC,MAAQD,EAAOC,MAAML,GAAsB,IAAII,EAAOJ,GACjF1uB,KAAKgvB,mBAAqB,EAC1BhvB,KAAKivB,aAAUhrB,EACfjE,KAAKkvB,mBAAgBjrB,EAErBjE,KAAKuJ,SAAMtF,EACXjE,KAAKyI,UAAOxE,EACZjE,KAAKqK,MAAQ,GACbrK,KAAKmvB,MAAQrB,EACb9tB,KAAKovB,gBAAkB,EACvBpvB,KAAKqvB,kBAAoB,EACzBrvB,KAAKsvB,WAAa,CAAE,EAAK,IAAIR,EAAO,GAAI,EAAK,IAAIA,EAAO,GAAI,EAAK,IAAIA,EAAO,IAG5E9uB,KAAK4hB,QAAU,CACjB,CAGA7kB,EAAOwyB,OAAS,SAAUpa,GAExB,IADA,IAAIrN,EAAOzI,OAAOyI,KAAKgkB,GACd7lB,EAAI,EAAGupB,EAAI1nB,EAAK7J,OAAQgI,EAAIupB,EAAGvpB,IAAK,CAC3C,IAAIsD,EAAMzB,EAAK7B,GACf,GAAI6lB,EAAEviB,KAAS4L,EAAQ,OAAO5L,CAChC,CACA,OAAO4L,GAAS,KAAOA,EAAK/R,SAAS,GACvC,EAEA,IAAIqsB,EAAQ1yB,EAAOqD,UACnBqvB,EAAMjQ,QAAU,SAAU7f,GAAO,MAAMA,CAAK,EAC5C8vB,EAAMC,UAAY,SAAUnpB,EAAQN,GAClCjG,KAAK2uB,OAAShC,EACd3sB,KAAKwf,QAAQ,IAAI5d,MAAM,cAAgB4F,KAAKsG,UAAUxK,OAAO4C,aAAaK,EAAON,KAAO,gBAAkBA,EAAI,aAAelJ,EAAOwyB,OAAOvvB,KAAK2uB,SAClJ,EACAc,EAAME,iBAAmB,SAAUC,GAC7B5vB,KAAKgvB,oBAAsBN,IAC7B1uB,KAAK4uB,QAAU5uB,KAAK6uB,aAAazrB,SAAS,QAC1CpD,KAAKgvB,mBAAqB,GAG5BhvB,KAAK6uB,aAAa7uB,KAAKgvB,sBAAwBY,CACjD,EACAH,EAAMI,gBAAkB,SAAUhqB,EAAKiqB,EAAOC,GAC5C,IAAIC,EAAOnqB,EAAI5H,OACM,kBAAV6xB,IAILE,EAHe,kBAARD,EACLA,EAAM,EAEDlqB,EAAI5H,OAAS6xB,EAAQC,EAErBA,EAAMD,EAGRjqB,EAAI5H,OAAS6xB,GAIpBE,EAAO,IACTA,EAAO,GAGLhwB,KAAKgvB,mBAAqBgB,EAAOtB,IACnC1uB,KAAK4uB,QAAU5uB,KAAK6uB,aAAazrB,SAAS,OAAQ,EAAGpD,KAAKgvB,oBAC1DhvB,KAAKgvB,mBAAqB,GAG5BnpB,EAAIoqB,KAAKjwB,KAAK6uB,aAAc7uB,KAAKgvB,mBAAoBc,EAAOC,GAC5D/vB,KAAKgvB,oBAAsBgB,CAC7B,EACAP,EAAMxU,MAAQ,SAAU1U,GAEtB,IAAI2pB,EADkB,kBAAX3pB,IAAqBA,EAAS,IAAIuoB,EAAOvoB,IAEpD,IAAK,IAAIN,EAAI,EAAGupB,EAAIjpB,EAAOtI,OAAQgI,EAAIupB,EAAGvpB,IACxC,GAAIjG,KAAK2uB,SAAWjC,GAGlB,GAFAwD,EAAI3pB,EAAON,GACXjG,KAAK4hB,SACI,MAANsO,EAAalwB,KAAKmwB,QAAQpE,EAAY,UACnC,GAAS,MAANmE,EAAalwB,KAAKmwB,QAAQnE,EAAa,UAC1C,GAAS,KAANkE,EAAalwB,KAAKmwB,QAAQlE,EAAc,UAC3C,GAAS,KAANiE,EAAalwB,KAAKmwB,QAAQjE,EAAe,UAC5C,GAAS,KAANgE,EAAalwB,KAAKmwB,QAAQhE,EAAO,UACpC,GAAS,KAAN+D,EAAalwB,KAAKmwB,QAAQ/D,EAAO,UACpC,GAAS,MAAN8D,EAAalwB,KAAK2uB,OAAS/B,OAC9B,GAAS,MAANsD,EAAalwB,KAAK2uB,OAAS5B,OAC9B,GAAS,MAANmD,EAAalwB,KAAK2uB,OAASxB,OAC9B,GAAS,KAAN+C,EACPlwB,KAAK4uB,OAAS,GACd5uB,KAAKgvB,mBAAqB,EAC1BhvB,KAAK2uB,OAASnB,OACV,GAAS,KAAN0C,EAAalwB,KAAK4uB,OAAS,IAAK5uB,KAAK2uB,OAASrB,OAErD,GAAI4C,GAAK,IAAQA,EAAI,GACnBlwB,KAAK4uB,OAAStrB,OAAO4C,aAAagqB,GAAIlwB,KAAK2uB,OAASpB,OAC/C,GAAU,KAAN2C,GAAoB,IAANA,GAAoB,KAANA,GAAoB,KAANA,EAGnD,OAAOlwB,KAAK0vB,UAAUnpB,EAAQN,QAG9B,GAAIjG,KAAK2uB,SAAWnB,EAIxB,GAHA0C,EAAI3pB,EAAON,GAGPjG,KAAKovB,gBAAkB,EAAG,CAC5B,IAAK,IAAIgB,EAAI,EAAGA,EAAIpwB,KAAKovB,gBAAiBgB,IACxCpwB,KAAKsvB,WAAWtvB,KAAKqvB,mBAAmBrvB,KAAKqvB,kBAAoBrvB,KAAKovB,gBAAkBgB,GAAK7pB,EAAO6pB,GAGtGpwB,KAAK6vB,gBAAgB7vB,KAAKsvB,WAAWtvB,KAAKqvB,oBAC1CrvB,KAAKqvB,kBAAoBrvB,KAAKovB,gBAAkB,EAChDnpB,EAAIA,EAAImqB,EAAI,CACd,MAAO,GAA6B,IAAzBpwB,KAAKovB,iBAAyBc,GAAK,IAAK,CACjD,GAAIA,GAAK,KAAOA,EAAI,IAClB,OAAOlwB,KAAKwf,QAAQ,IAAI5d,MAAM,uCAAyCqE,EAAI,aAAelJ,EAAOwyB,OAAOvvB,KAAK2uB,UAK/G,GAHKuB,GAAK,KAASA,GAAK,MAAMlwB,KAAKqvB,kBAAoB,GAClDa,GAAK,KAASA,GAAK,MAAMlwB,KAAKqvB,kBAAoB,GAClDa,GAAK,KAASA,GAAK,MAAMlwB,KAAKqvB,kBAAoB,GAClDrvB,KAAKqvB,kBAAoBppB,EAAKM,EAAOtI,OAAQ,CAChD,IAAK,IAAIiO,EAAI,EAAGA,GAAM3F,EAAOtI,OAAS,EAAIgI,EAAIiG,IAC5ClM,KAAKsvB,WAAWtvB,KAAKqvB,mBAAmBnjB,GAAK3F,EAAON,EAAIiG,GAE1DlM,KAAKovB,gBAAmBnpB,EAAIjG,KAAKqvB,kBAAqB9oB,EAAOtI,OAC7DgI,EAAIM,EAAOtI,OAAS,CACtB,MACE+B,KAAK6vB,gBAAgBtpB,EAAQN,EAAGA,EAAIjG,KAAKqvB,mBACzCppB,EAAIA,EAAIjG,KAAKqvB,kBAAoB,CAErC,MAAO,GAAU,KAANa,EACTlwB,KAAK2uB,OAASjC,EACd1sB,KAAK4uB,QAAU5uB,KAAK6uB,aAAazrB,SAAS,OAAQ,EAAGpD,KAAKgvB,oBAC1DhvB,KAAKgvB,mBAAqB,EAC1BhvB,KAAKmwB,QAAQ3D,EAAQxsB,KAAK4uB,QAC1B5uB,KAAK4hB,QAAUkN,EAAOzoB,WAAWrG,KAAK4uB,OAAQ,QAAU,EACxD5uB,KAAK4uB,YAAS3qB,OAEX,GAAU,KAANisB,EACPlwB,KAAK2uB,OAASlB,MAEX,MAAIyC,GAAK,IAEV,OAAOlwB,KAAK0vB,UAAUnpB,EAAQN,GAFZjG,KAAK2vB,iBAAiBO,EAG5C,MACI,GAAIlwB,KAAK2uB,SAAWlB,EAExB,GADAyC,EAAI3pB,EAAON,GACF,KAANiqB,EAAalwB,KAAK2vB,iBAAiBO,GAAIlwB,KAAK2uB,OAASnB,OAClD,GAAS,KAAN0C,EAAalwB,KAAK2vB,iBAAiBzB,GAAaluB,KAAK2uB,OAASnB,OACjE,GAAS,KAAN0C,EAAalwB,KAAK2vB,iBAAiBvB,GAAgBpuB,KAAK2uB,OAASnB,OACpE,GAAS,KAAN0C,EAAalwB,KAAK2vB,iBAAiBtB,GAAYruB,KAAK2uB,OAASnB,OAChE,GAAS,MAAN0C,EAAalwB,KAAK2vB,iBAAiBrB,GAAYtuB,KAAK2uB,OAASnB,OAChE,GAAS,MAAN0C,EAAalwB,KAAK2vB,iBAAiBpB,GAAUvuB,KAAK2uB,OAASnB,OAC9D,GAAS,MAAN0C,EAAalwB,KAAK2vB,iBAAiBnB,GAAkBxuB,KAAK2uB,OAASnB,OACtE,GAAS,MAAN0C,EAAalwB,KAAK2vB,iBAAiBlB,GAAMzuB,KAAK2uB,OAASnB,MAC1D,IAAS,MAAN0C,EAEP,OAAOlwB,KAAK0vB,UAAUnpB,EAAQN,GAFVjG,KAAKivB,QAAU,GAAIjvB,KAAK2uB,OAASjB,CAGvD,MACI,GAAI1tB,KAAK2uB,SAAWjB,GAAW1tB,KAAK2uB,SAAWhB,GAAW3tB,KAAK2uB,SAAWf,GAAW5tB,KAAK2uB,SAAWd,EAAQ,CAGjH,GAFAqC,EAAI3pB,EAAON,KAENiqB,GAAK,IAAQA,EAAI,IAAUA,EAAI,IAAQA,GAAK,IAAUA,EAAI,IAAQA,GAAK,KAoB1E,OAAOlwB,KAAK0vB,UAAUnpB,EAAQN,GAlB9B,GADAjG,KAAKivB,SAAW3rB,OAAO4C,aAAagqB,GAChClwB,KAAK2uB,WAAad,EAAS,CAC7B,IAAIwC,EAASC,SAAStwB,KAAKivB,QAAS,IACpCjvB,KAAKivB,aAAUhrB,OACYA,IAAvBjE,KAAKkvB,eAA+BmB,GAAU,OAAUA,EAAS,OACnErwB,KAAK6vB,gBAAgB,IAAIf,EAAOxrB,OAAO4C,aAAalG,KAAKkvB,cAAemB,KACxErwB,KAAKkvB,mBAAgBjrB,QACWA,IAAvBjE,KAAKkvB,eAA+BmB,GAAU,OAAUA,EAAS,MAC1ErwB,KAAKkvB,cAAgBmB,QAEMpsB,IAAvBjE,KAAKkvB,gBACPlvB,KAAK6vB,gBAAgB,IAAIf,EAAOxrB,OAAO4C,aAAalG,KAAKkvB,iBACzDlvB,KAAKkvB,mBAAgBjrB,GAEvBjE,KAAK6vB,gBAAgB,IAAIf,EAAOxrB,OAAO4C,aAAamqB,MAEtDrwB,KAAK2uB,OAASnB,CAChB,CAIJ,MAAO,GAAIxtB,KAAK2uB,SAAWrB,GAAWttB,KAAK2uB,SAAWpB,EAGlD,OAFA2C,EAAI3pB,EAAON,GAEHiqB,GACN,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,GACL,KAAK,IACL,KAAK,GACL,KAAK,GACL,KAAK,GACHlwB,KAAK4uB,QAAUtrB,OAAO4C,aAAagqB,GACnClwB,KAAK2uB,OAASpB,EACd,MACF,QACEvtB,KAAK2uB,OAASjC,EACd,IAAIvnB,EAASmhB,OAAOtmB,KAAK4uB,QAEzB,GAAI2B,MAAMprB,GACR,OAAOnF,KAAK0vB,UAAUnpB,EAAQN,GAG3BjG,KAAK4uB,OAAOnU,MAAM,WAAaza,KAAK4uB,QAAYzpB,EAAO/B,YAAcpD,KAAK4uB,OAE7E5uB,KAAKmwB,QAAQ3D,EAAQxsB,KAAK4uB,QAE1B5uB,KAAKmwB,QAAQ1D,EAAQtnB,GAGvBnF,KAAK4hB,QAAU5hB,KAAK4uB,OAAO3wB,OAAS,EACpC+B,KAAK4uB,YAAS3qB,EACdgC,IACA,WAEF,GAAIjG,KAAK2uB,SAAW/B,EAAM,CAC9B,GAAkB,MAAdrmB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAAS9B,CAE1C,MAAM,GAAI7sB,KAAK2uB,SAAW9B,EAAM,CAC9B,GAAkB,MAAdtmB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAAS7B,CAE1C,MAAM,GAAI9sB,KAAK2uB,SAAW7B,EAAM,CAC9B,GAAkB,MAAdvmB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAASjC,EAAO1sB,KAAKmwB,QAAQ9D,GAAM,GAAOrsB,KAAK4hB,QAAS,CAEzF,MAAM,GAAI5hB,KAAK2uB,SAAW5B,EAAO,CAC/B,GAAkB,KAAdxmB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAAS3B,CAE1C,MAAM,GAAIhtB,KAAK2uB,SAAW3B,EAAO,CAC/B,GAAkB,MAAdzmB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAAS1B,CAE1C,MAAM,GAAIjtB,KAAK2uB,SAAW1B,EAAO,CAC/B,GAAkB,MAAd1mB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAASzB,CAE1C,MAAM,GAAIltB,KAAK2uB,SAAWzB,EAAO,CAC/B,GAAkB,MAAd3mB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAASjC,EAAO1sB,KAAKmwB,QAAQ7D,GAAO,GAAQtsB,KAAK4hB,QAAS,CAE3F,MAAM,GAAI5hB,KAAK2uB,SAAWxB,EAAM,CAC9B,GAAkB,MAAd5mB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAASvB,CAE1C,MAAM,GAAIptB,KAAK2uB,SAAWvB,EAAM,CAC9B,GAAkB,MAAd7mB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAAStB,CAE1C,MAAM,GAAIrtB,KAAK2uB,SAAWtB,EAAM,CAC9B,GAAkB,MAAd9mB,EAAON,GACJ,OAAOjG,KAAK0vB,UAAUnpB,EAAQN,GADXjG,KAAK2uB,OAASjC,EAAO1sB,KAAKmwB,QAAQ5D,EAAM,MAAOvsB,KAAK4hB,QAAU,CAE1F,CAEJ,EACA6N,EAAMU,QAAU,SAAUK,EAAO3yB,GAEjC,EAEA4xB,EAAMgB,WAAa,SAAUD,EAAO3yB,GAClCmC,KAAK2uB,OAAShC,EACd3sB,KAAKwf,QAAQ,IAAI5d,MAAM,cAAgB7E,EAAOwyB,OAAOiB,IAAU3yB,EAAS,IAAM2J,KAAKsG,UAAUjQ,GAAS,IAAO,IAAM,aAAed,EAAOwyB,OAAOvvB,KAAKmvB,QACvJ,EACAM,EAAM1nB,KAAO,WACX/H,KAAKqK,MAAMtC,KAAK,CAAClK,MAAOmC,KAAKnC,MAAO0L,IAAKvJ,KAAKuJ,IAAKd,KAAMzI,KAAKyI,MAChE,EACAgnB,EAAMiB,IAAM,WACV,IAAI7yB,EAAQmC,KAAKnC,MACb8yB,EAAS3wB,KAAKqK,MAAMqmB,MACxB1wB,KAAKnC,MAAQ8yB,EAAO9yB,MACpBmC,KAAKuJ,IAAMonB,EAAOpnB,IAClBvJ,KAAKyI,KAAOkoB,EAAOloB,KACnBzI,KAAKN,KAAK7B,GACLmC,KAAKyI,OAAQzI,KAAKmvB,MAAQrB,EACjC,EACA2B,EAAM/vB,KAAO,SAAU7B,GACjBmC,KAAKyI,OAAQzI,KAAKmvB,MAAQ/C,GAC9BpsB,KAAK+e,QAAQlhB,EACf,EACA4xB,EAAM1Q,QAAU,SAAUlhB,GAE1B,EACA4xB,EAAMU,QAAU,SAAUK,EAAO3yB,GAC/B,GAAGmC,KAAKmvB,QAAUrB,EAChB,GAAG0C,IAAUhE,GAAUgE,IAAU/D,GAAU+D,IAAUnE,GAAQmE,IAAUlE,GAASkE,IAAUjE,EACpFvsB,KAAKnC,QACPmC,KAAKnC,MAAMmC,KAAKuJ,KAAO1L,GAEzBmC,KAAKN,KAAK7B,QACN,GAAG2yB,IAAUzE,EACjB/rB,KAAK+H,OACD/H,KAAKnC,MACPmC,KAAKnC,MAAQmC,KAAKnC,MAAMmC,KAAKuJ,KAAO,CAAC,EAErCvJ,KAAKnC,MAAQ,CAAC,EAEhBmC,KAAKuJ,SAAMtF,EACXjE,KAAKmvB,MAAQpB,EACb/tB,KAAKyI,KAAOulB,OACR,GAAGwC,IAAUvE,EACjBjsB,KAAK+H,OACD/H,KAAKnC,MACPmC,KAAKnC,MAAQmC,KAAKnC,MAAMmC,KAAKuJ,KAAO,GAEpCvJ,KAAKnC,MAAQ,GAEfmC,KAAKuJ,IAAM,EACXvJ,KAAKyI,KAAOwlB,EACZjuB,KAAKmvB,MAAQrB,OACT,GAAG0C,IAAUxE,EAAY,CAC7B,GAAIhsB,KAAKyI,OAASulB,EAGhB,OAAOhuB,KAAKywB,WAAWD,EAAO3yB,GAF9BmC,KAAK0wB,KAIT,KAAM,IAAGF,IAAUtE,EAOjB,OAAOlsB,KAAKywB,WAAWD,EAAO3yB,GAN9B,GAAImC,KAAKyI,OAASwlB,EAGhB,OAAOjuB,KAAKywB,WAAWD,EAAO3yB,GAF9BmC,KAAK0wB,KAMT,MACI,GAAG1wB,KAAKmvB,QAAUpB,EACtB,GAAIyC,IAAUhE,EACZxsB,KAAKuJ,IAAM1L,EACXmC,KAAKmvB,MAAQhD,MACR,IAAIqE,IAAUxE,EAGnB,OAAOhsB,KAAKywB,WAAWD,EAAO3yB,GAF9BmC,KAAK0wB,KAGP,MACI,GAAG1wB,KAAKmvB,QAAUhD,EAAM,CAC5B,GAAIqE,IAAUrE,EACP,OAAOnsB,KAAKywB,WAAWD,EAAO3yB,GADdmC,KAAKmvB,MAAQrB,CAEtC,KAAM,IAAG9tB,KAAKmvB,QAAU/C,EAWtB,OAAOpsB,KAAKywB,WAAWD,EAAO3yB,GAV9B,GAAI2yB,IAAUpE,EACRpsB,KAAKyI,OAASwlB,GAASjuB,KAAKuJ,MAAOvJ,KAAKmvB,MAAQrB,GAC3C9tB,KAAKyI,OAASulB,IAAUhuB,KAAKmvB,MAAQpB,OAEzC,MAAIyC,IAAUtE,GAAiBlsB,KAAKyI,OAASwlB,GAASuC,IAAUxE,GAAehsB,KAAKyI,OAASulB,GAGlG,OAAOhuB,KAAKywB,WAAWD,EAAO3yB,GAF9BmC,KAAK0wB,KAGP,CAGF,CACF,EAEA3zB,EAAO+uB,EAAIA,EAEX3uB,EAAOC,QAAUL,C","sources":["webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/index.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/index.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/BlankNode.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/DataFactory.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/DefaultGraph.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/Literal.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/NamedNode.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/Quad.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/Variable.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/parser-jsonld/node_modules/@rdfjs/data-model/lib/fromTerm.js","webpack://mobilitydcatap-ui/./node_modules/@rdfjs/sink/index.js","webpack://mobilitydcatap-ui/./node_modules/cross-fetch/dist/browser-polyfill.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/index.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/ContextParser.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/ErrorCoded.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/FetchDocumentLoader.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/IDocumentLoader.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/JsonLdContext.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/JsonLdContextNormalized.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-context-parser/lib/Util.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/index.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/ContextTree.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/JsonLdParser.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/ParsingContext.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/Util.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js","webpack://mobilitydcatap-ui/./node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js","webpack://mobilitydcatap-ui/./node_modules/jsonparse/jsonparse.js"],"sourcesContent":["const Sink = require('@rdfjs/sink')\nconst ParserStream = require('./lib/ParserStream')\n\nclass Parser extends Sink {\n  constructor (options) {\n    super(ParserStream, options)\n  }\n}\n\nmodule.exports = Parser\n","const rdf = require('@rdfjs/data-model')\nconst { JsonLdParser } = require('jsonld-streaming-parser')\nconst { Transform } = require('readable-stream')\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, factory = rdf } = {}) {\n    const parser = new JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return transform\n  }\n}\n\nmodule.exports = ParserStream\n","const DataFactory = require('./lib/DataFactory.js')\n\nmodule.exports = DataFactory\n","class BlankNode {\n  constructor (id) {\n    this.value = id || ('b' + (++BlankNode.nextId))\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nBlankNode.prototype.termType = 'BlankNode'\n\nBlankNode.nextId = 0\n\nmodule.exports = BlankNode\n","const BlankNode = require('./BlankNode.js')\nconst DefaultGraph = require('./DefaultGraph.js')\nconst fromTermRaw = require('./fromTerm.js')\nconst Literal = require('./Literal.js')\nconst NamedNode = require('./NamedNode.js')\nconst Quad = require('./Quad.js')\nconst Variable = require('./Variable.js')\n\nfunction namedNode (value) {\n  return new NamedNode(value)\n}\n\nfunction blankNode (value) {\n  return new BlankNode(value)\n}\n\nfunction literal (value, languageOrDatatype) {\n  if (typeof languageOrDatatype === 'string') {\n    if (languageOrDatatype.indexOf(':') === -1) {\n      return new Literal(value, languageOrDatatype)\n    }\n\n    return new Literal(value, null, DataFactory.namedNode(languageOrDatatype))\n  }\n\n  return new Literal(value, null, languageOrDatatype)\n}\n\nfunction variable (value) {\n  return new Variable(value)\n}\n\nfunction defaultGraph () {\n  return DataFactory.defaultGraphInstance\n}\n\nfunction triple (subject, predicate, object) {\n  return DataFactory.quad(subject, predicate, object)\n}\n\nfunction quad (subject, predicate, object, graph) {\n  return new Quad(subject, predicate, object, graph || DataFactory.defaultGraphInstance)\n}\n\nfunction fromTerm (original) {\n  return fromTermRaw.call(DataFactory, original)\n}\n\nfunction fromQuad (original) {\n  return fromTermRaw.call(DataFactory, original)\n}\n\nconst DataFactory = {\n  namedNode,\n  blankNode,\n  literal,\n  variable,\n  defaultGraph,\n  triple,\n  quad,\n  fromTerm,\n  fromQuad,\n  defaultGraphInstance: new DefaultGraph()\n}\n\nmodule.exports = DataFactory\n","class DefaultGraph {\n  equals (other) {\n    return !!other && other.termType === this.termType\n  }\n}\n\nDefaultGraph.prototype.termType = 'DefaultGraph'\nDefaultGraph.prototype.value = ''\n\nmodule.exports = DefaultGraph\n","const NamedNode = require('./NamedNode.js')\n\nclass Literal {\n  constructor (value, language, datatype) {\n    this.value = value\n    this.datatype = Literal.stringDatatype\n    this.language = ''\n\n    if (language) {\n      this.language = language\n      this.datatype = Literal.langStringDatatype\n    } else if (datatype) {\n      this.datatype = datatype\n    }\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value &&\n      other.language === this.language && other.datatype.equals(this.datatype)\n  }\n}\n\nLiteral.prototype.termType = 'Literal'\n\nLiteral.langStringDatatype = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString')\nLiteral.stringDatatype = new NamedNode('http://www.w3.org/2001/XMLSchema#string')\n\nmodule.exports = Literal\n","class NamedNode {\n  constructor (iri) {\n    this.value = iri\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nNamedNode.prototype.termType = 'NamedNode'\n\nmodule.exports = NamedNode\n","const DefaultGraph = require('./DefaultGraph.js')\n\nclass Quad {\n  constructor (subject, predicate, object, graph) {\n    this.subject = subject\n    this.predicate = predicate\n    this.object = object\n\n    if (graph) {\n      this.graph = graph\n    } else {\n      this.graph = new DefaultGraph()\n    }\n  }\n\n  equals (other) {\n    // `|| !other.termType` is for backwards-compatibility with old factories without RDF* support.\n    return !!other && (other.termType === 'Quad' || !other.termType) &&\n      other.subject.equals(this.subject) && other.predicate.equals(this.predicate) &&\n      other.object.equals(this.object) && other.graph.equals(this.graph)\n  }\n}\n\nQuad.prototype.termType = 'Quad'\nQuad.prototype.value = ''\n\nmodule.exports = Quad\n","class Variable {\n  constructor (name) {\n    this.value = name\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nVariable.prototype.termType = 'Variable'\n\nmodule.exports = Variable\n","function fromTerm (original) {\n  if (!original) {\n    return null\n  }\n\n  if (original.termType === 'BlankNode') {\n    return this.blankNode(original.value)\n  }\n\n  if (original.termType === 'DefaultGraph') {\n    return this.defaultGraph()\n  }\n\n  if (original.termType === 'Literal') {\n    return this.literal(original.value, original.language || this.namedNode(original.datatype.value))\n  }\n\n  if (original.termType === 'NamedNode') {\n    return this.namedNode(original.value)\n  }\n\n  if (original.termType === 'Quad') {\n    const subject = this.fromTerm(original.subject)\n    const predicate = this.fromTerm(original.predicate)\n    const object = this.fromTerm(original.object)\n    const graph = this.fromTerm(original.graph)\n\n    return this.quad(subject, predicate, object, graph)\n  }\n\n  if (original.termType === 'Variable') {\n    return this.variable(original.value)\n  }\n\n  throw new Error(`unknown termType ${original.termType}`)\n}\n\nmodule.exports = fromTerm\n","class Sink {\n  constructor (Impl, options) {\n    this.Impl = Impl\n    this.options = options\n  }\n\n  import (input, options) {\n    const output = new this.Impl(input, Object.assign({}, this.options, options))\n\n    input.on('end', () => {\n      if (!output.readable) {\n        output.emit('end')\n      }\n    })\n\n    input.on('error', (err) => {\n      output.emit('error', err)\n    })\n\n    return output\n  }\n}\n\nmodule.exports = Sink\n","(function(self) {\n\nvar irrelevant = (function (exports) {\n\n  var support = {\n    searchParams: 'URLSearchParams' in self,\n    iterable: 'Symbol' in self && 'iterator' in Symbol,\n    blob:\n      'FileReader' in self &&\n      'Blob' in self &&\n      (function() {\n        try {\n          new Blob();\n          return true\n        } catch (e) {\n          return false\n        }\n      })(),\n    formData: 'FormData' in self,\n    arrayBuffer: 'ArrayBuffer' in self\n  };\n\n  function isDataView(obj) {\n    return obj && DataView.prototype.isPrototypeOf(obj)\n  }\n\n  if (support.arrayBuffer) {\n    var viewClasses = [\n      '[object Int8Array]',\n      '[object Uint8Array]',\n      '[object Uint8ClampedArray]',\n      '[object Int16Array]',\n      '[object Uint16Array]',\n      '[object Int32Array]',\n      '[object Uint32Array]',\n      '[object Float32Array]',\n      '[object Float64Array]'\n    ];\n\n    var isArrayBufferView =\n      ArrayBuffer.isView ||\n      function(obj) {\n        return obj && viewClasses.indexOf(Object.prototype.toString.call(obj)) > -1\n      };\n  }\n\n  function normalizeName(name) {\n    if (typeof name !== 'string') {\n      name = String(name);\n    }\n    if (/[^a-z0-9\\-#$%&'*+.^_`|~]/i.test(name)) {\n      throw new TypeError('Invalid character in header field name')\n    }\n    return name.toLowerCase()\n  }\n\n  function normalizeValue(value) {\n    if (typeof value !== 'string') {\n      value = String(value);\n    }\n    return value\n  }\n\n  // Build a destructive iterator for the value list\n  function iteratorFor(items) {\n    var iterator = {\n      next: function() {\n        var value = items.shift();\n        return {done: value === undefined, value: value}\n      }\n    };\n\n    if (support.iterable) {\n      iterator[Symbol.iterator] = function() {\n        return iterator\n      };\n    }\n\n    return iterator\n  }\n\n  function Headers(headers) {\n    this.map = {};\n\n    if (headers instanceof Headers) {\n      headers.forEach(function(value, name) {\n        this.append(name, value);\n      }, this);\n    } else if (Array.isArray(headers)) {\n      headers.forEach(function(header) {\n        this.append(header[0], header[1]);\n      }, this);\n    } else if (headers) {\n      Object.getOwnPropertyNames(headers).forEach(function(name) {\n        this.append(name, headers[name]);\n      }, this);\n    }\n  }\n\n  Headers.prototype.append = function(name, value) {\n    name = normalizeName(name);\n    value = normalizeValue(value);\n    var oldValue = this.map[name];\n    this.map[name] = oldValue ? oldValue + ', ' + value : value;\n  };\n\n  Headers.prototype['delete'] = function(name) {\n    delete this.map[normalizeName(name)];\n  };\n\n  Headers.prototype.get = function(name) {\n    name = normalizeName(name);\n    return this.has(name) ? this.map[name] : null\n  };\n\n  Headers.prototype.has = function(name) {\n    return this.map.hasOwnProperty(normalizeName(name))\n  };\n\n  Headers.prototype.set = function(name, value) {\n    this.map[normalizeName(name)] = normalizeValue(value);\n  };\n\n  Headers.prototype.forEach = function(callback, thisArg) {\n    for (var name in this.map) {\n      if (this.map.hasOwnProperty(name)) {\n        callback.call(thisArg, this.map[name], name, this);\n      }\n    }\n  };\n\n  Headers.prototype.keys = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push(name);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.values = function() {\n    var items = [];\n    this.forEach(function(value) {\n      items.push(value);\n    });\n    return iteratorFor(items)\n  };\n\n  Headers.prototype.entries = function() {\n    var items = [];\n    this.forEach(function(value, name) {\n      items.push([name, value]);\n    });\n    return iteratorFor(items)\n  };\n\n  if (support.iterable) {\n    Headers.prototype[Symbol.iterator] = Headers.prototype.entries;\n  }\n\n  function consumed(body) {\n    if (body.bodyUsed) {\n      return Promise.reject(new TypeError('Already read'))\n    }\n    body.bodyUsed = true;\n  }\n\n  function fileReaderReady(reader) {\n    return new Promise(function(resolve, reject) {\n      reader.onload = function() {\n        resolve(reader.result);\n      };\n      reader.onerror = function() {\n        reject(reader.error);\n      };\n    })\n  }\n\n  function readBlobAsArrayBuffer(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsArrayBuffer(blob);\n    return promise\n  }\n\n  function readBlobAsText(blob) {\n    var reader = new FileReader();\n    var promise = fileReaderReady(reader);\n    reader.readAsText(blob);\n    return promise\n  }\n\n  function readArrayBufferAsText(buf) {\n    var view = new Uint8Array(buf);\n    var chars = new Array(view.length);\n\n    for (var i = 0; i < view.length; i++) {\n      chars[i] = String.fromCharCode(view[i]);\n    }\n    return chars.join('')\n  }\n\n  function bufferClone(buf) {\n    if (buf.slice) {\n      return buf.slice(0)\n    } else {\n      var view = new Uint8Array(buf.byteLength);\n      view.set(new Uint8Array(buf));\n      return view.buffer\n    }\n  }\n\n  function Body() {\n    this.bodyUsed = false;\n\n    this._initBody = function(body) {\n      this._bodyInit = body;\n      if (!body) {\n        this._bodyText = '';\n      } else if (typeof body === 'string') {\n        this._bodyText = body;\n      } else if (support.blob && Blob.prototype.isPrototypeOf(body)) {\n        this._bodyBlob = body;\n      } else if (support.formData && FormData.prototype.isPrototypeOf(body)) {\n        this._bodyFormData = body;\n      } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n        this._bodyText = body.toString();\n      } else if (support.arrayBuffer && support.blob && isDataView(body)) {\n        this._bodyArrayBuffer = bufferClone(body.buffer);\n        // IE 10-11 can't handle a DataView body.\n        this._bodyInit = new Blob([this._bodyArrayBuffer]);\n      } else if (support.arrayBuffer && (ArrayBuffer.prototype.isPrototypeOf(body) || isArrayBufferView(body))) {\n        this._bodyArrayBuffer = bufferClone(body);\n      } else {\n        this._bodyText = body = Object.prototype.toString.call(body);\n      }\n\n      if (!this.headers.get('content-type')) {\n        if (typeof body === 'string') {\n          this.headers.set('content-type', 'text/plain;charset=UTF-8');\n        } else if (this._bodyBlob && this._bodyBlob.type) {\n          this.headers.set('content-type', this._bodyBlob.type);\n        } else if (support.searchParams && URLSearchParams.prototype.isPrototypeOf(body)) {\n          this.headers.set('content-type', 'application/x-www-form-urlencoded;charset=UTF-8');\n        }\n      }\n    };\n\n    if (support.blob) {\n      this.blob = function() {\n        var rejected = consumed(this);\n        if (rejected) {\n          return rejected\n        }\n\n        if (this._bodyBlob) {\n          return Promise.resolve(this._bodyBlob)\n        } else if (this._bodyArrayBuffer) {\n          return Promise.resolve(new Blob([this._bodyArrayBuffer]))\n        } else if (this._bodyFormData) {\n          throw new Error('could not read FormData body as blob')\n        } else {\n          return Promise.resolve(new Blob([this._bodyText]))\n        }\n      };\n\n      this.arrayBuffer = function() {\n        if (this._bodyArrayBuffer) {\n          return consumed(this) || Promise.resolve(this._bodyArrayBuffer)\n        } else {\n          return this.blob().then(readBlobAsArrayBuffer)\n        }\n      };\n    }\n\n    this.text = function() {\n      var rejected = consumed(this);\n      if (rejected) {\n        return rejected\n      }\n\n      if (this._bodyBlob) {\n        return readBlobAsText(this._bodyBlob)\n      } else if (this._bodyArrayBuffer) {\n        return Promise.resolve(readArrayBufferAsText(this._bodyArrayBuffer))\n      } else if (this._bodyFormData) {\n        throw new Error('could not read FormData body as text')\n      } else {\n        return Promise.resolve(this._bodyText)\n      }\n    };\n\n    if (support.formData) {\n      this.formData = function() {\n        return this.text().then(decode)\n      };\n    }\n\n    this.json = function() {\n      return this.text().then(JSON.parse)\n    };\n\n    return this\n  }\n\n  // HTTP methods whose capitalization should be normalized\n  var methods = ['DELETE', 'GET', 'HEAD', 'OPTIONS', 'POST', 'PUT'];\n\n  function normalizeMethod(method) {\n    var upcased = method.toUpperCase();\n    return methods.indexOf(upcased) > -1 ? upcased : method\n  }\n\n  function Request(input, options) {\n    options = options || {};\n    var body = options.body;\n\n    if (input instanceof Request) {\n      if (input.bodyUsed) {\n        throw new TypeError('Already read')\n      }\n      this.url = input.url;\n      this.credentials = input.credentials;\n      if (!options.headers) {\n        this.headers = new Headers(input.headers);\n      }\n      this.method = input.method;\n      this.mode = input.mode;\n      this.signal = input.signal;\n      if (!body && input._bodyInit != null) {\n        body = input._bodyInit;\n        input.bodyUsed = true;\n      }\n    } else {\n      this.url = String(input);\n    }\n\n    this.credentials = options.credentials || this.credentials || 'same-origin';\n    if (options.headers || !this.headers) {\n      this.headers = new Headers(options.headers);\n    }\n    this.method = normalizeMethod(options.method || this.method || 'GET');\n    this.mode = options.mode || this.mode || null;\n    this.signal = options.signal || this.signal;\n    this.referrer = null;\n\n    if ((this.method === 'GET' || this.method === 'HEAD') && body) {\n      throw new TypeError('Body not allowed for GET or HEAD requests')\n    }\n    this._initBody(body);\n  }\n\n  Request.prototype.clone = function() {\n    return new Request(this, {body: this._bodyInit})\n  };\n\n  function decode(body) {\n    var form = new FormData();\n    body\n      .trim()\n      .split('&')\n      .forEach(function(bytes) {\n        if (bytes) {\n          var split = bytes.split('=');\n          var name = split.shift().replace(/\\+/g, ' ');\n          var value = split.join('=').replace(/\\+/g, ' ');\n          form.append(decodeURIComponent(name), decodeURIComponent(value));\n        }\n      });\n    return form\n  }\n\n  function parseHeaders(rawHeaders) {\n    var headers = new Headers();\n    // Replace instances of \\r\\n and \\n followed by at least one space or horizontal tab with a space\n    // https://tools.ietf.org/html/rfc7230#section-3.2\n    var preProcessedHeaders = rawHeaders.replace(/\\r?\\n[\\t ]+/g, ' ');\n    preProcessedHeaders.split(/\\r?\\n/).forEach(function(line) {\n      var parts = line.split(':');\n      var key = parts.shift().trim();\n      if (key) {\n        var value = parts.join(':').trim();\n        headers.append(key, value);\n      }\n    });\n    return headers\n  }\n\n  Body.call(Request.prototype);\n\n  function Response(bodyInit, options) {\n    if (!options) {\n      options = {};\n    }\n\n    this.type = 'default';\n    this.status = options.status === undefined ? 200 : options.status;\n    this.ok = this.status >= 200 && this.status < 300;\n    this.statusText = 'statusText' in options ? options.statusText : 'OK';\n    this.headers = new Headers(options.headers);\n    this.url = options.url || '';\n    this._initBody(bodyInit);\n  }\n\n  Body.call(Response.prototype);\n\n  Response.prototype.clone = function() {\n    return new Response(this._bodyInit, {\n      status: this.status,\n      statusText: this.statusText,\n      headers: new Headers(this.headers),\n      url: this.url\n    })\n  };\n\n  Response.error = function() {\n    var response = new Response(null, {status: 0, statusText: ''});\n    response.type = 'error';\n    return response\n  };\n\n  var redirectStatuses = [301, 302, 303, 307, 308];\n\n  Response.redirect = function(url, status) {\n    if (redirectStatuses.indexOf(status) === -1) {\n      throw new RangeError('Invalid status code')\n    }\n\n    return new Response(null, {status: status, headers: {location: url}})\n  };\n\n  exports.DOMException = self.DOMException;\n  try {\n    new exports.DOMException();\n  } catch (err) {\n    exports.DOMException = function(message, name) {\n      this.message = message;\n      this.name = name;\n      var error = Error(message);\n      this.stack = error.stack;\n    };\n    exports.DOMException.prototype = Object.create(Error.prototype);\n    exports.DOMException.prototype.constructor = exports.DOMException;\n  }\n\n  function fetch(input, init) {\n    return new Promise(function(resolve, reject) {\n      var request = new Request(input, init);\n\n      if (request.signal && request.signal.aborted) {\n        return reject(new exports.DOMException('Aborted', 'AbortError'))\n      }\n\n      var xhr = new XMLHttpRequest();\n\n      function abortXhr() {\n        xhr.abort();\n      }\n\n      xhr.onload = function() {\n        var options = {\n          status: xhr.status,\n          statusText: xhr.statusText,\n          headers: parseHeaders(xhr.getAllResponseHeaders() || '')\n        };\n        options.url = 'responseURL' in xhr ? xhr.responseURL : options.headers.get('X-Request-URL');\n        var body = 'response' in xhr ? xhr.response : xhr.responseText;\n        resolve(new Response(body, options));\n      };\n\n      xhr.onerror = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.ontimeout = function() {\n        reject(new TypeError('Network request failed'));\n      };\n\n      xhr.onabort = function() {\n        reject(new exports.DOMException('Aborted', 'AbortError'));\n      };\n\n      xhr.open(request.method, request.url, true);\n\n      if (request.credentials === 'include') {\n        xhr.withCredentials = true;\n      } else if (request.credentials === 'omit') {\n        xhr.withCredentials = false;\n      }\n\n      if ('responseType' in xhr && support.blob) {\n        xhr.responseType = 'blob';\n      }\n\n      request.headers.forEach(function(value, name) {\n        xhr.setRequestHeader(name, value);\n      });\n\n      if (request.signal) {\n        request.signal.addEventListener('abort', abortXhr);\n\n        xhr.onreadystatechange = function() {\n          // DONE (success or failure)\n          if (xhr.readyState === 4) {\n            request.signal.removeEventListener('abort', abortXhr);\n          }\n        };\n      }\n\n      xhr.send(typeof request._bodyInit === 'undefined' ? null : request._bodyInit);\n    })\n  }\n\n  fetch.polyfill = true;\n\n  if (!self.fetch) {\n    self.fetch = fetch;\n    self.Headers = Headers;\n    self.Request = Request;\n    self.Response = Response;\n  }\n\n  exports.Headers = Headers;\n  exports.Request = Request;\n  exports.Response = Response;\n  exports.fetch = fetch;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n  return exports;\n\n})({});\n})(typeof self !== 'undefined' ? self : this);\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/ContextParser\"), exports);\n__exportStar(require(\"./lib/ErrorCoded\"), exports);\n__exportStar(require(\"./lib/FetchDocumentLoader\"), exports);\n__exportStar(require(\"./lib/IDocumentLoader\"), exports);\n__exportStar(require(\"./lib/JsonLdContext\"), exports);\n__exportStar(require(\"./lib/JsonLdContextNormalized\"), exports);\n__exportStar(require(\"./lib/Util\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextParser = void 0;\nrequire(\"cross-fetch/polyfill\");\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst FetchDocumentLoader_1 = require(\"./FetchDocumentLoader\");\nconst JsonLdContextNormalized_1 = require(\"./JsonLdContextNormalized\");\nconst Util_1 = require(\"./Util\");\n/**\n * Parses JSON-LD contexts.\n */\nclass ContextParser {\n    constructor(options) {\n        options = options || {};\n        this.documentLoader = options.documentLoader || new FetchDocumentLoader_1.FetchDocumentLoader();\n        this.documentCache = {};\n        this.validateContext = !options.skipValidation;\n        this.expandContentTypeToBase = !!options.expandContentTypeToBase;\n        this.remoteContextsDepthLimit = options.remoteContextsDepthLimit || 32;\n        this.redirectSchemaOrgHttps = 'redirectSchemaOrgHttps' in options ? !!options.redirectSchemaOrgHttps : true;\n    }\n    /**\n     * Validate the given @language value.\n     * An error will be thrown if it is invalid.\n     * @param value An @language value.\n     * @param {boolean} strictRange If the string value should be strictly checked against a regex.\n     * @param {string} errorCode The error code to emit on errors.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateLanguage(value, strictRange, errorCode) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a string, got '${JSON.stringify(value)}'`, errorCode);\n        }\n        if (!Util_1.Util.REGEX_LANGUAGE_TAG.test(value)) {\n            if (strictRange) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@language' must be a valid language tag, got '${JSON.stringify(value)}'`, errorCode);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Validate the given @direction value.\n     * An error will be thrown if it is invalid.\n     * @param value An @direction value.\n     * @param {boolean} strictValues If the string value should be strictly checked against a regex.\n     * @return {boolean} If validation passed.\n     *                   Can only be false if strictRange is false and the string value did not pass the regex.\n     */\n    static validateDirection(value, strictValues) {\n        if (typeof value !== 'string') {\n            throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be a string, got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n        }\n        if (!Util_1.Util.REGEX_DIRECTION_TAG.test(value)) {\n            if (strictValues) {\n                throw new ErrorCoded_1.ErrorCoded(`The value of an '@direction' must be 'ltr' or 'rtl', got '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_DIRECTION);\n            }\n            else {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Add an @id term for all @reverse terms.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     */\n    idifyReverseTerms(context) {\n        for (const key of Object.keys(context)) {\n            let value = context[key];\n            if (value && typeof value === 'object') {\n                if (value['@reverse'] && !value['@id']) {\n                    if (typeof value['@reverse'] !== 'string' || Util_1.Util.isValidKeyword(value['@reverse'])) {\n                        throw new ErrorCoded_1.ErrorCoded(`Invalid @reverse value, must be absolute IRI or blank node: '${value['@reverse']}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                    }\n                    value = context[key] = Object.assign(Object.assign({}, value), { '@id': value['@reverse'] });\n                    value['@id'] = value['@reverse'];\n                    if (Util_1.Util.isPotentialKeyword(value['@reverse'])) {\n                        delete value['@reverse'];\n                    }\n                    else {\n                        value['@reverse'] = true;\n                    }\n                }\n            }\n        }\n        return context;\n    }\n    /**\n     * Expand all prefixed terms in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {boolean} expandContentTypeToBase If @type inside the context may be expanded\n     *                                          via @base if @vocab is set to null.\n     * @param {string[]} keys Optional set of keys from the context to expand. If left undefined, all\n     * keys in the context will be expanded.\n     */\n    expandPrefixedTerms(context, expandContentTypeToBase, keys) {\n        const contextRaw = context.getContextRaw();\n        for (const key of (keys || Object.keys(contextRaw))) {\n            // Only expand allowed keys\n            if (Util_1.Util.EXPAND_KEYS_BLACKLIST.indexOf(key) < 0 && !Util_1.Util.isReservedInternalKeyword(key)) {\n                // Error if we try to alias a keyword to something else.\n                const keyValue = contextRaw[key];\n                if (Util_1.Util.isPotentialKeyword(key) && Util_1.Util.ALIAS_DOMAIN_BLACKLIST.indexOf(key) >= 0) {\n                    if (key !== '@type' || typeof contextRaw[key] === 'object'\n                        && !(contextRaw[key]['@protected'] || contextRaw[key]['@container'] === '@set')) {\n                        throw new ErrorCoded_1.ErrorCoded(`Keywords can not be aliased to something else.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                    }\n                }\n                // Error if we try to alias to an illegal keyword\n                if (Util_1.Util.ALIAS_RANGE_BLACKLIST.indexOf(Util_1.Util.getContextValueId(keyValue)) >= 0) {\n                    throw new ErrorCoded_1.ErrorCoded(`Aliasing to certain keywords is not allowed.\nTried mapping ${key} to ${JSON.stringify(keyValue)}`, ErrorCoded_1.ERROR_CODES.INVALID_KEYWORD_ALIAS);\n                }\n                // Error if this term was marked as prefix as well\n                if (keyValue && Util_1.Util.isPotentialKeyword(Util_1.Util.getContextValueId(keyValue))\n                    && keyValue['@prefix'] === true) {\n                    throw new ErrorCoded_1.ErrorCoded(`Tried to use keyword aliases as prefix: '${key}': '${JSON.stringify(keyValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // Loop because prefixes might be nested\n                while (Util_1.Util.isPrefixValue(contextRaw[key])) {\n                    const value = contextRaw[key];\n                    let changed = false;\n                    if (typeof value === 'string') {\n                        contextRaw[key] = context.expandTerm(value, true);\n                        changed = changed || value !== contextRaw[key];\n                    }\n                    else {\n                        const id = value['@id'];\n                        const type = value['@type'];\n                        // If @id is missing, don't allow @id to be added if @prefix: true and key not being a valid IRI.\n                        const canAddIdEntry = !('@prefix' in value) || Util_1.Util.isValidIri(key);\n                        if ('@id' in value) {\n                            // Use @id value for expansion\n                            if (id !== undefined && id !== null && typeof id === 'string') {\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': context.expandTerm(id, true) });\n                                changed = changed || id !== contextRaw[key]['@id'];\n                            }\n                        }\n                        else if (!Util_1.Util.isPotentialKeyword(key) && canAddIdEntry) {\n                            // Add an explicit @id value based on the expanded key value\n                            const newId = context.expandTerm(key, true);\n                            if (newId !== key) {\n                                // Don't set @id if expansion failed\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@id': newId });\n                                changed = true;\n                            }\n                        }\n                        if (type && typeof type === 'string' && type !== '@vocab'\n                            && (!value['@container'] || !value['@container']['@type'])\n                            && canAddIdEntry) {\n                            // First check @vocab, then fallback to @base\n                            let expandedType = context.expandTerm(type, true);\n                            if (expandContentTypeToBase && type === expandedType) {\n                                expandedType = context.expandTerm(type, false);\n                            }\n                            if (expandedType !== type) {\n                                changed = true;\n                                contextRaw[key] = Object.assign(Object.assign({}, contextRaw[key]), { '@type': expandedType });\n                            }\n                        }\n                    }\n                    if (!changed) {\n                        break;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Normalize the @language entries in the given context to lowercase.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} parseOptions The parsing options.\n     */\n    normalize(context, { processingMode, normalizeLanguageTags }) {\n        // Lowercase language keys in 1.0\n        if (normalizeLanguageTags || processingMode === 1.0) {\n            for (const key of Object.keys(context)) {\n                if (key === '@language' && typeof context[key] === 'string') {\n                    context[key] = context[key].toLowerCase();\n                }\n                else {\n                    const value = context[key];\n                    if (value && typeof value === 'object') {\n                        if (typeof value['@language'] === 'string') {\n                            const lowercase = value['@language'].toLowerCase();\n                            if (lowercase !== value['@language']) {\n                                context[key] = Object.assign(Object.assign({}, value), { '@language': lowercase });\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert all @container strings and array values to hash-based values.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     */\n    containersToHash(context) {\n        for (const key of Object.keys(context)) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if (typeof value['@container'] === 'string') {\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': { [value['@container']]: true } });\n                }\n                else if (Array.isArray(value['@container'])) {\n                    const newValue = {};\n                    for (const containerValue of value['@container']) {\n                        newValue[containerValue] = true;\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@container': newValue });\n                }\n            }\n        }\n    }\n    /**\n     * Normalize and apply context-level @protected terms onto each term separately.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {number} processingMode The processing mode.\n     */\n    applyScopedProtected(context, { processingMode }, expandOptions) {\n        if (processingMode && processingMode >= 1.1) {\n            if (context['@protected']) {\n                for (const key of Object.keys(context)) {\n                    if (Util_1.Util.isReservedInternalKeyword(key)) {\n                        continue;\n                    }\n                    if (!Util_1.Util.isPotentialKeyword(key) && !Util_1.Util.isTermProtected(context, key)) {\n                        const value = context[key];\n                        if (value && typeof value === 'object') {\n                            if (!('@protected' in context[key])) {\n                                // Mark terms with object values as protected if they don't have an @protected: false annotation\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@protected': true });\n                            }\n                        }\n                        else {\n                            // Convert string-based term values to object-based values with @protected: true\n                            context[key] = {\n                                '@id': value,\n                                '@protected': true,\n                            };\n                            if (Util_1.Util.isSimpleTermDefinitionPrefix(value, expandOptions)) {\n                                context[key] = Object.assign(Object.assign({}, context[key]), { '@prefix': true });\n                            }\n                        }\n                    }\n                }\n                delete context['@protected'];\n            }\n        }\n    }\n    /**\n     * Check if the given context inheritance does not contain any overrides of protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextBefore The context that may contain some protected terms.\n     * @param {IJsonLdContextNormalizedRaw} contextAfter A new context that is being applied on the first one.\n     * @param {IExpandOptions} expandOptions Options that are needed for any expansions during this validation.\n     * @param {string[]} keys Optional set of keys from the context to validate. If left undefined, all\n     * keys defined in contextAfter will be checked.\n     */\n    validateKeywordRedefinitions(contextBefore, contextAfter, expandOptions, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(contextAfter))) {\n            if (Util_1.Util.isTermProtected(contextBefore, key)) {\n                // The entry in the context before will always be in object-mode\n                // If the new entry is in string-mode, convert it to object-mode\n                // before checking if it is identical.\n                if (typeof contextAfter[key] === 'string') {\n                    contextAfter[key] = { '@id': contextAfter[key], '@protected': true };\n                }\n                else {\n                    // We modify this deliberately,\n                    // as we need it for the value comparison (they must be identical modulo '@protected')),\n                    // and for the fact that this new value will override the first one.\n                    contextAfter[key] = Object.assign(Object.assign({}, contextAfter[key]), { '@protected': true });\n                }\n                // Error if they are not identical\n                if (!Util_1.Util.deepEqual(contextBefore[key], contextAfter[key])) {\n                    throw new ErrorCoded_1.ErrorCoded(`Attempted to override the protected keyword ${key} from ${JSON.stringify(Util_1.Util.getContextValueId(contextBefore[key]))} to ${JSON.stringify(Util_1.Util.getContextValueId(contextAfter[key]))}`, ErrorCoded_1.ERROR_CODES.PROTECTED_TERM_REDEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Validate the entries of the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options The parse options.\n     */\n    validate(context, { processingMode }) {\n        for (const key of Object.keys(context)) {\n            // Ignore reserved internal keywords.\n            if (Util_1.Util.isReservedInternalKeyword(key)) {\n                continue;\n            }\n            // Do not allow empty term\n            if (key === '') {\n                throw new ErrorCoded_1.ErrorCoded(`The empty term is not allowed, got: '${key}': '${JSON.stringify(context[key])}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n            }\n            const value = context[key];\n            const valueType = typeof value;\n            // First check if the key is a keyword\n            if (Util_1.Util.isPotentialKeyword(key)) {\n                switch (key.substr(1)) {\n                    case 'vocab':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @vocab IRI: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                        }\n                        break;\n                    case 'base':\n                        if (value !== null && valueType !== 'string') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @base IRI: ${context[key]}`, ErrorCoded_1.ERROR_CODES.INVALID_BASE_IRI);\n                        }\n                        break;\n                    case 'language':\n                        if (value !== null) {\n                            ContextParser.validateLanguage(value, true, ErrorCoded_1.ERROR_CODES.INVALID_DEFAULT_LANGUAGE);\n                        }\n                        break;\n                    case 'version':\n                        if (value !== null && valueType !== 'number') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @version number: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                        }\n                        break;\n                    case 'direction':\n                        if (value !== null) {\n                            ContextParser.validateDirection(value, true);\n                        }\n                        break;\n                    case 'propagate':\n                        if (processingMode === 1.0) {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an illegal @propagate keyword: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                        }\n                        if (value !== null && valueType !== 'boolean') {\n                            throw new ErrorCoded_1.ErrorCoded(`Found an invalid @propagate value: ${value}`, ErrorCoded_1.ERROR_CODES.INVALID_PROPAGATE_VALUE);\n                        }\n                        break;\n                }\n                // Don't allow keywords to be overridden\n                if (Util_1.Util.isValidKeyword(key) && Util_1.Util.isValidKeyword(Util_1.Util.getContextValueId(value))) {\n                    throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${Util_1.Util\n                        .getContextValueId(value)}'`, ErrorCoded_1.ERROR_CODES.KEYWORD_REDEFINITION);\n                }\n                continue;\n            }\n            // Otherwise, consider the key a term\n            if (value !== null) {\n                switch (valueType) {\n                    case 'string':\n                        if (Util_1.Util.getPrefix(value, context) === key) {\n                            throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                        }\n                        if (Util_1.Util.isValidIriWeak(key)) {\n                            if (value === '@type') {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                            else if (Util_1.Util.isValidIri(value) && value !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                            }\n                        }\n                        break;\n                    case 'object':\n                        if (!Util_1.Util.isCompactIri(key) && !('@id' in value)\n                            && (value['@type'] === '@id' ? !context['@base'] : !context['@vocab'])) {\n                            throw new ErrorCoded_1.ErrorCoded(`Missing @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                        }\n                        for (const objectKey of Object.keys(value)) {\n                            const objectValue = value[objectKey];\n                            if (!objectValue) {\n                                continue;\n                            }\n                            switch (objectKey) {\n                                case '@id':\n                                    if (Util_1.Util.isValidKeyword(objectValue)\n                                        && objectValue !== '@type' && objectValue !== '@id' && objectValue !== '@graph' && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Illegal keyword alias in term value, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.isValidIriWeak(key)) {\n                                        if (objectValue === '@type') {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to @type, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                        else if (Util_1.Util.isValidIri(objectValue)\n                                            && objectValue !== new JsonLdContextNormalized_1.JsonLdContextNormalized(context).expandTerm(key)) {\n                                            throw new ErrorCoded_1.ErrorCoded(`IRIs can not be mapped to other IRIs, found: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                        }\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected non-string @id in context entry: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n                                    }\n                                    if (Util_1.Util.getPrefix(objectValue, context) === key) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Detected cyclical IRI mapping in context entry: '${key}': '${JSON\n                                            .stringify(value)}'`, ErrorCoded_1.ERROR_CODES.CYCLIC_IRI_MAPPING);\n                                    }\n                                    break;\n                                case '@type':\n                                    if (value['@container'] === '@type' && objectValue !== '@id' && objectValue !== '@vocab') {\n                                        throw new ErrorCoded_1.ErrorCoded(`@container: @type only allows @type: @id or @vocab, but got: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (typeof objectValue !== 'string') {\n                                        throw new ErrorCoded_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    if (objectValue !== '@id' && objectValue !== '@vocab'\n                                        && (processingMode === 1.0 || objectValue !== '@json')\n                                        && (processingMode === 1.0 || objectValue !== '@none')\n                                        && (objectValue[0] === '_' || !Util_1.Util.isValidIri(objectValue))) {\n                                        throw new ErrorCoded_1.ErrorCoded(`A context @type must be an absolute IRI, found: '${key}': '${objectValue}'`, ErrorCoded_1.ERROR_CODES.INVALID_TYPE_MAPPING);\n                                    }\n                                    break;\n                                case '@reverse':\n                                    if (typeof objectValue === 'string' && value['@id'] && value['@id'] !== objectValue) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found non-matching @id and @reverse term values in '${key}':\\\n'${objectValue}' and '${value['@id']}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    if ('@nest' in value) {\n                                        throw new ErrorCoded_1.ErrorCoded(`@nest is not allowed in the reverse property '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                    }\n                                    break;\n                                case '@container':\n                                    if (processingMode === 1.0) {\n                                        if (Object.keys(objectValue).length > 1\n                                            || Util_1.Util.CONTAINERS_1_0.indexOf(Object.keys(objectValue)[0]) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${Object.keys(objectValue)}') in 1.0, \\\nmust be only one of ${Util_1.Util.CONTAINERS_1_0.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    for (const containerValue of Object.keys(objectValue)) {\n                                        if (containerValue === '@list' && value['@reverse']) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Term value can not be @container: @list and @reverse at the same time on '${key}'`, ErrorCoded_1.ERROR_CODES.INVALID_REVERSE_PROPERTY);\n                                        }\n                                        if (Util_1.Util.CONTAINERS.indexOf(containerValue) < 0) {\n                                            throw new ErrorCoded_1.ErrorCoded(`Invalid term @container for '${key}' ('${containerValue}'), \\\nmust be one of ${Util_1.Util.CONTAINERS.join(', ')}`, ErrorCoded_1.ERROR_CODES.INVALID_CONTAINER_MAPPING);\n                                        }\n                                    }\n                                    break;\n                                case '@language':\n                                    ContextParser.validateLanguage(objectValue, true, ErrorCoded_1.ERROR_CODES.INVALID_LANGUAGE_MAPPING);\n                                    break;\n                                case '@direction':\n                                    ContextParser.validateDirection(objectValue, true);\n                                    break;\n                                case '@prefix':\n                                    if (objectValue !== null && typeof objectValue !== 'boolean') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @prefix boolean in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_PREFIX_VALUE);\n                                    }\n                                    if (!('@id' in value) && !Util_1.Util.isValidIri(key)) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Invalid @prefix definition for '${key}' ('${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@index':\n                                    if (processingMode === 1.0 || !value['@container'] || !value['@container']['@index']) {\n                                        throw new ErrorCoded_1.ErrorCoded(`Attempt to add illegal key to value object: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                                    }\n                                    break;\n                                case '@nest':\n                                    if (Util_1.Util.isPotentialKeyword(objectValue) && objectValue !== '@nest') {\n                                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term @nest value in: '${key}': '${JSON.stringify(value)}'`, ErrorCoded_1.ERROR_CODES.INVALID_NEST_VALUE);\n                                    }\n                            }\n                        }\n                        break;\n                    default:\n                        throw new ErrorCoded_1.ErrorCoded(`Found an invalid term value: '${key}': '${value}'`, ErrorCoded_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n            }\n        }\n    }\n    /**\n     * Apply the @base context entry to the given context under certain circumstances.\n     * @param context A context.\n     * @param options Parsing options.\n     * @param inheritFromParent If the @base value from the parent context can be inherited.\n     * @return The given context.\n     */\n    applyBaseEntry(context, options, inheritFromParent) {\n        // In some special cases, this can be a string, so ignore those.\n        if (typeof context === 'string') {\n            return context;\n        }\n        // Give priority to @base in the parent context\n        if (inheritFromParent && !('@base' in context) && options.parentContext\n            && typeof options.parentContext === 'object' && '@base' in options.parentContext) {\n            context['@base'] = options.parentContext['@base'];\n            if (options.parentContext['@__baseDocument']) {\n                context['@__baseDocument'] = true;\n            }\n        }\n        // Override the base IRI if provided.\n        if (options.baseIRI && !options.external) {\n            if (!('@base' in context)) {\n                // The context base is the document base\n                context['@base'] = options.baseIRI;\n                context['@__baseDocument'] = true;\n            }\n            else if (context['@base'] !== null && typeof context['@base'] === 'string'\n                && !Util_1.Util.isValidIri(context['@base'])) {\n                // The context base is relative to the document base\n                context['@base'] = (0, relative_to_absolute_iri_1.resolve)(context['@base'], options.parentContext && options.parentContext['@base'] || options.baseIRI);\n            }\n        }\n        return context;\n    }\n    /**\n     * Resolve relative context IRIs, or return full IRIs as-is.\n     * @param {string} contextIri A context IRI.\n     * @param {string} baseIRI A base IRI.\n     * @return {string} The normalized context IRI.\n     */\n    normalizeContextIri(contextIri, baseIRI) {\n        if (!Util_1.Util.isValidIri(contextIri)) {\n            try {\n                contextIri = (0, relative_to_absolute_iri_1.resolve)(contextIri, baseIRI);\n            }\n            catch (_a) {\n                throw new Error(`Invalid context IRI: ${contextIri}`);\n            }\n        }\n        // TODO: Temporary workaround for fixing schema.org CORS issues (https://github.com/schemaorg/schemaorg/issues/2578#issuecomment-652324465)\n        if (this.redirectSchemaOrgHttps && contextIri.startsWith('http://schema.org')) {\n            contextIri = 'https://schema.org/';\n        }\n        return contextIri;\n    }\n    /**\n     * Parse scoped contexts in the given context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {IParseOptions} options Parsing options.\n     * @return {IJsonLdContextNormalizedRaw} The mutated input context.\n     * @param {string[]} keys Optional set of keys from the context to parseInnerContexts of. If left undefined, all\n     * keys in the context will be iterated over.\n     */\n    async parseInnerContexts(context, options, keys) {\n        for (const key of (keys !== null && keys !== void 0 ? keys : Object.keys(context))) {\n            const value = context[key];\n            if (value && typeof value === 'object') {\n                if ('@context' in value && value['@context'] !== null && !options.ignoreScopedContexts) {\n                    // Simulate a processing based on the parent context to check if there are any (potential errors).\n                    // Honestly, I find it a bit weird to do this here, as the context may be unused,\n                    // and the final effective context may differ based on any other embedded/scoped contexts.\n                    // But hey, it's part of the spec, so we have no choice...\n                    // https://w3c.github.io/json-ld-api/#h-note-10\n                    if (this.validateContext) {\n                        try {\n                            const parentContext = Object.assign(Object.assign({}, context), { [key]: Object.assign({}, context[key]) });\n                            delete parentContext[key]['@context'];\n                            await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, parentContext, ignoreProtection: true, ignoreRemoteScopedContexts: true, ignoreScopedContexts: true }));\n                        }\n                        catch (e) {\n                            throw new ErrorCoded_1.ErrorCoded(e.message, ErrorCoded_1.ERROR_CODES.INVALID_SCOPED_CONTEXT);\n                        }\n                    }\n                    context[key] = Object.assign(Object.assign({}, value), { '@context': (await this.parse(value['@context'], Object.assign(Object.assign({}, options), { external: false, minimalProcessing: true, ignoreRemoteScopedContexts: true, parentContext: context })))\n                            .getContextRaw() });\n                }\n            }\n        }\n        return context;\n    }\n    async parse(context, options = {}, \n    // These options are only for internal use on recursive calls and should not be used by\n    // libraries consuming this function\n    internalOptions = {}) {\n        const { baseIRI, parentContext, external, processingMode = ContextParser.DEFAULT_PROCESSING_MODE, normalizeLanguageTags, ignoreProtection, minimalProcessing, } = options;\n        const remoteContexts = options.remoteContexts || {};\n        // Avoid remote context overflows\n        if (Object.keys(remoteContexts).length >= this.remoteContextsDepthLimit) {\n            throw new ErrorCoded_1.ErrorCoded('Detected an overflow in remote context inclusions: ' + Object.keys(remoteContexts), ErrorCoded_1.ERROR_CODES.CONTEXT_OVERFLOW);\n        }\n        if (context === null || context === undefined) {\n            // Don't allow context nullification and there are protected terms\n            if (!ignoreProtection && parentContext && Util_1.Util.hasProtectedTerms(parentContext)) {\n                throw new ErrorCoded_1.ErrorCoded('Illegal context nullification when terms are protected', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_NULLIFICATION);\n            }\n            // Context that are explicitly set to null are empty.\n            return new JsonLdContextNormalized_1.JsonLdContextNormalized(this.applyBaseEntry({}, options, false));\n        }\n        else if (typeof context === 'string') {\n            const contextIri = this.normalizeContextIri(context, baseIRI);\n            const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n            if (overriddenLoad) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(overriddenLoad);\n            }\n            const parsedStringContext = await this.parse(await this.load(contextIri), Object.assign(Object.assign({}, options), { baseIRI: contextIri, external: true, remoteContexts: Object.assign(Object.assign({}, remoteContexts), { [contextIri]: true }) }));\n            this.applyBaseEntry(parsedStringContext.getContextRaw(), options, true);\n            return parsedStringContext;\n        }\n        else if (Array.isArray(context)) {\n            // As a performance consideration, first load all external contexts in parallel.\n            const contextIris = [];\n            const contexts = await Promise.all(context.map((subContext, i) => {\n                if (typeof subContext === 'string') {\n                    const contextIri = this.normalizeContextIri(subContext, baseIRI);\n                    contextIris[i] = contextIri;\n                    const overriddenLoad = this.getOverriddenLoad(contextIri, options);\n                    if (overriddenLoad) {\n                        return overriddenLoad;\n                    }\n                    return this.load(contextIri);\n                }\n                else {\n                    return subContext;\n                }\n            }));\n            // Don't apply inheritance logic on minimal processing\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(contexts);\n            }\n            const reducedContexts = await contexts.reduce((accContextPromise, contextEntry, i) => accContextPromise\n                .then((accContext) => this.parse(contextEntry, Object.assign(Object.assign({}, options), { baseIRI: contextIris[i] || options.baseIRI, external: !!contextIris[i] || options.external, parentContext: accContext.getContextRaw(), remoteContexts: contextIris[i] ? Object.assign(Object.assign({}, remoteContexts), { [contextIris[i]]: true }) : remoteContexts }), \n            // @ts-expect-error: This third argument causes a type error because we have hidden it from consumers\n            {\n                skipValidation: i < contexts.length - 1,\n            })), Promise.resolve(new JsonLdContextNormalized_1.JsonLdContextNormalized(parentContext || {})));\n            // Override the base IRI if provided.\n            this.applyBaseEntry(reducedContexts.getContextRaw(), options, true);\n            return reducedContexts;\n        }\n        else if (typeof context === 'object') {\n            if ('@context' in context) {\n                return await this.parse(context['@context'], options);\n            }\n            // Make a deep clone of the given context, to avoid modifying it.\n            context = Object.assign({}, context);\n            // According to the JSON-LD spec, @base must be ignored from external contexts.\n            if (external) {\n                delete context['@base'];\n            }\n            // Override the base IRI if provided.\n            this.applyBaseEntry(context, options, true);\n            // Hashify container entries\n            // Do this before protected term validation as that influences term format\n            this.containersToHash(context);\n            // Don't perform any other modifications if only minimal processing is needed.\n            if (minimalProcessing) {\n                return new JsonLdContextNormalized_1.JsonLdContextNormalized(context);\n            }\n            // In JSON-LD 1.1, load @import'ed context prior to processing.\n            let importContext = {};\n            if ('@import' in context) {\n                if (processingMode >= 1.1) {\n                    // Only accept string values\n                    if (typeof context['@import'] !== 'string') {\n                        throw new ErrorCoded_1.ErrorCoded('An @import value must be a string, but got ' + typeof context['@import'], ErrorCoded_1.ERROR_CODES.INVALID_IMPORT_VALUE);\n                    }\n                    // Load context\n                    importContext = await this.loadImportContext(this.normalizeContextIri(context['@import'], baseIRI));\n                    delete context['@import'];\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded('Context importing is not supported in JSON-LD 1.0', ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n                }\n            }\n            this.applyScopedProtected(importContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const newContext = Object.assign(importContext, context);\n            // Handle terms (before protection checks)\n            this.idifyReverseTerms(newContext);\n            this.normalize(newContext, { processingMode, normalizeLanguageTags });\n            this.applyScopedProtected(newContext, { processingMode }, JsonLdContextNormalized_1.defaultExpandOptions);\n            const keys = Object.keys(newContext);\n            const overlappingKeys = [];\n            if (typeof parentContext === 'object') {\n                // Merge different parts of the final context in order\n                for (const key in parentContext) {\n                    if (key in newContext) {\n                        overlappingKeys.push(key);\n                    }\n                    else {\n                        newContext[key] = parentContext[key];\n                    }\n                }\n            }\n            // Parse inner contexts with minimal processing\n            await this.parseInnerContexts(newContext, options, keys);\n            const newContextWrapped = new JsonLdContextNormalized_1.JsonLdContextNormalized(newContext);\n            // In JSON-LD 1.1, @vocab can be relative to @vocab in the parent context, or a compact IRI.\n            if ((newContext && newContext['@version'] || ContextParser.DEFAULT_PROCESSING_MODE) >= 1.1\n                && ((context['@vocab'] && typeof context['@vocab'] === 'string') || context['@vocab'] === '')) {\n                if (parentContext && '@vocab' in parentContext && context['@vocab'].indexOf(':') < 0) {\n                    newContext['@vocab'] = parentContext['@vocab'] + context['@vocab'];\n                }\n                else if (Util_1.Util.isCompactIri(context['@vocab']) || context['@vocab'] in newContext) {\n                    // @vocab is a compact IRI or refers exactly to a prefix\n                    newContext['@vocab'] = newContextWrapped.expandTerm(context['@vocab'], true);\n                }\n            }\n            this.expandPrefixedTerms(newContextWrapped, this.expandContentTypeToBase, keys);\n            // In JSON-LD 1.1, check if we are not redefining any protected keywords\n            if (!ignoreProtection && parentContext && processingMode >= 1.1) {\n                this.validateKeywordRedefinitions(parentContext, newContext, JsonLdContextNormalized_1.defaultExpandOptions, overlappingKeys);\n            }\n            if (this.validateContext && !internalOptions.skipValidation) {\n                this.validate(newContext, { processingMode });\n            }\n            return newContextWrapped;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Tried parsing a context that is not a string, array or object, but got ${context}`, ErrorCoded_1.ERROR_CODES.INVALID_LOCAL_CONTEXT);\n        }\n    }\n    /**\n     * Fetch the given URL as a raw JSON-LD context.\n     * @param url An URL.\n     * @return A promise resolving to a raw JSON-LD context.\n     */\n    async load(url) {\n        // First try to retrieve the context from cache\n        const cached = this.documentCache[url];\n        if (cached) {\n            return cached;\n        }\n        // If not in cache, load it\n        let document;\n        try {\n            document = await this.documentLoader.load(url);\n        }\n        catch (e) {\n            throw new ErrorCoded_1.ErrorCoded(`Failed to load remote context ${url}: ${e.message}`, ErrorCoded_1.ERROR_CODES.LOADING_REMOTE_CONTEXT_FAILED);\n        }\n        // Validate the context\n        if (!('@context' in document)) {\n            throw new ErrorCoded_1.ErrorCoded(`Missing @context in remote context at ${url}`, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        return this.documentCache[url] = document['@context'];\n    }\n    /**\n     * Override the given context that may be loaded.\n     *\n     * This will check whether or not the url is recursively being loaded.\n     * @param url An URL.\n     * @param options Parsing options.\n     * @return An overridden context, or null.\n     *         Optionally an error can be thrown if a cyclic context is detected.\n     */\n    getOverriddenLoad(url, options) {\n        if (url in (options.remoteContexts || {})) {\n            if (options.ignoreRemoteScopedContexts) {\n                return url;\n            }\n            else {\n                throw new ErrorCoded_1.ErrorCoded('Detected a cyclic context inclusion of ' + url, ErrorCoded_1.ERROR_CODES.RECURSIVE_CONTEXT_INCLUSION);\n            }\n        }\n        return null;\n    }\n    /**\n     * Load an @import'ed context.\n     * @param importContextIri The full URI of an @import value.\n     */\n    async loadImportContext(importContextIri) {\n        // Load the context - and do a deep clone since we are about to mutate it\n        let importContext = await this.load(importContextIri);\n        // Require the context to be a non-array object\n        if (typeof importContext !== 'object' || Array.isArray(importContext)) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context must be a single object: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_REMOTE_CONTEXT);\n        }\n        // Error if the context contains another @import\n        if ('@import' in importContext) {\n            throw new ErrorCoded_1.ErrorCoded('An imported context can not import another context: ' + importContextIri, ErrorCoded_1.ERROR_CODES.INVALID_CONTEXT_ENTRY);\n        }\n        importContext = Object.assign({}, importContext);\n        // Containers have to be converted into hash values the same way as for the importing context\n        // Otherwise context validation will fail for container values\n        this.containersToHash(importContext);\n        return importContext;\n    }\n}\nContextParser.DEFAULT_PROCESSING_MODE = 1.1;\nexports.ContextParser = ContextParser;\n//# sourceMappingURL=ContextParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ERROR_CODES = exports.ErrorCoded = void 0;\n/**\n * An error that has a certain error code.\n *\n * The error code can be any string.\n * All standardized error codes are listed in {@link ERROR_CODES}.\n */\nclass ErrorCoded extends Error {\n    /* istanbul ignore next */\n    constructor(message, code) {\n        super(message);\n        this.code = code;\n    }\n}\nexports.ErrorCoded = ErrorCoded;\n/**\n * All standardized JSON-LD error codes.\n * @see https://w3c.github.io/json-ld-api/#dom-jsonlderrorcode\n */\n// tslint:disable:object-literal-sort-keys\nvar ERROR_CODES;\n(function (ERROR_CODES) {\n    ERROR_CODES[\"COLLIDING_KEYWORDS\"] = \"colliding keywords\";\n    ERROR_CODES[\"CONFLICTING_INDEXES\"] = \"conflicting indexes\";\n    ERROR_CODES[\"CYCLIC_IRI_MAPPING\"] = \"cyclic IRI mapping\";\n    ERROR_CODES[\"INVALID_ID_VALUE\"] = \"invalid @id value\";\n    ERROR_CODES[\"INVALID_INDEX_VALUE\"] = \"invalid @index value\";\n    ERROR_CODES[\"INVALID_NEST_VALUE\"] = \"invalid @nest value\";\n    ERROR_CODES[\"INVALID_PREFIX_VALUE\"] = \"invalid @prefix value\";\n    ERROR_CODES[\"INVALID_PROPAGATE_VALUE\"] = \"invalid @propagate value\";\n    ERROR_CODES[\"INVALID_REVERSE_VALUE\"] = \"invalid @reverse value\";\n    ERROR_CODES[\"INVALID_IMPORT_VALUE\"] = \"invalid @import value\";\n    ERROR_CODES[\"INVALID_VERSION_VALUE\"] = \"invalid @version value\";\n    ERROR_CODES[\"INVALID_BASE_IRI\"] = \"invalid base IRI\";\n    ERROR_CODES[\"INVALID_CONTAINER_MAPPING\"] = \"invalid container mapping\";\n    ERROR_CODES[\"INVALID_CONTEXT_ENTRY\"] = \"invalid context entry\";\n    ERROR_CODES[\"INVALID_CONTEXT_NULLIFICATION\"] = \"invalid context nullification\";\n    ERROR_CODES[\"INVALID_DEFAULT_LANGUAGE\"] = \"invalid default language\";\n    ERROR_CODES[\"INVALID_INCLUDED_VALUE\"] = \"invalid @included value\";\n    ERROR_CODES[\"INVALID_IRI_MAPPING\"] = \"invalid IRI mapping\";\n    ERROR_CODES[\"INVALID_JSON_LITERAL\"] = \"invalid JSON literal\";\n    ERROR_CODES[\"INVALID_KEYWORD_ALIAS\"] = \"invalid keyword alias\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAP_VALUE\"] = \"invalid language map value\";\n    ERROR_CODES[\"INVALID_LANGUAGE_MAPPING\"] = \"invalid language mapping\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_STRING\"] = \"invalid language-tagged string\";\n    ERROR_CODES[\"INVALID_LANGUAGE_TAGGED_VALUE\"] = \"invalid language-tagged value\";\n    ERROR_CODES[\"INVALID_LOCAL_CONTEXT\"] = \"invalid local context\";\n    ERROR_CODES[\"INVALID_REMOTE_CONTEXT\"] = \"invalid remote context\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY\"] = \"invalid reverse property\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_MAP\"] = \"invalid reverse property map\";\n    ERROR_CODES[\"INVALID_REVERSE_PROPERTY_VALUE\"] = \"invalid reverse property value\";\n    ERROR_CODES[\"INVALID_SCOPED_CONTEXT\"] = \"invalid scoped context\";\n    ERROR_CODES[\"INVALID_SCRIPT_ELEMENT\"] = \"invalid script element\";\n    ERROR_CODES[\"INVALID_SET_OR_LIST_OBJECT\"] = \"invalid set or list object\";\n    ERROR_CODES[\"INVALID_TERM_DEFINITION\"] = \"invalid term definition\";\n    ERROR_CODES[\"INVALID_TYPE_MAPPING\"] = \"invalid type mapping\";\n    ERROR_CODES[\"INVALID_TYPE_VALUE\"] = \"invalid type value\";\n    ERROR_CODES[\"INVALID_TYPED_VALUE\"] = \"invalid typed value\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT\"] = \"invalid value object\";\n    ERROR_CODES[\"INVALID_VALUE_OBJECT_VALUE\"] = \"invalid value object value\";\n    ERROR_CODES[\"INVALID_VOCAB_MAPPING\"] = \"invalid vocab mapping\";\n    ERROR_CODES[\"IRI_CONFUSED_WITH_PREFIX\"] = \"IRI confused with prefix\";\n    ERROR_CODES[\"KEYWORD_REDEFINITION\"] = \"keyword redefinition\";\n    ERROR_CODES[\"LOADING_DOCUMENT_FAILED\"] = \"loading document failed\";\n    ERROR_CODES[\"LOADING_REMOTE_CONTEXT_FAILED\"] = \"loading remote context failed\";\n    ERROR_CODES[\"MULTIPLE_CONTEXT_LINK_HEADERS\"] = \"multiple context link headers\";\n    ERROR_CODES[\"PROCESSING_MODE_CONFLICT\"] = \"processing mode conflict\";\n    ERROR_CODES[\"PROTECTED_TERM_REDEFINITION\"] = \"protected term redefinition\";\n    ERROR_CODES[\"CONTEXT_OVERFLOW\"] = \"context overflow\";\n    ERROR_CODES[\"INVALID_BASE_DIRECTION\"] = \"invalid base direction\";\n    ERROR_CODES[\"RECURSIVE_CONTEXT_INCLUSION\"] = \"recursive context inclusion\";\n    ERROR_CODES[\"INVALID_STREAMING_KEY_ORDER\"] = \"invalid streaming key order\";\n    /**\n     * JSON-LD-star\n     */\n    ERROR_CODES[\"INVALID_EMBEDDED_NODE\"] = \"invalid embedded node\";\n    ERROR_CODES[\"INVALID_ANNOTATION\"] = \"invalid annotation\";\n})(ERROR_CODES = exports.ERROR_CODES || (exports.ERROR_CODES = {}));\n//# sourceMappingURL=ErrorCoded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.FetchDocumentLoader = void 0;\nrequire(\"cross-fetch/polyfill\");\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst http_link_header_1 = require(\"http-link-header\");\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\n/**\n * Loads documents via the fetch API.\n */\nclass FetchDocumentLoader {\n    constructor(fetcher) {\n        this.fetcher = fetcher;\n    }\n    async load(url) {\n        const response = await (this.fetcher || fetch)(url, { headers: new Headers({ accept: 'application/ld+json' }) });\n        if (response.ok && response.headers) {\n            let mediaType = response.headers.get('Content-Type');\n            if (mediaType) {\n                const colonPos = mediaType.indexOf(';');\n                if (colonPos > 0) {\n                    mediaType = mediaType.substr(0, colonPos);\n                }\n            }\n            if (mediaType === 'application/ld+json') {\n                // Return JSON-LD if proper content type was returned\n                return (await response.json());\n            }\n            else {\n                // Check for alternate link for a non-JSON-LD response\n                if (response.headers.has('Link')) {\n                    let alternateUrl;\n                    response.headers.forEach((value, key) => {\n                        if (key === 'link') {\n                            const linkHeader = (0, http_link_header_1.parse)(value);\n                            for (const link of linkHeader.get('type', 'application/ld+json')) {\n                                if (link.rel === 'alternate') {\n                                    if (alternateUrl) {\n                                        throw new Error('Multiple JSON-LD alternate links were found on ' + url);\n                                    }\n                                    alternateUrl = (0, relative_to_absolute_iri_1.resolve)(link.uri, url);\n                                }\n                            }\n                        }\n                    });\n                    if (alternateUrl) {\n                        return this.load(alternateUrl);\n                    }\n                }\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, ErrorCoded_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        else {\n            throw new Error(response.statusText || `Status code: ${response.status}`);\n        }\n    }\n}\nexports.FetchDocumentLoader = FetchDocumentLoader;\n//# sourceMappingURL=FetchDocumentLoader.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n//# sourceMappingURL=IDocumentLoader.js.map","\"use strict\";\n// tslint:disable:max-line-length\nObject.defineProperty(exports, \"__esModule\", { value: true });\n//# sourceMappingURL=JsonLdContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.defaultExpandOptions = exports.JsonLdContextNormalized = void 0;\nconst relative_to_absolute_iri_1 = require(\"relative-to-absolute-iri\");\nconst ErrorCoded_1 = require(\"./ErrorCoded\");\nconst Util_1 = require(\"./Util\");\n/**\n * A class exposing operations over a normalized JSON-LD context.\n */\nclass JsonLdContextNormalized {\n    constructor(contextRaw) {\n        this.contextRaw = contextRaw;\n    }\n    /**\n     * @return The raw inner context.\n     */\n    getContextRaw() {\n        return this.contextRaw;\n    }\n    /**\n     * Expand the term or prefix of the given term if it has one,\n     * otherwise return the term as-is.\n     *\n     * This will try to expand the IRI as much as possible.\n     *\n     * Iff in vocab-mode, then other references to other terms in the context can be used,\n     * such as to `myTerm`:\n     * ```\n     * {\n     *   \"myTerm\": \"http://example.org/myLongTerm\"\n     * }\n     * ```\n     *\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {boolean} expandVocab If the term is a predicate or type and should be expanded based on @vocab,\n     *                              otherwise it is considered a regular term that is expanded based on @base.\n     * @param {IExpandOptions} options Options that define the way how expansion must be done.\n     * @return {string} The expanded term, the term as-is, or null if it was explicitly disabled in the context.\n     * @throws If the term is aliased to an invalid value (not a string, IRI or keyword).\n     */\n    expandTerm(term, expandVocab, options = exports.defaultExpandOptions) {\n        const contextValue = this.contextRaw[term];\n        // Immediately return if the term was disabled in the context\n        if (contextValue === null || (contextValue && contextValue['@id'] === null)) {\n            return null;\n        }\n        // Check the @id\n        let validIriMapping = true;\n        if (contextValue && expandVocab) {\n            const value = Util_1.Util.getContextValueId(contextValue);\n            if (value && value !== term) {\n                if (typeof value !== 'string' || (!Util_1.Util.isValidIri(value) && !Util_1.Util.isValidKeyword(value))) {\n                    // Don't mark this mapping as invalid if we have an unknown keyword, but of the correct form.\n                    if (!Util_1.Util.isPotentialKeyword(value)) {\n                        validIriMapping = false;\n                    }\n                }\n                else {\n                    return value;\n                }\n            }\n        }\n        // Check if the term is prefixed\n        const prefix = Util_1.Util.getPrefix(term, this.contextRaw);\n        const vocab = this.contextRaw['@vocab'];\n        const vocabRelative = (!!vocab || vocab === '') && vocab.indexOf(':') < 0;\n        const base = this.contextRaw['@base'];\n        const potentialKeyword = Util_1.Util.isPotentialKeyword(term);\n        if (prefix) {\n            const contextPrefixValue = this.contextRaw[prefix];\n            const value = Util_1.Util.getContextValueId(contextPrefixValue);\n            if (value) {\n                if (typeof contextPrefixValue === 'string' || !options.allowPrefixForcing) {\n                    // If we have a simple term definition,\n                    // check the last character of the prefix to determine whether or not it is a prefix.\n                    // Validate that prefix ends with gen-delim character, unless @prefix is true\n                    if (!Util_1.Util.isSimpleTermDefinitionPrefix(value, options)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                else {\n                    // If we have an expanded term definition, default to @prefix: false\n                    if (value[0] !== '_' && !potentialKeyword && !contextPrefixValue['@prefix'] && !(term in this.contextRaw)) {\n                        // Treat the term as an absolute IRI\n                        return term;\n                    }\n                }\n                return value + term.substr(prefix.length + 1);\n            }\n        }\n        else if (expandVocab && ((vocab || vocab === '') || (options.allowVocabRelativeToBase && (base && vocabRelative)))\n            && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            if (vocabRelative) {\n                if (options.allowVocabRelativeToBase) {\n                    return ((vocab || base) ? (0, relative_to_absolute_iri_1.resolve)(vocab, base) : '') + term;\n                }\n                else {\n                    throw new ErrorCoded_1.ErrorCoded(`Relative vocab expansion for term '${term}' with vocab '${vocab}' is not allowed.`, ErrorCoded_1.ERROR_CODES.INVALID_VOCAB_MAPPING);\n                }\n            }\n            else {\n                return vocab + term;\n            }\n        }\n        else if (!expandVocab && base && !potentialKeyword && !Util_1.Util.isCompactIri(term)) {\n            return (0, relative_to_absolute_iri_1.resolve)(term, base);\n        }\n        // Return the term as-is, unless we discovered an invalid IRI mapping for this term in the context earlier.\n        if (validIriMapping) {\n            return term;\n        }\n        else {\n            throw new ErrorCoded_1.ErrorCoded(`Invalid IRI mapping found for context entry '${term}': '${JSON.stringify(contextValue)}'`, ErrorCoded_1.ERROR_CODES.INVALID_IRI_MAPPING);\n        }\n    }\n    /**\n     * Compact the given term using @base, @vocab, an aliased term, or a prefixed term.\n     *\n     * This will try to compact the IRI as much as possible.\n     *\n     * @param {string} iri An IRI to compact.\n     * @param {boolean} vocab If the term is a predicate or type and should be compacted based on @vocab,\n     *                        otherwise it is considered a regular term that is compacted based on @base.\n     * @return {string} The compacted term or the IRI as-is.\n     */\n    compactIri(iri, vocab) {\n        // Try @vocab compacting\n        if (vocab && this.contextRaw['@vocab'] && iri.startsWith(this.contextRaw['@vocab'])) {\n            return iri.substr(this.contextRaw['@vocab'].length);\n        }\n        // Try @base compacting\n        if (!vocab && this.contextRaw['@base'] && iri.startsWith(this.contextRaw['@base'])) {\n            return iri.substr(this.contextRaw['@base'].length);\n        }\n        // Loop over all terms in the context\n        // This will try to prefix as short as possible.\n        // Once a fully compacted alias is found, return immediately, as we can not go any shorter.\n        const shortestPrefixing = { prefix: '', suffix: iri };\n        for (const key in this.contextRaw) {\n            const value = this.contextRaw[key];\n            if (value && !Util_1.Util.isPotentialKeyword(key)) {\n                const contextIri = Util_1.Util.getContextValueId(value);\n                if (iri.startsWith(contextIri)) {\n                    const suffix = iri.substr(contextIri.length);\n                    if (!suffix) {\n                        if (vocab) {\n                            // Immediately return on compacted alias\n                            return key;\n                        }\n                    }\n                    else if (suffix.length < shortestPrefixing.suffix.length) {\n                        // Overwrite the shortest prefix\n                        shortestPrefixing.prefix = key;\n                        shortestPrefixing.suffix = suffix;\n                    }\n                }\n            }\n        }\n        // Return the shortest prefix\n        if (shortestPrefixing.prefix) {\n            return shortestPrefixing.prefix + ':' + shortestPrefixing.suffix;\n        }\n        return iri;\n    }\n}\nexports.JsonLdContextNormalized = JsonLdContextNormalized;\nexports.defaultExpandOptions = {\n    allowPrefixForcing: true,\n    allowPrefixNonGenDelims: false,\n    allowVocabRelativeToBase: true,\n};\n//# sourceMappingURL=JsonLdContextNormalized.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nclass Util {\n    /**\n     * Check if the given term is a valid compact IRI.\n     * Otherwise, it may be an IRI.\n     * @param {string} term A term.\n     * @return {boolean} If it is a compact IRI.\n     */\n    static isCompactIri(term) {\n        return term.indexOf(':') > 0 && !(term && term[0] === '#');\n    }\n    /**\n     * Get the prefix from the given term.\n     * @see https://json-ld.org/spec/latest/json-ld/#compact-iris\n     * @param {string} term A term that is an URL or a prefixed URL.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @return {string} The prefix or null.\n     */\n    static getPrefix(term, context) {\n        // Do not consider relative IRIs starting with a hash as compact IRIs\n        if (term && term[0] === '#') {\n            return null;\n        }\n        const separatorPos = term.indexOf(':');\n        if (separatorPos >= 0) {\n            // Suffix can not begin with two slashes\n            if (term.length > separatorPos + 1\n                && term.charAt(separatorPos + 1) === '/'\n                && term.charAt(separatorPos + 2) === '/') {\n                return null;\n            }\n            const prefix = term.substr(0, separatorPos);\n            // Prefix can not be an underscore (this is a blank node)\n            if (prefix === '_') {\n                return null;\n            }\n            // Prefix must match a term in the active context\n            if (context[prefix]) {\n                return prefix;\n            }\n        }\n        return null;\n    }\n    /**\n     * From a given context entry value, get the string value, or the @id field.\n     * @param contextValue A value for a term in a context.\n     * @return {string} The id value, or null.\n     */\n    static getContextValueId(contextValue) {\n        if (contextValue === null || typeof contextValue === 'string') {\n            return contextValue;\n        }\n        const id = contextValue['@id'];\n        return id ? id : null;\n    }\n    /**\n     * Check if the given simple term definition (string-based value of a context term)\n     * should be considered a prefix.\n     * @param value A simple term definition value.\n     * @param options Options that define the way how expansion must be done.\n     */\n    static isSimpleTermDefinitionPrefix(value, options) {\n        return !Util.isPotentialKeyword(value)\n            && (options.allowPrefixNonGenDelims || (typeof value === 'string' && (value[0] === '_' || Util.isPrefixIriEndingWithGenDelim(value))));\n    }\n    /**\n     * Check if the given keyword is of the keyword format \"@\"1*ALPHA.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is of the keyword format.\n     */\n    static isPotentialKeyword(keyword) {\n        return typeof keyword === 'string' && Util.KEYWORD_REGEX.test(keyword);\n    }\n    /**\n     * Check if the given prefix ends with a gen-delim character.\n     * @param {string} prefixIri A prefix IRI.\n     * @return {boolean} If the given prefix IRI is valid.\n     */\n    static isPrefixIriEndingWithGenDelim(prefixIri) {\n        return Util.ENDS_WITH_GEN_DELIM.test(prefixIri);\n    }\n    /**\n     * Check if the given context value can be a prefix value.\n     * @param value A context value.\n     * @return {boolean} If it can be a prefix value.\n     */\n    static isPrefixValue(value) {\n        return value && (typeof value === 'string' || (value && typeof value === 'object'));\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return Boolean(iri && Util.IRI_REGEX.test(iri));\n    }\n    /**\n     * Check if the given IRI is valid, this includes the possibility of being a relative IRI.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIriWeak(iri) {\n        return !!iri && iri[0] !== ':' && Util.IRI_REGEX_WEAK.test(iri);\n    }\n    /**\n     * Check if the given keyword is a defined according to the JSON-LD specification.\n     * @param {string} keyword A potential keyword.\n     * @return {boolean} If the given keyword is valid.\n     */\n    static isValidKeyword(keyword) {\n        return Util.VALID_KEYWORDS[keyword];\n    }\n    /**\n     * Check if the given term is protected in the context.\n     * @param {IJsonLdContextNormalizedRaw} context A context.\n     * @param {string} key A context term.\n     * @return {boolean} If the given term has an @protected flag.\n     */\n    static isTermProtected(context, key) {\n        const value = context[key];\n        return !(typeof value === 'string') && value && value['@protected'];\n    }\n    /**\n     * Check if the given context has at least one protected term.\n     * @param context A context.\n     * @return If the context has a protected term.\n     */\n    static hasProtectedTerms(context) {\n        for (const key of Object.keys(context)) {\n            if (Util.isTermProtected(context, key)) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check if the given key is an internal reserved keyword.\n     * @param key A context key.\n     */\n    static isReservedInternalKeyword(key) {\n        return key.startsWith('@__');\n    }\n    /**\n     * Check if two objects are deepEqual to on another.\n     * @param object1 The first object to test.\n     * @param object2 The second object to test.\n     */\n    static deepEqual(object1, object2) {\n        const objKeys1 = Object.keys(object1);\n        const objKeys2 = Object.keys(object2);\n        if (objKeys1.length !== objKeys2.length)\n            return false;\n        return objKeys1.every((key) => {\n            const value1 = object1[key];\n            const value2 = object2[key];\n            return (value1 === value2) || (value1 !== null &&\n                value2 !== null &&\n                typeof value1 === \"object\" &&\n                typeof value2 === \"object\" &&\n                this.deepEqual(value1, value2));\n        });\n    }\n    ;\n}\n// Regex for valid IRIs\nUtil.IRI_REGEX = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^ \"<>{}|\\\\\\[\\]`#]*(#[^#]*)?$/;\n// Weaker regex for valid IRIs, this includes relative IRIs\nUtil.IRI_REGEX_WEAK = /(?::[^:])|\\//;\n// Regex for keyword form\nUtil.KEYWORD_REGEX = /^@[a-z]+$/i;\n// Regex to see if an IRI ends with a gen-delim character (see RFC 3986)\nUtil.ENDS_WITH_GEN_DELIM = /[:/?#\\[\\]@]$/;\n// Regex for language tags\nUtil.REGEX_LANGUAGE_TAG = /^[a-zA-Z]+(-[a-zA-Z0-9]+)*$/;\n// Regex for base directions\nUtil.REGEX_DIRECTION_TAG = /^(ltr)|(rtl)$/;\n// All known valid JSON-LD keywords\n// @see https://www.w3.org/TR/json-ld11/#keywords\nUtil.VALID_KEYWORDS = {\n    '@annotation': true,\n    '@base': true,\n    '@container': true,\n    '@context': true,\n    '@direction': true,\n    '@graph': true,\n    '@id': true,\n    '@import': true,\n    '@included': true,\n    '@index': true,\n    '@json': true,\n    '@language': true,\n    '@list': true,\n    '@nest': true,\n    '@none': true,\n    '@prefix': true,\n    '@propagate': true,\n    '@protected': true,\n    '@reverse': true,\n    '@set': true,\n    '@type': true,\n    '@value': true,\n    '@version': true,\n    '@vocab': true,\n};\n// Keys in the contexts that will not be expanded based on the base IRI\nUtil.EXPAND_KEYS_BLACKLIST = [\n    '@base',\n    '@vocab',\n    '@language',\n    '@version',\n    '@direction',\n];\n// Keys in the contexts that may not be aliased from\nUtil.ALIAS_DOMAIN_BLACKLIST = [\n    '@container',\n    '@graph',\n    '@id',\n    '@index',\n    '@list',\n    '@nest',\n    '@none',\n    '@prefix',\n    '@reverse',\n    '@set',\n    '@type',\n    '@value',\n    '@version',\n];\n// Keys in the contexts that may not be aliased to\nUtil.ALIAS_RANGE_BLACKLIST = [\n    '@context',\n    '@preserve',\n];\n// All valid @container values\nUtil.CONTAINERS = [\n    '@list',\n    '@set',\n    '@index',\n    '@language',\n    '@graph',\n    '@id',\n    '@type',\n];\n// All valid @container values under processing mode 1.0\nUtil.CONTAINERS_1_0 = [\n    '@list',\n    '@set',\n    '@index',\n];\nexports.Util = Util;\n//# sourceMappingURL=Util.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/JsonLdParser\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst stream_1 = require(\"stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        // Special cases when receiving something else than the JSON-LD media type\n        if (mediaType !== 'application/ld+json') {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = http_link_header_1.parse(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        const output = new stream_1.PassThrough({ readableObjectMode: true });\n        stream.on('error', (error) => parsed.emit('error', error));\n        stream.on('data', (data) => output.push(data));\n        stream.on('end', () => output.push(null));\n        const parsed = output.pipe(new JsonLdParser(this.options));\n        return parsed;\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.emit('data', this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (this.util.isLiteral(depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        if (!subjects) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            if (bufferedValue.reverse) {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.object, bufferedValue.predicate, subject, graph));\n                            }\n                            else {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(subject, bufferedValue.predicate, bufferedValue.object, graph));\n                            }\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else if (keys[depth] === '@type'\n                        || typeof keys[depth] === 'number' && keys[depth - 1] === '@type') { // Also capture @type with array values\n                        // Remove @type from keys, because we want it to apply to parent later on\n                        this.typeJobs.push({ job: valueJobCb, keys: keys.slice(0, keys.length - 1) });\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        // Handle non-context jobs\n        for (const job of this.contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\n//# sourceMappingURL=JsonLdParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst ErrorCoded_1 = require(\"jsonld-context-parser/lib/ErrorCoded\");\nconst ContextTree_1 = require(\"./ContextTree\");\nconst JsonLdParser_1 = require(\"./JsonLdParser\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = scopedContext;\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nexports.ParsingContext = ParsingContext;\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\n//# sourceMappingURL=ParsingContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst rdf_data_factory_1 = require(\"rdf-data-factory\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection && this.parsingContext.rdfDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection && this.parsingContext.rdfDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        return this.nullableTermToArray(this.resourceToTerm(context, value[\"@id\"]));\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection && this.parsingContext.rdfDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    isLiteral(depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n}\nexports.Util = Util;\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\n//# sourceMappingURL=Util.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = require(\"../containerhandler/ContainerHandlerIdentifier\");\nconst ContainerHandlerIndex_1 = require(\"../containerhandler/ContainerHandlerIndex\");\nconst ContainerHandlerLanguage_1 = require(\"../containerhandler/ContainerHandlerLanguage\");\nconst ContainerHandlerType_1 = require(\"../containerhandler/ContainerHandlerType\");\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nexports.EntryHandlerContainer = EntryHandlerContainer;\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\n//# sourceMappingURL=EntryHandlerContainer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../Util\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            if (reverse) {\n                                util.validateReverseSubject(object);\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                            }\n                            else {\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                            }\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    if (reverse) {\n                        util.validateReverseSubject(object);\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                    }\n                    else {\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                    }\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse });\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../../Util\");\nconst EntryHandlerPredicate_1 = require(\"../EntryHandlerPredicate\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                if (!('@propagate' in c.getContextRaw())) {\n                    c.getContextRaw()['@propagate'] = false;\n                }\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] === false) {\n                    c.getContextRaw()['@__propagateFallback'] = context.getContextRaw();\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map","/*global Buffer*/\n// Named constants with unique integer values\nvar C = {};\n// Tokens\nvar LEFT_BRACE    = C.LEFT_BRACE    = 0x1;\nvar RIGHT_BRACE   = C.RIGHT_BRACE   = 0x2;\nvar LEFT_BRACKET  = C.LEFT_BRACKET  = 0x3;\nvar RIGHT_BRACKET = C.RIGHT_BRACKET = 0x4;\nvar COLON         = C.COLON         = 0x5;\nvar COMMA         = C.COMMA         = 0x6;\nvar TRUE          = C.TRUE          = 0x7;\nvar FALSE         = C.FALSE         = 0x8;\nvar NULL          = C.NULL          = 0x9;\nvar STRING        = C.STRING        = 0xa;\nvar NUMBER        = C.NUMBER        = 0xb;\n// Tokenizer States\nvar START   = C.START   = 0x11;\nvar STOP    = C.STOP    = 0x12;\nvar TRUE1   = C.TRUE1   = 0x21;\nvar TRUE2   = C.TRUE2   = 0x22;\nvar TRUE3   = C.TRUE3   = 0x23;\nvar FALSE1  = C.FALSE1  = 0x31;\nvar FALSE2  = C.FALSE2  = 0x32;\nvar FALSE3  = C.FALSE3  = 0x33;\nvar FALSE4  = C.FALSE4  = 0x34;\nvar NULL1   = C.NULL1   = 0x41;\nvar NULL2   = C.NULL2   = 0x42;\nvar NULL3   = C.NULL3   = 0x43;\nvar NUMBER1 = C.NUMBER1 = 0x51;\nvar NUMBER3 = C.NUMBER3 = 0x53;\nvar STRING1 = C.STRING1 = 0x61;\nvar STRING2 = C.STRING2 = 0x62;\nvar STRING3 = C.STRING3 = 0x63;\nvar STRING4 = C.STRING4 = 0x64;\nvar STRING5 = C.STRING5 = 0x65;\nvar STRING6 = C.STRING6 = 0x66;\n// Parser States\nvar VALUE   = C.VALUE   = 0x71;\nvar KEY     = C.KEY     = 0x72;\n// Parser Modes\nvar OBJECT  = C.OBJECT  = 0x81;\nvar ARRAY   = C.ARRAY   = 0x82;\n// Character constants\nvar BACK_SLASH =      \"\\\\\".charCodeAt(0);\nvar FORWARD_SLASH =   \"\\/\".charCodeAt(0);\nvar BACKSPACE =       \"\\b\".charCodeAt(0);\nvar FORM_FEED =       \"\\f\".charCodeAt(0);\nvar NEWLINE =         \"\\n\".charCodeAt(0);\nvar CARRIAGE_RETURN = \"\\r\".charCodeAt(0);\nvar TAB =             \"\\t\".charCodeAt(0);\n\nvar STRING_BUFFER_SIZE = 64 * 1024;\n\nfunction Parser() {\n  this.tState = START;\n  this.value = undefined;\n\n  this.string = undefined; // string data\n  this.stringBuffer = Buffer.alloc ? Buffer.alloc(STRING_BUFFER_SIZE) : new Buffer(STRING_BUFFER_SIZE);\n  this.stringBufferOffset = 0;\n  this.unicode = undefined; // unicode escapes\n  this.highSurrogate = undefined;\n\n  this.key = undefined;\n  this.mode = undefined;\n  this.stack = [];\n  this.state = VALUE;\n  this.bytes_remaining = 0; // number of bytes remaining in multi byte utf8 char to read after split boundary\n  this.bytes_in_sequence = 0; // bytes in multi byte utf8 char to read\n  this.temp_buffs = { \"2\": new Buffer(2), \"3\": new Buffer(3), \"4\": new Buffer(4) }; // for rebuilding chars split before boundary is reached\n\n  // Stream offset\n  this.offset = -1;\n}\n\n// Slow code to string converter (only used when throwing syntax errors)\nParser.toknam = function (code) {\n  var keys = Object.keys(C);\n  for (var i = 0, l = keys.length; i < l; i++) {\n    var key = keys[i];\n    if (C[key] === code) { return key; }\n  }\n  return code && (\"0x\" + code.toString(16));\n};\n\nvar proto = Parser.prototype;\nproto.onError = function (err) { throw err; };\nproto.charError = function (buffer, i) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + JSON.stringify(String.fromCharCode(buffer[i])) + \" at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n};\nproto.appendStringChar = function (char) {\n  if (this.stringBufferOffset >= STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8');\n    this.stringBufferOffset = 0;\n  }\n\n  this.stringBuffer[this.stringBufferOffset++] = char;\n};\nproto.appendStringBuf = function (buf, start, end) {\n  var size = buf.length;\n  if (typeof start === 'number') {\n    if (typeof end === 'number') {\n      if (end < 0) {\n        // adding a negative end decreeses the size\n        size = buf.length - start + end;\n      } else {\n        size = end - start;\n      }\n    } else {\n      size = buf.length - start;\n    }\n  }\n\n  if (size < 0) {\n    size = 0;\n  }\n\n  if (this.stringBufferOffset + size > STRING_BUFFER_SIZE) {\n    this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n    this.stringBufferOffset = 0;\n  }\n\n  buf.copy(this.stringBuffer, this.stringBufferOffset, start, end);\n  this.stringBufferOffset += size;\n};\nproto.write = function (buffer) {\n  if (typeof buffer === \"string\") buffer = new Buffer(buffer);\n  var n;\n  for (var i = 0, l = buffer.length; i < l; i++) {\n    if (this.tState === START){\n      n = buffer[i];\n      this.offset++;\n      if(n === 0x7b){ this.onToken(LEFT_BRACE, \"{\"); // {\n      }else if(n === 0x7d){ this.onToken(RIGHT_BRACE, \"}\"); // }\n      }else if(n === 0x5b){ this.onToken(LEFT_BRACKET, \"[\"); // [\n      }else if(n === 0x5d){ this.onToken(RIGHT_BRACKET, \"]\"); // ]\n      }else if(n === 0x3a){ this.onToken(COLON, \":\");  // :\n      }else if(n === 0x2c){ this.onToken(COMMA, \",\"); // ,\n      }else if(n === 0x74){ this.tState = TRUE1;  // t\n      }else if(n === 0x66){ this.tState = FALSE1;  // f\n      }else if(n === 0x6e){ this.tState = NULL1; // n\n      }else if(n === 0x22){ // \"\n        this.string = \"\";\n        this.stringBufferOffset = 0;\n        this.tState = STRING1;\n      }else if(n === 0x2d){ this.string = \"-\"; this.tState = NUMBER1; // -\n      }else{\n        if (n >= 0x30 && n < 0x40) { // 1-9\n          this.string = String.fromCharCode(n); this.tState = NUMBER3;\n        } else if (n === 0x20 || n === 0x09 || n === 0x0a || n === 0x0d) {\n          // whitespace\n        } else {\n          return this.charError(buffer, i);\n        }\n      }\n    }else if (this.tState === STRING1){ // After open quote\n      n = buffer[i]; // get current byte from buffer\n      // check for carry over of a multi byte char split between data chunks\n      // & fill temp buffer it with start of this data chunk up to the boundary limit set in the last iteration\n      if (this.bytes_remaining > 0) {\n        for (var j = 0; j < this.bytes_remaining; j++) {\n          this.temp_buffs[this.bytes_in_sequence][this.bytes_in_sequence - this.bytes_remaining + j] = buffer[j];\n        }\n\n        this.appendStringBuf(this.temp_buffs[this.bytes_in_sequence]);\n        this.bytes_in_sequence = this.bytes_remaining = 0;\n        i = i + j - 1;\n      } else if (this.bytes_remaining === 0 && n >= 128) { // else if no remainder bytes carried over, parse multi byte (>=128) chars one at a time\n        if (n <= 193 || n > 244) {\n          return this.onError(new Error(\"Invalid UTF-8 character at position \" + i + \" in state \" + Parser.toknam(this.tState)));\n        }\n        if ((n >= 194) && (n <= 223)) this.bytes_in_sequence = 2;\n        if ((n >= 224) && (n <= 239)) this.bytes_in_sequence = 3;\n        if ((n >= 240) && (n <= 244)) this.bytes_in_sequence = 4;\n        if ((this.bytes_in_sequence + i) > buffer.length) { // if bytes needed to complete char fall outside buffer length, we have a boundary split\n          for (var k = 0; k <= (buffer.length - 1 - i); k++) {\n            this.temp_buffs[this.bytes_in_sequence][k] = buffer[i + k]; // fill temp buffer of correct size with bytes available in this chunk\n          }\n          this.bytes_remaining = (i + this.bytes_in_sequence) - buffer.length;\n          i = buffer.length - 1;\n        } else {\n          this.appendStringBuf(buffer, i, i + this.bytes_in_sequence);\n          i = i + this.bytes_in_sequence - 1;\n        }\n      } else if (n === 0x22) {\n        this.tState = START;\n        this.string += this.stringBuffer.toString('utf8', 0, this.stringBufferOffset);\n        this.stringBufferOffset = 0;\n        this.onToken(STRING, this.string);\n        this.offset += Buffer.byteLength(this.string, 'utf8') + 1;\n        this.string = undefined;\n      }\n      else if (n === 0x5c) {\n        this.tState = STRING2;\n      }\n      else if (n >= 0x20) { this.appendStringChar(n); }\n      else {\n          return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING2){ // After backslash\n      n = buffer[i];\n      if(n === 0x22){ this.appendStringChar(n); this.tState = STRING1;\n      }else if(n === 0x5c){ this.appendStringChar(BACK_SLASH); this.tState = STRING1;\n      }else if(n === 0x2f){ this.appendStringChar(FORWARD_SLASH); this.tState = STRING1;\n      }else if(n === 0x62){ this.appendStringChar(BACKSPACE); this.tState = STRING1;\n      }else if(n === 0x66){ this.appendStringChar(FORM_FEED); this.tState = STRING1;\n      }else if(n === 0x6e){ this.appendStringChar(NEWLINE); this.tState = STRING1;\n      }else if(n === 0x72){ this.appendStringChar(CARRIAGE_RETURN); this.tState = STRING1;\n      }else if(n === 0x74){ this.appendStringChar(TAB); this.tState = STRING1;\n      }else if(n === 0x75){ this.unicode = \"\"; this.tState = STRING3;\n      }else{\n        return this.charError(buffer, i);\n      }\n    }else if (this.tState === STRING3 || this.tState === STRING4 || this.tState === STRING5 || this.tState === STRING6){ // unicode hex codes\n      n = buffer[i];\n      // 0-9 A-F a-f\n      if ((n >= 0x30 && n < 0x40) || (n > 0x40 && n <= 0x46) || (n > 0x60 && n <= 0x66)) {\n        this.unicode += String.fromCharCode(n);\n        if (this.tState++ === STRING6) {\n          var intVal = parseInt(this.unicode, 16);\n          this.unicode = undefined;\n          if (this.highSurrogate !== undefined && intVal >= 0xDC00 && intVal < (0xDFFF + 1)) { //<56320,57343> - lowSurrogate\n            this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate, intVal)));\n            this.highSurrogate = undefined;\n          } else if (this.highSurrogate === undefined && intVal >= 0xD800 && intVal < (0xDBFF + 1)) { //<55296,56319> - highSurrogate\n            this.highSurrogate = intVal;\n          } else {\n            if (this.highSurrogate !== undefined) {\n              this.appendStringBuf(new Buffer(String.fromCharCode(this.highSurrogate)));\n              this.highSurrogate = undefined;\n            }\n            this.appendStringBuf(new Buffer(String.fromCharCode(intVal)));\n          }\n          this.tState = STRING1;\n        }\n      } else {\n        return this.charError(buffer, i);\n      }\n    } else if (this.tState === NUMBER1 || this.tState === NUMBER3) {\n        n = buffer[i];\n\n        switch (n) {\n          case 0x30: // 0\n          case 0x31: // 1\n          case 0x32: // 2\n          case 0x33: // 3\n          case 0x34: // 4\n          case 0x35: // 5\n          case 0x36: // 6\n          case 0x37: // 7\n          case 0x38: // 8\n          case 0x39: // 9\n          case 0x2e: // .\n          case 0x65: // e\n          case 0x45: // E\n          case 0x2b: // +\n          case 0x2d: // -\n            this.string += String.fromCharCode(n);\n            this.tState = NUMBER3;\n            break;\n          default:\n            this.tState = START;\n            var result = Number(this.string);\n\n            if (isNaN(result)){\n              return this.charError(buffer, i);\n            }\n\n            if ((this.string.match(/[0-9]+/) == this.string) && (result.toString() != this.string)) {\n              // Long string of digits which is an ID string and not valid and/or safe JavaScript integer Number\n              this.onToken(STRING, this.string);\n            } else {\n              this.onToken(NUMBER, result);\n            }\n\n            this.offset += this.string.length - 1;\n            this.string = undefined;\n            i--;\n            break;\n        }\n    }else if (this.tState === TRUE1){ // r\n      if (buffer[i] === 0x72) { this.tState = TRUE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE2){ // u\n      if (buffer[i] === 0x75) { this.tState = TRUE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === TRUE3){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(TRUE, true); this.offset+= 3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE1){ // a\n      if (buffer[i] === 0x61) { this.tState = FALSE2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE2){ // l\n      if (buffer[i] === 0x6c) { this.tState = FALSE3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE3){ // s\n      if (buffer[i] === 0x73) { this.tState = FALSE4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === FALSE4){ // e\n      if (buffer[i] === 0x65) { this.tState = START; this.onToken(FALSE, false); this.offset+= 4; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL1){ // u\n      if (buffer[i] === 0x75) { this.tState = NULL2; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL2){ // l\n      if (buffer[i] === 0x6c) { this.tState = NULL3; }\n      else { return this.charError(buffer, i); }\n    }else if (this.tState === NULL3){ // l\n      if (buffer[i] === 0x6c) { this.tState = START; this.onToken(NULL, null); this.offset += 3; }\n      else { return this.charError(buffer, i); }\n    }\n  }\n};\nproto.onToken = function (token, value) {\n  // Override this to get events\n};\n\nproto.parseError = function (token, value) {\n  this.tState = STOP;\n  this.onError(new Error(\"Unexpected \" + Parser.toknam(token) + (value ? (\"(\" + JSON.stringify(value) + \")\") : \"\") + \" in state \" + Parser.toknam(this.state)));\n};\nproto.push = function () {\n  this.stack.push({value: this.value, key: this.key, mode: this.mode});\n};\nproto.pop = function () {\n  var value = this.value;\n  var parent = this.stack.pop();\n  this.value = parent.value;\n  this.key = parent.key;\n  this.mode = parent.mode;\n  this.emit(value);\n  if (!this.mode) { this.state = VALUE; }\n};\nproto.emit = function (value) {\n  if (this.mode) { this.state = COMMA; }\n  this.onValue(value);\n};\nproto.onValue = function (value) {\n  // Override me\n};\nproto.onToken = function (token, value) {\n  if(this.state === VALUE){\n    if(token === STRING || token === NUMBER || token === TRUE || token === FALSE || token === NULL){\n      if (this.value) {\n        this.value[this.key] = value;\n      }\n      this.emit(value);\n    }else if(token === LEFT_BRACE){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = {};\n      } else {\n        this.value = {};\n      }\n      this.key = undefined;\n      this.state = KEY;\n      this.mode = OBJECT;\n    }else if(token === LEFT_BRACKET){\n      this.push();\n      if (this.value) {\n        this.value = this.value[this.key] = [];\n      } else {\n        this.value = [];\n      }\n      this.key = 0;\n      this.mode = ARRAY;\n      this.state = VALUE;\n    }else if(token === RIGHT_BRACE){\n      if (this.mode === OBJECT) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else if(token === RIGHT_BRACKET){\n      if (this.mode === ARRAY) {\n        this.pop();\n      } else {\n        return this.parseError(token, value);\n      }\n    }else{\n      return this.parseError(token, value);\n    }\n  }else if(this.state === KEY){\n    if (token === STRING) {\n      this.key = value;\n      this.state = COLON;\n    } else if (token === RIGHT_BRACE) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else if(this.state === COLON){\n    if (token === COLON) { this.state = VALUE; }\n    else { return this.parseError(token, value); }\n  }else if(this.state === COMMA){\n    if (token === COMMA) {\n      if (this.mode === ARRAY) { this.key++; this.state = VALUE; }\n      else if (this.mode === OBJECT) { this.state = KEY; }\n\n    } else if (token === RIGHT_BRACKET && this.mode === ARRAY || token === RIGHT_BRACE && this.mode === OBJECT) {\n      this.pop();\n    } else {\n      return this.parseError(token, value);\n    }\n  }else{\n    return this.parseError(token, value);\n  }\n};\n\nParser.C = C;\n\nmodule.exports = Parser;\n"],"names":["Sink","ParserStream","Parser","constructor","options","super","module","exports","rdf","JsonLdParser","Transform","relativeIriProtocol","termCleanup","factory","term","termType","value","startsWith","namedNode","slice","length","quadCleanup","cleanup","quad","subject","predicate","object","graph","input","baseIRI","context","parser","dataFactory","streamingProfile","pipe","transform","objectMode","encoding","callback","on","Object","entries","forEach","prefix","iri","emit","err","destroy","DataFactory","BlankNode","id","this","nextId","equals","other","prototype","DefaultGraph","fromTermRaw","Literal","NamedNode","Quad","Variable","blankNode","literal","languageOrDatatype","indexOf","variable","defaultGraph","defaultGraphInstance","triple","fromTerm","original","call","fromQuad","language","datatype","stringDatatype","langStringDatatype","name","Error","Impl","import","output","assign","readable","self","support","searchParams","iterable","Symbol","blob","Blob","e","formData","arrayBuffer","isDataView","obj","DataView","isPrototypeOf","viewClasses","isArrayBufferView","ArrayBuffer","isView","toString","normalizeName","String","test","TypeError","toLowerCase","normalizeValue","iteratorFor","items","iterator","next","shift","done","undefined","Headers","headers","map","append","Array","isArray","header","getOwnPropertyNames","consumed","body","bodyUsed","Promise","reject","fileReaderReady","reader","resolve","onload","result","onerror","error","readBlobAsArrayBuffer","FileReader","promise","readAsArrayBuffer","readBlobAsText","readAsText","readArrayBufferAsText","buf","view","Uint8Array","chars","i","fromCharCode","join","bufferClone","byteLength","set","buffer","Body","_initBody","_bodyInit","_bodyText","_bodyBlob","FormData","_bodyFormData","URLSearchParams","_bodyArrayBuffer","get","type","rejected","then","text","decode","json","JSON","parse","oldValue","has","hasOwnProperty","thisArg","keys","push","values","methods","normalizeMethod","method","upcased","toUpperCase","Request","url","credentials","mode","signal","referrer","form","trim","split","bytes","replace","decodeURIComponent","parseHeaders","rawHeaders","preProcessedHeaders","line","parts","key","Response","bodyInit","status","ok","statusText","clone","response","redirectStatuses","redirect","RangeError","location","DOMException","message","stack","create","fetch","init","request","aborted","xhr","XMLHttpRequest","abortXhr","abort","getAllResponseHeaders","responseURL","responseText","ontimeout","onabort","open","withCredentials","responseType","setRequestHeader","addEventListener","onreadystatechange","readyState","removeEventListener","send","polyfill","defineProperty","__createBinding","o","m","k","k2","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","__exportStar","p","ContextParser","relative_to_absolute_iri_1","ErrorCoded_1","FetchDocumentLoader_1","JsonLdContextNormalized_1","Util_1","documentLoader","FetchDocumentLoader","documentCache","validateContext","skipValidation","expandContentTypeToBase","remoteContextsDepthLimit","redirectSchemaOrgHttps","validateLanguage","strictRange","errorCode","ErrorCoded","stringify","Util","REGEX_LANGUAGE_TAG","validateDirection","strictValues","ERROR_CODES","INVALID_BASE_DIRECTION","REGEX_DIRECTION_TAG","idifyReverseTerms","isValidKeyword","INVALID_IRI_MAPPING","isPotentialKeyword","expandPrefixedTerms","contextRaw","getContextRaw","EXPAND_KEYS_BLACKLIST","isReservedInternalKeyword","keyValue","ALIAS_DOMAIN_BLACKLIST","KEYWORD_REDEFINITION","ALIAS_RANGE_BLACKLIST","getContextValueId","INVALID_KEYWORD_ALIAS","INVALID_TERM_DEFINITION","isPrefixValue","changed","expandTerm","canAddIdEntry","isValidIri","newId","expandedType","normalize","processingMode","normalizeLanguageTags","lowercase","containersToHash","newValue","containerValue","applyScopedProtected","expandOptions","isTermProtected","isSimpleTermDefinitionPrefix","validateKeywordRedefinitions","contextBefore","contextAfter","deepEqual","PROTECTED_TERM_REDEFINITION","validate","valueType","substr","INVALID_VOCAB_MAPPING","INVALID_BASE_IRI","INVALID_DEFAULT_LANGUAGE","INVALID_VERSION_VALUE","INVALID_CONTEXT_ENTRY","INVALID_PROPAGATE_VALUE","getPrefix","CYCLIC_IRI_MAPPING","isValidIriWeak","JsonLdContextNormalized","isCompactIri","objectKey","objectValue","INVALID_TYPE_MAPPING","INVALID_REVERSE_PROPERTY","CONTAINERS_1_0","INVALID_CONTAINER_MAPPING","CONTAINERS","INVALID_LANGUAGE_MAPPING","INVALID_PREFIX_VALUE","INVALID_NEST_VALUE","applyBaseEntry","inheritFromParent","parentContext","external","normalizeContextIri","contextIri","_a","parseInnerContexts","ignoreScopedContexts","ignoreProtection","ignoreRemoteScopedContexts","INVALID_SCOPED_CONTEXT","minimalProcessing","internalOptions","DEFAULT_PROCESSING_MODE","remoteContexts","CONTEXT_OVERFLOW","hasProtectedTerms","INVALID_CONTEXT_NULLIFICATION","overriddenLoad","getOverriddenLoad","parsedStringContext","load","contextIris","contexts","all","subContext","reducedContexts","reduce","accContextPromise","contextEntry","accContext","importContext","INVALID_IMPORT_VALUE","loadImportContext","defaultExpandOptions","newContext","overlappingKeys","newContextWrapped","INVALID_LOCAL_CONTEXT","cached","document","LOADING_REMOTE_CONTEXT_FAILED","INVALID_REMOTE_CONTEXT","RECURSIVE_CONTEXT_INCLUSION","importContextIri","code","http_link_header_1","fetcher","accept","mediaType","colonPos","alternateUrl","linkHeader","link","rel","uri","LOADING_DOCUMENT_FAILED","expandVocab","contextValue","validIriMapping","vocab","vocabRelative","base","potentialKeyword","contextPrefixValue","allowPrefixForcing","allowVocabRelativeToBase","compactIri","shortestPrefixing","suffix","allowPrefixNonGenDelims","separatorPos","charAt","isPrefixIriEndingWithGenDelim","keyword","KEYWORD_REGEX","prefixIri","ENDS_WITH_GEN_DELIM","Boolean","IRI_REGEX","IRI_REGEX_WEAK","VALID_KEYWORDS","object1","object2","objKeys1","objKeys2","every","value1","value2","ContextTree","subTrees","getContext","head","tail","subTree","depth","setContext","removeContext","path","jsonld_context_parser_1","stream_1","EntryHandlerArrayValue_1","EntryHandlerContainer_1","EntryHandlerInvalidFallback_1","EntryHandlerPredicate_1","EntryHandlerKeywordContext_1","EntryHandlerKeywordGraph_1","EntryHandlerKeywordId_1","EntryHandlerKeywordIncluded_1","EntryHandlerKeywordNest_1","EntryHandlerKeywordType_1","EntryHandlerKeywordUnknownFallback_1","EntryHandlerKeywordValue_1","ParsingContext_1","readableObjectMode","parsingContext","ParsingContext","util","jsonParser","contextJobs","typeJobs","contextAwaitingJobs","lastDepth","lastKeys","lastOnValueJob","attachJsonParserListeners","fromHttpResponse","endsWith","MULTIPLE_CONTEXT_LINK_HEADERS","ignoreMissingContextLinkHeader","contentType","match","exec","stream","PassThrough","parsed","data","_transform","chunk","write","newOnValueJob","lastDepthCheck","flushStacks","listPointer","listPointerStack","rdfRest","rdfNil","getDefaultGraph","listId","listHead","idStack","listRootDepth","splice","EntryHandlerContainer","isBufferableContainerHandler","pendingContainerFlushBuffers","flushBuffer","unaliasKeyword","parentKey","unaliasKeywordParent","emittedStack","handleKey","INVALID_REVERSE_PROPERTY_MAP","inProperty","validationStack","property","Math","max","validationResult","validateKey","valid","isLiteral","entryHandler","ENTRY_HANDLERS","testResult","handle","isStackProcessor","processingStack","validateValueIndexes","unaliasedKeywordCacheStack","processingType","graphStack","graphContainerTermStack","jsonLiteralStack","literalStack","subjects","valueBuffer","unidentifiedValuesBuffer","depthOffsetGraph","getDepthOffsetGraph","graphs","getGraphContainerValue","bufferedValue","reverse","emitQuad","subGraphBuffer","getUnidentifiedGraphBufferSafe","graphBuffer","unidentifiedGraphsBuffer","topLevelProperties","isPropertyHandler","onValue","fill","v","isParsingContextInner","valueJobCb","contextTree","jobs","job","executeBufferedJobs","onError","applicableTypeJobs","applicableTypeJobIds","typeJob","isPrefixArray","sortedTypeJobs","sort","job1","job2","sortedApplicableTypeJobIds","jobId","EntryHandlerArrayValue","EntryHandlerKeywordContext","EntryHandlerKeywordId","EntryHandlerKeywordIncluded","EntryHandlerKeywordGraph","EntryHandlerKeywordNest","EntryHandlerKeywordType","EntryHandlerKeywordValue","EntryHandlerKeywordUnknownFallback","EntryHandlerPredicate","EntryHandlerInvalidFallback","ContextTree_1","JsonLdParser_1","contextParser","skipContextValidation","produceGeneralizedRdf","allowSubjectList","rdfDirection","streamingProfileAllowOutOfOrderPlainType","activeProcessingMode","parseFloat","rootContext","parseContext","activeVersion","PROCESSING_MODE_CONFLICT","offset","keysOriginal","contextData","getContextPropagationAware","contextKeyEntry","scopedContext","propagate","originalDepth","hasApplicablePropertyScopedContext","lastKey","lastKeyValue","handlePendingContainerFlushBuffers","pendingFlushBuffer","emitError","emitContext","getUnidentifiedValueBufferSafe","getExpandOptions","EXPAND_OPTIONS","shiftStack","depthOffset","deeperIdStack","rdf_data_factory_1","canonicalizeJson","rdfFirst","RDF","rdfType","rdfJson","getContextValue","contextKey","fallback","entry","getContextValueContainer","getContextValueType","getContextValueLanguage","getContextValueDirection","isContextValueReverse","getContextValueIndex","isPropertyReverse","needle","haystack","indexHashes","index","existingIndexValue","CONFLICTING_INDEXES","valueToTerm","valueToJsonString","getContextSelfOrPropertyScoped","unaliasKeywords","val","valueLanguage","valueDirection","valueIndex","subValue","INVALID_VALUE_OBJECT","INVALID_VALUE_OBJECT_VALUE","INVALID_INDEX_VALUE","INVALID_LANGUAGE_TAGGED_VALUE","INVALID_LANGUAGE_TAGGED_STRING","nullableTermToArray","createLanguageDirectionLiteral","INVALID_TYPED_VALUE","typeTerm","createVocabOrBaseTerm","INVALID_SET_OR_LIST_OBJECT","listValue","graphContainerEntries","resourceToTerm","stringValueToTerm","XSD_BOOLEAN","XSD_INTEGER","XSD_DOUBLE","predicateToTerm","expanded","intToString","Number","isFinite","isInteger","toExponential","defaultDatatype","contextType","contextLanguage","contextDirection","direction","valueNode","disableCache","cachedUnaliasedKeyword","unliased","hash","newHash","containers","getContainerHandler","isComplexGraphContainer","validateReverseSubject","INVALID_REVERSE_PROPERTY_VALUE","depthContainer","graphContainerIndex","getContainerGraphIndex","graphId","keyUnaliased","getContainerKey","getPropertiesDepth","lastValidDepth","XSD","ContainerHandlerIdentifier","canCombineWithGraph","maybeId","ids","some","ContainerHandlerIndex","graphContainer","indexKey","indexPropertyRaw","indexProperty","indexValues","indexValue","handlePredicateObject","ContainerHandlerLanguage","INVALID_LANGUAGE_MAP_VALUE","ContainerHandlerType","containerTypeType","entryHasIdentifier","keyOriginal","listRootKey","keyOption","handleListElement","valueOriginal","listRootKeys","newLinkTerm","linkTerm","ContainerHandlerIdentifier_1","ContainerHandlerIndex_1","ContainerHandlerLanguage_1","ContainerHandlerType_1","isSimpleGraphContainer","checkGraphContainer","containersSelf","containersParent","containerHandleName","CONTAINER_HANDLERS","handler","containerName","depthProperties","depthPropertiesGraph","atGraph","objects","listValueContainer","EntryHandlerKeyword","EntryHandlerKeyword_1","INVALID_STREAMING_KEY_ORDER","INVALID_ID_VALUE","COLLIDING_KEYWORDS","INVALID_INCLUDED_VALUE","valueUnliased","elements","element","INVALID_TYPE_VALUE","hasTypedScopedContext","typeContext","c","keywordType","VALID_KEYWORDS_TYPES","INVALID_REVERSE_VALUE","C","LEFT_BRACE","RIGHT_BRACE","LEFT_BRACKET","RIGHT_BRACKET","COLON","COMMA","TRUE","FALSE","NULL","STRING","NUMBER","START","STOP","TRUE1","TRUE2","TRUE3","FALSE1","FALSE2","FALSE3","FALSE4","NULL1","NULL2","NULL3","NUMBER1","NUMBER3","STRING1","STRING2","STRING3","STRING4","STRING5","STRING6","VALUE","KEY","OBJECT","ARRAY","BACK_SLASH","charCodeAt","FORWARD_SLASH","BACKSPACE","FORM_FEED","NEWLINE","CARRIAGE_RETURN","TAB","STRING_BUFFER_SIZE","tState","string","stringBuffer","Buffer","alloc","stringBufferOffset","unicode","highSurrogate","state","bytes_remaining","bytes_in_sequence","temp_buffs","toknam","l","proto","charError","appendStringChar","char","appendStringBuf","start","end","size","copy","n","onToken","j","intVal","parseInt","isNaN","token","parseError","pop","parent"],"sourceRoot":""}